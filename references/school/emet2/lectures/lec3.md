SPEAKER 0
This material has been reproduced and communicated to you by or on behalf of the Australian National University, in accordance with Section 113% of the Copyright Act 1968. The material in this communication may be subject to copyright under the Act. Any further reproduction or communication of this material by you must be consistent with the provisions of the Act. Do not reproduce this material. Do not remove this notice.

SPEAKER 1
I The something Yeah. Because Uh Um. Oh No, OK. Yeah. I Yeah Don't have to go. I Yeah Yeah. For sure. Yeah. Right.

SPEAKER 2
OK, good, good afternoon, everybody. Thanks for being here on such a nice and sunny day. And how is everyone? The quiz is underway. Do you guys know this? Has someone attempted it already? Was it? Oh it was good, OK. You had, sorry? OK, super. I like it. Good. So it's, it's constructed in a way to be, uh, what's the word, reminiscent of the lecture. And uh what we covered in the first two weeks and for you to go ding ding ding ding ding, so you, you collect a lot of points, hopefully, most of you, it's not a promise, um, but you'll find, you'll find out. Um, It closes. It shuts down at 3 tomorrow. Start early enough, so like I said, don't, don't wait until 2:30 or tomorrow, then you only have half an hour, but also I believe at 3 o'clock. Um, you will receive your score. You haven't received your score yet. So they'll be released, um, at 3, I'm guessing. And And then I guess in each question you will find out. Um, whether you got it right or wrong, but it will not tell you the correct answer if you got it wrong. boo, can you, can you give me the correct answer? No. So you, you talk to your classmates, or then you work through it, and then if you can't work it out on your own. Then you talk to us and then we help you, OK, but we don't sort of just hand out hand out the answers, but it should be doable because if you get an answer wrong, that means there's only 3 remaining on each question because it's a multiple choice out of 4 in each question, so you should be able to work it out. So learning, it's a learning exercise, or learning journey as they say in my kids' schools. OK, we, we're there to support you, um, so feel free to talk to us, talk to the tutors, surprise them or talk to me, and well. Should be OK. Any other questions before we continue? Well, let's continue then. All right, what are we doing? Are we still reviewing probability and statistics, but only maybe 10 more slides, and then we start doing the simple regression model or we start with the simple regression model. So let's run through the rest of. Probability and statistics. So far we've done, I don't know if you've noticed or if I said it explicitly we've done univariate statistics probability meaning we have one variable. Now we do bivariate, right? And the extension and later in the semester will be multivariate. Um, so bivariate means two variables and multivariate when we run regressions. Later in the semester, we have A dependent variable and K regresses, so you've got K plus 1 variables at the same time, and a key concept is that of covariance and correlation, which, which, Looks at the statistical relationships between two randoms. Which you probably have done in stats, I'm hoping. I don't have a lot of faith, but uh we'll run through this so covariance and correlation. So I've said, I've mentioned all of this, let's move on. So we assume that we have a random sample of sample observations on all that pairs XI and YI from an unknown population. Um, let me just skip ahead. Do I give you an example? No. Um, soon enough I'll give you an example. We don't know the marginal population distributions of XI and Y I. By marginal I mean sort of their individual statistical distributions. So for example, XI could be your heights and YI could be. Your weight. OK. You would think there's a relationship between these two variables. Right, and what I'm meaning by the marginal population distribution, if Xi is height and Yi is weight, I don't know. The underlying distribution of height or weight, I don't know. And I also don't know the joint distribution, so how Sort of the association between the two is generated, OK? So I don't, I don't know them individually. Never mind jointly, no information. But um we of course will use a sample to learn about the joint distribution and our focus here in the next 5 slides or so is to study parameters of the joint distribution. Alright. And those are the covariants and the correlation, those are the two main parameters that we're interested in. So the first thing to do when you have Two variables whose association you want to look at. Is plotting them, looking at a scatter plot, and I'm taking Aya the example from, from the textbook which is looking at the joint distribution of student test scores and the student teacher ratio and this I think is at secondary schools in California. It's an American textbook. Um, the primitive idea, and so this is an example that runs throughout the semester. So we'll, we'll see this quite a bit this semester. So if you pay attention now, that's useful because we will revisit this example all the time this semester. So the primitive idea is that schools, when I say schools, I, I mean, I think secondary schools, if I remember this right. And that schools, secondary schools with lower student teacher ratios, so means smaller class sizes. achieve better results on standardised tests. And so looking at data from Californian school districts, this is how the scatter looks like. This is taken from the book. Now, let me explain what's going on in this picture. So 5 variant, 2 variables. One is test score. Stand some standardised test does it say is it a math test or reading I I have no idea, and a student teacher ratio. So what do we do? And what is the, what is, what does a dot represent here? Um, there are 420 dots and the way this data is organised is a bit Unrepresentative for what we do in for many of our applications and given the story here, you would expect that every dot is a school but it isn't. It is a school district which has which sort of aggregates the schools in its district, which is fine, OK. So So let's pick a dot. Um, What is a good dot, uh. This one here. Can you see this one? I'm, I'm pointing at it. It is at 20, this is this dot here represents a school district in California with. 25 kids per teacher. And so this school district has a bunch of schools in it whose average class size is 25. And test score is? I don't know, roughly 620. So this is a school district. That is a bad school district in both dimensions low test score, high student teacher ratio, and that is sort of what we would expect that would be our hypothesis go if you have a large student teacher ratio, you're probably not doing so well and the kids' outcomes won't be so good. That's what that school district represents. But you also have sitting above it, I know, at least this dot and that dot here. Is that dot also at 25? Yeah. A dot that has the same student-teacher ratio, so take the this one here, but has a test score of 660 roughly. Which just shows that The student teacher ratio is not deterministic of outcomes, OK? So it's also, I guess a disadvantaged school district. This, this dot here, it's also a disadvantaged school district in the sense that it has a it has relatively large class sizes, but it's doing better. And anything else that's of interest here and Yeah, and then at the other end, you could also study sort of you can eyeball the marginal distribution of the student-teacher ratio. What I can read off here is that the range is from 14 to 25. I don't know what this is here. This is 26, maybe this is 26. So, the student-teacher ratio runs from 14 to 26 in this data set, and test scores run from 600 to maybe 710. OK. And then 400 dots in there represent every student-teacher ratio test score combination that was contained in the data. Um, So there's just a scatter plot and then our brains could think about if you had to fit a line in there, how would it look like? So if I didn't see the the description here, On the left hand side, I would say, first of all, without seeing the scatter plot, I would expect a negatively sloped line, right? Because the story is larger school districts, lower test scores, at least that's the association. If I look at the scatter plot, it's not so clear to me. That there would be a negatively sloped line, but we can read the blurb here and the confirmation is if you put a correlation in there, and most of us have heard of this before, which represents the line that best fits the data, then that would be a negatively sloped line because the sample correlation here is -0.23, but I'll define that more rigorously in a second. Any questions on this picture? It's relatively intuitive, what's going on here. OK. Um So what am I saying here? OK, so in the univariate case last week and 2 weeks ago, we studied as the main parameters of interest, the population mean, and it's sample version, the sample average, and we studied the population variants and the sample variant. And now our main parameter of interest in the bivariate world is the covariants and the the population covariance and this in its sample version and the population correlation and its sample equivalent. Here are the definitions. For the covariances, the covariance. Has this symbol here COV. Between two variables, it's always between two variables. There's no such thing as a covariance of three variables or more. It's always 2. It's always pair wise as this. There's an outer expected value and a product in between, and it's roughly is the demean version of X times the demeaned version of Y in expected value. I say D meaned, I mean the subtracting of, of the population mean here. So X minus E of X is the D meaned version. of X and Y minus E of Y is the D mean version of Y, OK? And you can, you study the mean of that product. That's the outer expected value here. That's called the population covariance. Sometimes you give it this Greek letter notation where the subscripts indicate which two random variables you're studying, and the sample equivalent of this is you replace where you see the expected value operator, you replace that by an average. Here you see I'm taking the average by going. Divided by minus 1. Like I said last week, I could also just divide by the subtracting of 1. Sometimes I do it, sometimes I don't. It doesn't really matter to me. And so this outer expectation here is replaced by 1 over N minus 1, the sun. These two inner expectations E of X is replaced by X bar, which is the sample average. And E of Y is Y bar. So that's how the sample covariance is a straightforward analogue of the population version. Makes sense? For the correlation that is defined off the covariance. So the complicated definition was on the previous slide. This year is now with the covariances in hand to find a new object called the correlation. The population correlation or the correlation coefficient is defined to be the covariance, the population covariance over the two population standard deviations. So, the substantive uh definition is really on the preceding slide, not here. Here this is sort of a just a A byproduct if you will. We look in a second why we do this, and the sample version replaces population parameters, so where you have the Greek symbol sigma in at the top and at the bottom here by the sample versions where I use the Ss. So as sub XY was defined on the previous slide here, right? That's this guy that's the sample covariance. That's in the numerator here and the denominator we defined last week as subscript or random variable is the sample standard deviation of the random variable. Now, what's the intuition? So we've seen the mathematical definitions. What's the intuition? So they are both measures of joint variation in X and Y. And this is, this is how to make sense of it. If above average values of X tend to occur together with above average values of Y, then both the covariance and the correlation will be positive. So a way of saying this slightly differently would be, so if, if you have this if statement here, then you go, then the covariance is positive. And as a consequence, the correlation will be positive too, because the correlation just inherits the sign of the covariance. If below average values of X tend to occur together with below average values of Y, then the same, then the covariance will be positive and therefore also the correlation. OK. So, Going with my example of your height and weight. So my argument, if you, if you think about what's the covariance, the sign of the covariance of these two variables, height and weight, my thinking would be this. People who are taller tend to be weighing more. This is also not saying that every tall person weighs more than a small person or the other way around, OK, but it's a that's why the word tend pops up here. OK, that's important. If it tends to be the case that tall people also are heavier. Then the covariance is positive. So the, on the flip side, uh. Shorter people So let me make a wrong statement. Shorter people are lighter. That is incorrect. You hear so does everyone understand this? This is important because this is also how we interpret regressions later. When I say all short people. Don't weigh a lot, doesn't make sense. Then, then that's wrong. But the statement is shorter, people tend to weigh less. Tend or the association is negative or the covariance is negative and then by inheritance the correlation too. Makes sense? Now, then the, the bottom two points are. Um, yeah, are not represented by these particular two random variables. Um, height and weight. Height and weight are positively correlated. If it, if it, well, the generic statement for, for negative covariances is if Um, above average values of X tend to occur together with below average values of Y, then the covariants are negative and therefore the correlation. And on the flip statement or the converse, if below average values of X tend to together with above the average values of Y, then both covariance and correlation will be. OK, any questions? All good? No surprises. And still remains the question, why bother about this thing called correlation if it sort of doesn't really seem to add any value, it inherits the same sign. What's the point? Um, the point is this. The Covariance, by definition inherits the units of measurements of both X and Y. So for heights and weights, it's literally centimetres times kilogrammes. And if those are the units of measurements that we used. And that is a weird unit of measurement, so to to get this free or. Yeah, to, to clean this or rinse this or rinse the units of measurements out by dividing by the standard deviations, you make it unit of measurement free, and that's what the correlation does. And it also turns it into a number that is between 91 and 1, which is nice. Why is this nice? Because if I give you. Um, a bunch of random variables, and I asked you to determine the covariances between them. You can't actually compare them because they've got different units of measurements. But with the correlation, you have um a concept of Covariation that is measurement or unit of measurement free that you can use to compare across applications. OK. So you can say, oh, I've got a correlation of 0.6 between these two random variables, and of 0.8 between those two random variables, you can make a judgement immediately on where the correlation is stronger, OK? That's what that does, but essentially it's sort of just a convenience function to turn the covariances into something that is more interpretable, OK? I think there are probably no surprises. You would have done this in stats, is that right? Few OK, and then one lesson that we addressed in the second hour also today is that they are both measures of co variation between two random variables, but only to the extent that they uh that there's a linear relationship between X and Y. So what do I mean by that? This is also from the book. Um, so I give you four cases of this is now correlation, where the top pictures show you very clear correlations. One's positive, one's negative. One is 0.9, which is close to maximum because one is the max, and then top right picture is negative.8. All right. And What I mean by linear relationship is that you, if you Have to visualise the line, the top two pictures would tell you roughly a suggestive of how a line would look like, or where you would put a line into the scatter plot in, in the middle of that scatter plot. Now, the bottom pictures are not so easy. The, the bottom left one has, is an example of a scatter plot with a zero correlation, and That is the the bottom left picture is an example of what we want the zero correlation to, to mean, namely, You can't visualise the line in there. I mean, you can, but you can visualise like infinitely many lines. A flat line, a vertical line, a positively sloped line, a negatively sloped line, all of them seem plausible in the bottom left picture, right? And that is what we would like, um, a zero correlation to mean. Unfortunately, the bottom right picture is also mathematically a zero correlation. You go, and if you put a line in this picture, not by line I mean. A straight line, not a curve. Then again, there's many ways of doing that, but you would go, wait, wait a second, why would you put a line into this picture, the bottom right, you would put a curve. So this is an example where there is clearly a relationship, a functional relationship between these, and this, this one is a quadratic one, OK. I mean, the bottom right picture here. But the correlation Doesn't adequately reflect it because the correlation can only detect linear associations. There is no linear association here or not a good one, OK. And in the 2nd hour, we'll, we'll study this situation. I, the situation that we will study is a U-shaped, so it's sort of the Um, flipped around version of this picture. OK. So just bear that in mind that uh when we talk about covariance and correlation, um we, and we say we did detect a zero correlation. That does not mean that there is no relationship. And the bottom right picture demonstrates this. There's clearly a relationship between these two random variables, but uh, that relationship is not covered or captured by the concept of covariance. That's also why when you have a data set, you you could skip the plotting and graphing and just calculate numbers and fit lines and come to the conclusion that there is no association or no correlation and make the wrong conclusion that therefore there's no relationship between the two variables. So that's why oftentimes a good. First step before you do numerical data analysis is to plot the data and then just give it. A reasonable visual inspection and go, look, there is a relationship, and I can already see I wouldn't fit a line here. I I think I said enough. Any questions? So we've finished statistics and probability. Um, and we'll move on now to a new topic, simple regression. Let's do it. Um, ordinarily squares estimation, we start, we're not actually defining the OLS estimator today. Uh, we do it in the 2nd hour in the workshop, but for now, we'll take a sort of a higher perspective on things. So we're still interested in the statistical relationship between two variables, X and Y. And we're running with the example from the textbook again, student teacher ratio that will be our X variable and student performance will be our Y variable because we're roughly seeing a causal story from the direction of student teacher ratio into test scores and we're sort of building up towards interpreting stuff as causal as we go throughout the semester. Um, but, um, that's why we pick the student-teacher ratio as X and the student performance as Y. Um OK. What's the hypothesised relationship between the two? I think we've we've mentioned this before. The argument is smaller classrooms or fewer students per teacher, more individualised instruction, individualised instruction hopefully helps students. You never know, really depends on the teacher, um. Uh, at least you hope doesn't make things worse, OK? And therefore we would hypothesise that smaller classrooms translate to better student performance. It's very, very straightforward argument. So if we wrote this down as a functional relationship, this is how we would write it down now. Um, what's interesting here is, what is interesting here, uh, the, the way we set this up is like I said earlier, almost like a causal model where we go, uh, STR student-teacher ratio explains test score. OK, so once you plug in a student-teacher ratio, out comes the test score, but it's not quite so easy. We have this thing called you. Uh, which is Everything, all other things that explain test score that are not STR. So the way I formulated this, it's an umbrella term, OK. The umbrella for everything that explains the outcome that isn't STR. And it really is context-specific on what that could be. But what I, what I'm giving you as an example is intelligence and luck on test taking day. This is not an exhaustive list here. I'm just giving you examples. OK? But the point here is there are other things that determine the outcome other than STR. OK. Good Now, OK, so terminology, which you would probably know is test score is the dependent variable or the outcome error. STR is the independent variable or explanatory variable or the regressor, and U is the error term. Um, so if this was our model, then our hypothesis from earlier. Which could be summarised in In the derivative. Of Tesco with respect to SDR to be negative, just meaning that um Larger classrooms. are suggestive of worse outcomes for kids. All right Um, that is a very simple economic model here in this equation summarised in this equation and the derivative. Um, Yeah, so why do we include you? I think I mentioned this already. Um, if we did not include you as part of the F function, then we would say that the relationship between the two variables, test score and STR. It's deterministic, that there is nothing else that specifies test scores. Other than STR, OK. So the presence of the er term is crucial. Otherwise, you're saying there's a deterministic relationship. Um. Which is almost like saying they are one and the same thing if there wasn't an error term. Of course there are variables that have deterministic relationships. So for example, the temperature in Celsius versus Fahrenheit, there's some um bijective mapping between these two, and there's no error term. OK, but here there is an error term. And it's relatively intuitive, um, that you would go, there must be other things beyond tests uh beyond STR student-teacher ratio that explain test scores. And I've mentioned them, some of them before, like luck on test taking day or kids intelligence. Um, our aptitude. In economics, relationships between variables are never deterministic. I think that's not an exaggeration, very seldomly. But are subject to some degree of randomness and the presence of the aero term allows for that. So, we do think there is a functional relationship between test scores and STR. Now, the, the next question is, what is F? And there we take a few shortcuts. Three shortcuts which help us immensely. First, the F function is additively separable in X and U. Like so OK. Second, the, the way that X affects the outcome is linear. Like so And the Greek stuff here, the betas are called the coefficients of the model and the The way that the error affects the outcome is just the identity. That is also without, that's really without loss of generality. Um. The most substantive restriction I think is the second one where we go, the way that X affects the outcome is linear. Uh, but if you, if you buy this, then that boils down to The specification of the F function. OK. Now, what have we done? uh wait. Just step back. The G function here is important. OK. First, uh, we've assumed linearity and it is, it is that function that governs how X affects Y. It has its own name. It's called the population regression function, the PRF, and we look at it. Now a little bit deeper. The coefficients, the betas, beta not and beta one are unknown. So in a way, on the, on this, on this slide here, our goal was to Get a handle on the F function, but we've reduced the the problem or the dimensionality of the problem, because here F could have been anything. Now the unknowns have reduced to these two parameters, beta not and beta 1. Um, so in a sense, we don't yet know the F function because we don't know beta0 and beta 1, but there will be a way for us from the data to estimate them, and that's what linear regression or estimation does, OK. Um, So Going back, if, if the G function is called the population regression function, and if I have a way of estimating the betas, then I can get an estimated version of the PIF. Now why would that be interesting? Um, So writing the Explicit representation for test scores. With our simplification on the F function that we have just assumed. You get this result here, test score is beta not plus beta1 STR plus the error term. Our hypothesis that I guess the effect of student-teacher ratio on test scores is negative, translates, so this is the derivative is negative, translates to beta 1 being negative. OK. So if the F function is linear, like we assumed, then our suspicion that the The effect of the student-teacher ratio on test scores is negative boils down to a negative beta 1 slope. So our main obsession this semester is to learn how to estimate and interpret these coefficients here, beta and beta one. Now we will learn that next week we define the main method to estimate them next week. Right now I'm just giving you like I'm playing the oracle and I'm saying, what if someone told you that beta not is 700 and beta 1 is -2.5. So this is like the unrealistic case where we are told. But true betas. And the, the examples I picked are sort of in line with the example of the student-teacher ratio and test score example. So what would this, what we would we make with this information? We could plot this. This is the function 700 minus 2.5 point student-teacher ratio. And this is what, this is what you get. And the slope here, so this shouldn't be beta hat, this is beta one, because I'm currently assuming that we know beta one, we don't have to estimate it. But um. So the negative slope comes from the negative beta 1. This year is the population regression function when an oracle tells me the true values of the betas beta 0 700 and beta 1 2.5. Then you can see the PRF. A closer look at the PIF. The PIF tells us the expected test score for a person with a given value of STR. So more technically it's called the conditional expectation of test score given the student teacher ratio. So going back to the previous slide, if I told you, uh when I was at secondary school I had 30 classmates, including myself, then the red line gives me what value? Let's say 622. So then my expected test score is 622. By that, by that line if instead you you tell me when you went to secondary school you had 15 classmates including yourself I guess the predicted or the expected test score is maybe 662 whatever, OK. But what this line tells us is your, your, or, well, the expected test score, which is different to saying the test score that you actually had, because not Every classmate of yours will have had the same test result, OK? And a technical way of saying this is the PRF captures the conditional expectation of test score. Given STR and here is So the technical way of thinking about this idea that the line gives us the expected outcome for a person, not the actual outcome. And the technical concept is the conditional expectation. So what is so we have this is the test score function that was our model after we explicitly assumed how F looks like and we want to study this object called the expected test score for a given value of STR. So the way to handle this is here. So you copy and paste this guy. What we do now is we plug in the test score function from up here on the right hand side, so we get this. So the way you work with a conditional expectation is the conditioning argument, which is the object after the vertical bar, STR. It's a random variable which you are allowed to treat as a known or as a, as a non-random object. So for that matter, you have, you're considering the expected value of beta knot plus beta one times STR plus the error, and what the vertical line here tells me is that I'm allowed to view STR. As a constant or as a known object rather than a random object. OK? So this STR here is, if I, if I didn't have this conditioning argument, I would have, I would need to see this as a random variable. But what the conditioning tells me is you are allowed to treat it as a known object. So in the next line, I'm actually not using that. I'm doing in the second line first is I use this rule that applies to expected values, namely that the expected value of the sum is equal to the sum of the expected values. That is true for conditional expectations as well. So all I'm doing here is breaking up these these three terms here. And I'm always conditioning on STR, but here the conditioning has disappeared. Why? Because the expected value of betano, the condition and expectation of betano, the constant. Conditional and student-teacher ratio is just the constant. OK, so you just go, that's the constant. And the second term here is beta 1 times STR. So I'm writing this here as well that is the factor beta 1 times the expected value of STR, which is a random variable conditioning on STR which tells me that I am allowed to regard STR as a non, where in the next step. I, I therefore just write it down. OK. It's like saying, Um, I, I can assume I know your, your value for STR for student-teacher ratio. The 3rd Um, variable, you. So we, we, we take apart these three terms. We've got the 3rd term here, the conditional expectation of the error, conditional STR. And here I'm plugging in 0, which I'll discuss in a second. If that 0 is true, what I what I've showed here is in the 3rd line that We end up with beta knot plus beta one STR, which is, was defined earlier to be the PRF. OK. And that's why I'm writing G here. If I go back several slides, I defined the PRF. Like so So if my calculation is true here, we have shown that this object here, the conditional expectation of test score given STR coincides with G at STR. Now, there was one. If this was confusing, I, I agree, but the most confusing bit is, where does the 0 come from? That is the so-called conditional mean independence assumption. And so by talking more about the condition expectation, I hope I'll clarify a little bit. I hope I'm not making it worse. Let's have a look. Seemingly on the previous slide, I must have said this. To, to end up with the result that I wanted. This is an assumption. It's called conditional mean independence. Let's have a look. By definition, I want condition to mean independence for two generic random variables Y and X to mean this conditional means independence. That is that the conditional expectation of Y given X is equal to the unconditional expectation of. What that basically says is that knowing the value of X is not informative. About the expectation of why. I'll run through a few examples with you in a second. That's how I read it. Um, so the unconditional expectation is on the right hand side, so there's no vertical bar there, there's no conditioning argument. And if they coincide, we say these two random variables are conditionally mean independent and then you can flip that around as well. And another fun fact is if two random variables are CMI, then their covariance is zero just a byproduct. But let's let's interpret this. Um, on the previous slide, X and Y played the role of generic random variables. What I have done in my test score example was, um, I set the conditional expectation of the error term given STR equal to 0. This has the flavour of the CMI assumption when the unconditional expectation is zero, which are without loss of generality, we can assume. So the conditional mean independence assumption would literally mean this year. You and STR, the random variable U, the error, and STR are conditionally mean independent by the previous definition, if, if this here is the case, right? That is the literal translation of the previous slide. Now, if in addition, I say the expected value of the error is 0, then I get this result here, and that's what I seemingly have done two slides earlier. Now, let's try and make sense of this in, in a real life application. I am using the weather in Canberra as a relatable example. OK. I think these numbers are actually sort of correct. We'll see. Oftentimes I make up numbers, but let's, let's see. The average data max in in Canberra. Throughout the year is 20 degrees. True or not who cares, but let's let's run with this, OK? I'm giving you this information. In summer, it's 27, in winter, it's 13. So mathematically, the unconditional expectation of the temperature is 20. Which we have previously just called the expectation, which we still continue to do. So the expected temperature in Canberra throughout the year is 20. As soon as I give you the extra information on the season, That changes. If I tell you, what is the expected value for temperature conditional that that you consider on summer days, it's 27. And winter days was 13. Then you go, are these two numbers here the same? No, so temperature and season. I'm not conditionally mean independent. OK. That make sense? Oh, what's the time? I'm losing track. Uh, one more minute. OK, let's do it. Now, here's fun examples. Intelligence and education, are they conditionally mean independent? What do you think? Never mind how you exactly define these things. You guys being university students, what should you say? Oh, you shake your head So I Pick two random people from the population and go, let's say they're all 50 years old, 50 years old. Go, Person A, what's your education level? Person A says, 10 years. I went to school for 10 years. Person B. Went 18 years university degree. What's your expected value with regards to these two people's intelligence? It's expected value. I'm not saying person A is not as clever as person B, but my expected value for the person who has less education would be that The intelligence is not higher. OK. This is not a causal story at all, but it's like the based just on the observation that people who tend to go to university tend to have higher aptitude in uh. Whatever, OK. Now, you can believe this or not, but that's, that's roughly my reasoning. A more interesting one is, let's go with height and your self-identified gender. There I would go if you self-identify as female. My conditional expectation is you're not as tall. OK. Again, it doesn't mean that all people who self-identify as female are Short. That's not what I'm saying. It's the average that I'm talking about. And then a fun one that you can think about is the middle one. But uh do you sort of get the idea of what the conditional expectation does? OK. Um, now, we, so just one more second, we now have to think about what that meant in the context of the umbrella term you and the student-teacher ratio. So we'll, we'll do that straight after a 10 minute break. So.

SPEAKER 1
Let's see Do you mind if I ask you? So I just wanna double check with you. I'm pretty sure that you said if you can't make up another occasion or occasion I have to what's the. So do I.

SPEAKER 2
During the same day or you what days different day. OK, so it will be a different um. Let them, let the, let the tutor know, um, you know that they. You write down your name. I don't know how how the um. We're not really attempting to assess. Attendance, yeah, but it's participation, so there's more of a longer tutor gets to know you throughout the semester that that will be the two. go to 12345 and then occasional absence.

SPEAKER 1
OK. because the government. You want a deterministic you don't want the Americans to any sort of. Because I do, because it makes and that means I. right, so it doesn't have to we're just like this. It doesn't necessarily to do with that. Yeah. we want that to be. Yeah, a total. I. Yeah, sort of shrink the role of the only survive. Yeah, the question is always, uh, it's still capture something it is yeah. And like you know a single re requesting that the er the relationship. When he like the the reading session. Are you expecting us to like So the material of the reading. They could just like stop like. Wow, yeah, but it was on. it's only. OK. I. Which is just like We do line re we will

SPEAKER 2
show that can capture it.

SPEAKER 1
fun. Thanks. Yes. Uh, let's Yeah. I What are we doing square. all the parents say this is why they belong to the same person. I can't. I. Yeah Me Yeah. I. And I. Yeah No. So I. Uh I I See. Yes, I That. I mean Yeah Now you Yeah Yeah. I. Yeah I Oh. S Yes. uh. OK, I just do. Yeah. Now Including, I've already I've. I Thank Yes. No. OK Yeah. Yes. Yeah. No, I Yeah. All right.

SPEAKER 2
Should we continue? How many slides are left? All right, not too many. Now how do I get back? OK, did everybody have a good break? All right, me too. Um, any questions before we continue? So I confronted you with this mathematical object which is actually mathematically a difficult object, but I just exposed you to it and I gave you what I'm talking about is the condition of expectation, gave you some context and it's relatively relatable that that guy, the condition of expectation. Um, Now, intuitively applying it to the case of the error term, the umbrella term, and the student teacher ratio because I go back 5 slides. Where I 3 slides, where I started my actually it was 5 slides where I started my D2 on the conditional expectation was Where we have this 0 here, where does that come from? I seemingly have Made the statement that the conditional expected value of the error term, given STR is zero. So what I'm trying to say here is that there's nothing in the student-teacher ratio. That is informative to me as the econometrician to form an opinion about the expected value of the error term. It's a mouthful. So let me repeat it. I want to know what is the expected value of the error term? And you go, I'm giving you this extra information on the student-teacher ratio. Does this Change your opinion about the expected value. Like this is like saying. I want to form an opinion about the average temperature in Canberra, and you go, OK, but only in summer. Does that change your thinking? Oh yeah, yeah, summer is hotter, so the temperature will be higher on average. Here it's a bit more complicated. It's not so relatable because what is the error term? The conditioning variable here, the student-teacher ratio is relatively relatable or intuitive. The error term is this abstract container that used, that we mentioned to be the thing that explains the dependent variable that isn't STR, but that's why earlier I gave you two concrete examples. Do you remember two examples that I gave you for what. The error term could capture um intelligence and luck. OK. So let's go back to, let's move on to the slide where I'm trying. Am I trying to say this here? Um Yeah. So when would the umbrella term, the error term, and ST SDR be conditionally mean independent? So in analogy to the previous examples, they would be if SDR is not predictive of the error term. To be more precise, not predictive about the expected value of the error term. It, it seems clear that if the error term was a truly random error term, then that's the case. So this is my example of luck, luck on test taking day. You go, I'm giving you the extra information on the student teacher ratio. So this is a kid with 25 classmates. So what is the expected value of luck on test taking day? Well, because luck is truly random. The, the extra piece of information that you're offering me that this was a child in a large classroom is irrelevant. It doesn't affect my opinion about the expected value of the error term. Um, But what am I saying here? So if, if, if you can convince yourself that the umbrella term is is a truly random object, then SDR wouldn't be predictive of its mean, and then you would go that's a case where conditional mean independence. Uh applies at least. Convincingly or sort of persuasive, OK. But the question is, do you believe that in a, in a particular situation. Now, here, there could be other factors, unfortunately. So the error term does not only capture luck, but it could also capture privilege. So you are um in a small classroom because you tend to be from a privileged background, whatever that means, but that could also mean um that uh What I'm trying to connect here that there's something in the error term that explains the outcome variable and that is your privilege that is also related to the student teacher ratio, OK, and when we run regressions later in the semester, we always have to think about. What regressors, what independent variables are we including in the regression? And what does the error term capture? And is there anything systematic left that could sort of undermine our causal interpretation? That is all technically related to this discussion here, whether the conditional mean independence assumption applies or not. We'll practise this over and over again as we go throughout the semester. Any questions on on that discussion so far? So here I would say. Since we're only controlling for the student-teacher ratio, there are plenty of other things left in the error term that could be systematically expanding the test score that is also related to the student-teacher ratio. And here is an example of where I actually think the conditional mean independence assumption does not hold. But generically, what I want. To emphasise and going back these 8 slides where we, where we imposed it here. Is it is a technical derivation we go if you can convince yourself that CMI. Applies then. The statement of this slide is the conditional expectation of test score given STR is equal to the PRF or conversely, in The PRF Captures the conditional expectation of the outcome. Conditional on The regressor that you're including. Are you just try to add another. Yeah, so that's where we headed um later in the semester. You go, you, in every regression that you're running or model that you're writing down, you don't have to run any regressions. You have to ask yourself, what's left in the umbrella term. So when you have more than one regressor, the umbrella term is literally captures everything that explains the dependent variables that is not captured by the independent variables. As you include more independent variables. The role of the error term shrinks, but it might not go away, and that's, that's the sort of internal question that we ask ourselves when we run regressions. So what you want to rule out is that there's something systematic left. We, we just, we will pin this down a little bit clearer as we go, and that's why we also will do multivariate regression. Um, so for now, we assume that our simple model. Satisfies the CMI assumptions somewhat unrealistically, but if it, if we, if we convinced ourselves that it does, and we, we had an oracle tell us this was the um The PIF was 700 minus 2.5 times 2828 is a specific number, um, because, oh yeah, the, the for exercise here is, I tell you, when I went to school, 70 years ago. OK. OK, thanks for laughing. Um, I had 28 classmates. Then the PLF, if it applies to me, tells me I'm 630. 630 is the expected test score for me. So the word expected is so important, right? Not the test score for me, it's the expected test score. All right. Now, Yeah, so that's what I'm saying here. The role of the error term is to bring in some randomness across students. So here this is not the PIF, but this is the PIF plus the error. So which models the distribution around the expected value. So I'm making up now. I'm making up Myself here, uh, so it's 3 of my classmates and one, I could be classmate B. So all of them have 28 classmates because they're my classmates. OK, we're all in the same classroom. I'm person B. I have a big negative error that we're just saying, OK, you have, you guys, you, you all, you A, B, and C all have the same expected. Test score of what was it? 630, was it? Yeah, 630. But person A had a large positive error, maybe, well, going with our example. That person was very lucky. OK. Um I'm person B. I was unlucky. It was only my negative, or my bad luck, OK, not my intelligence. And person C is the person that represents the average. OK. That person has the error of 0. Um, the point that I'm trying to make with this little table is only to say that the distinction between the expected test score and then the actual realisation, which could vary, OK? And if we go with the CMI assumption, then the variation is random, OK. Let's um run through this. So in the absence of any other influences on test score, the model predicts a score of 630 for for kids with a class size of 28. Um, Well, that's what I'm doing here. OK, this is, this is the last slide. I do want, I want to wrap it up now. So here is our average test score function. This is just the PRF on the right-hand side. This is what we said earlier, that the PRF, that's what's on the right-hand side. Describes the expected outcome for a person with a particular value of STR. So we're not actually studying how the so this is this sort of wraps it up, how the student-teacher ratio determines test score. What we're studying, that is how it determines the expected test score. So this was The whole narrative of the last 1015 slides, and that's an important point to make, OK, we can never make. Um, Yeah, we, we never make the statement that we Predicting exactly your outcome, but what we expect your outcome to be. OK. And then it's understood that your outcome then could randomly deviate from our prediction or expectation. Any questions? On that. Easy peasy. So next week, we'll learn how to estimate beta knot and beta one using OLS. Um, And Today, we'll still do some exercises from the workshop. So I've complained to um the support services for the lecture rooms. It takes them like 5 days to get back to me. They haven't fixed the situation. I couldn't be bothered, throwing them under the bus just like my parents. Um, so I'll, I'll use this thing again. Um, I couldn't hook up my iPad. Um, I guess to you it probably, I hope it doesn't matter. I came prepared, so I brought pieces of paper and pens. So, it is way too much. Um, let's work through the exercises. And the exercises are relatively easy um applications of Well, the first one for sure of what we just covered. So let's jump to the exercise. Um, where are they? Yeah, workshops. So I will, will be using the the document camera again. Can you guys see this? I'll zoom in one more sip. All right, so now I have to turn this thing on. Is this thing on? Ah, good. All right. Now I don't see the exercise. Uh, what would I do? Um, I, I look at, OK, I've got my iPad here. So one problem that I have with my iPad is that it just doesn't. Connect to the internet. I'll use my phone. Maybe it's easier. Just as I can find. Mm I found it, right. OK. So where are we here? OK. Can you read this? Uh, it's too small? Should I zoom in some more? This is better. And you, you stop me when I sort of right out of the frame. OK. So the exercise is what? The description is there's 2, so sorry about that. Two random variables X. And do you need the, do I need to turn on the light? Where's the light? What's this? I think you, you can see right. Um, this was the light, wasn't it? I just don't want to make it the worse, so 2 random bars. To members And they are independent. So independent, we haven't defined this, but you guys have done stats, means knowing one doesn't tell you anything about the other, roughly speaking, OK? Um, so the, the exercise here is to construct an example of where we do have a relationship between random variables, but it shows up as a negative, uh, sorry, not as a zero correlation. And Oh sorry, X. Is it X and Z? Sorry about that. X and Z. And why? I should read my own exercise. And they're like this. X. Has this distribution standard normal and Z. Has this distributions stay normal. But They have the same distribution and they're independent. But here's the Idea, you define a new random ver. And now We're studying A bunch of covariances here. The first one is, the first question is this. What is E of X? So this is just a warm up. Everyone will shout it out like I know you guys. So what, what are the answers here? What are the 1st 3 moments of, of a standard normal random variable? What's the, the first moment is the mean, right? What's, what's the mean? It's too easy, right? 0. What's the variance? Too easy. I can see that. OK. 1. Now, what's the, what's the 3rd moment? What do the moments do for the standard normal? What do my fingers do here? The alternate So if that is true, what should I write down next? 0. OK. Fun fact. Um, what does the third moment represent again? This, sorry? No. The, yeah, the skewness or symmetry. And the standard normal is quite symmetric. OK, so that's what the zeros tells me. OK, that's just a fun fact from stats 1008. Is that true? OK, everyone is nodding, that's good. Um, all right, this was just a Housekeeping for the next exercise. And the next exercise is this. What is it? Play, play around with this guy here, and what do you get? We want to write down the conditional expectation of Y given X. So The way we do this is The object whose expectation we are after is in front of the vertical bar. Why? So we plug in the definition of Y here, which is X2 + set, right? And the conditioning argument doesn't change, so the vertical bar and X then just tells me. What on the left-hand side of the vertical bar am I allowed to regard? As a known as non-random. That means Wherever X pops up on the left-hand side. OK, so first, before I apply conditional expectation, I'll just do this. The expected value of the sum is equal to the sum of expected values. So that applies to conditional expectation as well. So I've got two terms here X 2d and Z. So I break those up and I go, so this is the conditional expectation of X2 X plus the conditional expectation of Z given X. OK. Now I'm actually using. The conditional expectation. What this here tells me is that I'm interested in the expected value of X2.

SPEAKER 1
But The way to read this is, but you may

SPEAKER 2
treat X as a known. OK. This is like saying, what's the expected value of My age squared, if I tell you that my age is 70. OK. Well, 70 squared. So what's that? OK. But It's known, OK? So it is. X2 Next object to deal with, what's the condition expected value of that? Given information on X, and what would you say here? er justification.

SPEAKER 1
That is an extend Yeah, independent is the key word.

SPEAKER 2
Um, X and Z are independent. That means they have nothing to do with each other. So if you go, you are after the expected value of of that. And I'm telling you X, OK. And I go, well, you, that X is so useless for my opinion about that. That I go. Well, that is equal to the unconditional expectation of that. Which was 0 So we get X2 only, right? Makes sense? You're so quiet Is it too easy or is it still confusing? OK, I'll, I'll go with the two easy option unless you stop me. No, not too easy. Oh, I, it takes some getting used to, I, I, I admit, but um, um. The key here is that Z and X are independent of each other. So if you want to know the expected value of that, Given that I'm offering you information on X, you go, this doesn't help me for shaping an opinion about that. So for example, if that is the temperature in Canberra, and X is the height of a kangaroo, you go, what is the average temperature in Canberra throughout the year? And I'm telling you that um This kangaroo is, I don't know, what did I say, height or weight, weighs 50 kg. You go, that doesn't change my opinion about the temperature in Canberra at all. OK. I'm just picking a silly example where I'm giving you two random variables or two variables that have got nothing to do with each other. They're independent of each other. Um, so, to form an opinion about the expected value of Z, you basically Left alone, you can, you can only use, you only use the information that you have about that, which is it's standard normal that was given to us here. So you, you plug in the zero here. OK, so the big picture was that the expected value of Y given X is X2. Right. Now, Third, what is the expected value of Y, not conditional X, what I call Sometimes the unconditionally expected value or simply the expected value, you go, all right, plug in. What's the definition of Y? It's X2 plus Z. So why is. Is it the is it the random variable that is defined of these other two random variables, X and Z. So if we want to know the expected value of Y, we have to work out the, well, This thing here just. X2 plus that and it's expected value. OK. Well, that's relatively easy because we can still say, well, the expected value of the sum is equal to the sum of expected values. It's the sum of expected values, and then we've done our homework earlier and that is 1 + 0, which is 1. Then you go, all right, connecting the dots in part two, we have looked at the sorry, the conditional expectation and determined it to be. X And the unconditional expectation determined that to be equal to one. Are they generally the same? No. If I tell you. My X is equal to one, then yes, then they are the same. But X. Is standard normal. So, can I have everything in the picture? X is standard normal. It can take on the value one, in which case the the conditional expectation would be equal to one, and the unconditional expectation would be equal to one, but only in that case. There are infinitely many other values that X can take on that are not one. In those cases, the conditional expectation of Y will be something else. Let's say if I tell you my X is equal to 2, then the conditional expected value of Y given X will be 4. Whereas the unconditionally expected value is always equal to one. So this is a case where they differ, right? Where the, where the where the condition expected value and the um Unconditional are different. So we get E of so I start here E of Y given X is not equal to E of Y. So this is a case where we have no CMI. OK. Um, We moved it out of the way. So in a picture, so this will look very crude now. What will I do? Is this a good way of drawing this? Mm, let's say usually this is the 0. If this is X. And this is why, and it looks like this. And What have I done here? I'm trying to suggest that this is X2d. But then you have, OK, um, Lots of dots around there. OK. And so if I take this dot here, a very thick dot. And it's vertical distance to the line here. What is the vertical distance? Oh this, this distance here. That So in a way what I call Z. Here is what in the lecture. You, the era. OK. And beta one here, uh, I guess it gets too confusing. So let me not talk about betas. But, um, you know, I've, I've got a PRF yeah. Yeah, yeah, yeah, yeah. This goes back to our conversation earlier. So the, the regressor here is X squared. But in any case, um, we have a, we have got a curve here, the quadratic function, but Y is, are not the points only on the curve, but the dots, right? So you get X2 plus that takes you into Y, OK? Um, and this is the picture that I showed you earlier, the 4 pictures from the, um, from the textbook with the Covariances or correlations that change. And the bottom right picture was, I think, an inverted U shape, where, where there was a uh sorry, a quadratic relationship, but no linear relationship. And that's the sort of the same story. And we move on to the nonlinear case, I think an exercise 4 now, or with 4 and 5 on shoulders. So Well, derive um this. So this year is gonna be 0. Let's derive this. This is the expected value of X times Y. How would you evaluate this? Well, X is a, is a well-defined random variable. It's standard normal. Y is a derived one, which is derived of X and Z. So we have to plug in Y here. To work this out, so you get X times X2 plus Z, right? And then we work this out. We go, that is, we break this up. X to 3 plus. X times Z. I'm going very slowly, break this up further. And so for the first term, We have worked this out. That was equal to one. Sorry. 0 And I had to think for a second. What do you think this is? The expected value of X times Z. What's the key word? Independence. So what do you get? The expected value of X times Z is equal to. Here Because of independence. I'll just uh refer you, oops, to your stats teacher. Have you done this in stats? Everyone is nodding, that's good. Um, and then we can work this out, right? What is this equal to 0, right? So we get. 0 OK, this is just an ingredient in deriving Number 5. So what we did in number 4 is just the preparation, uh sorry. For number 5, which is Derive this guy here, the covariance. Well, it will be 0. Let's derive it. First, what was the covariance? From the lecture, it was this guy here. That is just copy and paste from the lecture, right? Now, let's expand in the, in the outer bracket, and we get this. So that should be um stats 1008 as well. Does everyone see this? Am I still in the picture. I'm just Expanding or whatever you call what I'm doing here. Makes sense? And then I have 4 terms. The first term is the expected value of XY. The second term. So, now I'm using all my colours here. So this one here, can you see the colours? This is sort of purplish. is the expected value. So I've got this outer expected value. Uh, let me just go slow here. Um, so I go, I'll just plug it in here, so we get. Of X times E of Y. Minus So like that it's just a writing exercise, but can I, can I at least jump ahead and go, do you see that these two expected values here. If I consider their expected value. What do I get? I just get the product of the expected values. Or for that matter, this outer expected value here. When it hits these two expected values there, it's redundant. Because these are just numbers. The expected value of X is some number, not a random variable. The expected value of Y is some number. Actually, we've worked those out. E X was uh 0. E of Y was? I don't remember one. So, E of X is 0, E Y is 1. So this product here is 0. This outer expected value is irrelevant. Right? As a general variation this year holds, and then you go, let's continue. This is E of X times Y, no change there. And then here, what you can do is take This expected value in front of this one here, right? Because that is just a number. Minus E Y E X. And likewise, minus uh what do we do? E of X times E of Y. The order, of course, doesn't matter. And then we have got the one at, at the end, E of X. Times E of Y and the bottom line is what? We get like E of X Y. Minus E of X times E of Y. This is a very, so, so these two guys annihilate each other. Um this is a relatively well known. Reformulation for the covariance. So we're coming from this definition of the covariance, and this result is fairly standard. You go, well, there's something. To memorise that the covariance is EXI minus E of X times E of Y. That is not 0, OK? But we can evaluate it now because we have worked out in the previous exercise. That E of X times Y is 0, so we go that is 0 minus 0 times 1 happens to be 0. He happens to be zero, but not always. So these two random variables. X and Y have a zero covariance. And the big picture is, of course, That They have a zero covariance, however, This is how they look like in a picture. There is a relationship between them, a non-linear one. OK. In fact, this is how Y was constructed, right, on the previous page. Y by construction is, is the quadratic function of X. And then you put an error term around it, Z. And then when you do the math, and you exploit independence and the normal distribution. You get the zero covariants. Yeah.

SPEAKER 1
Can we not just plug in the end of the X and Y.

SPEAKER 2
Where? Here? You can't, so you would, but you can plug in here. So I wanted to go most general. So here you could plug in 0 and 1 here and yeah, that's true. Then, yeah, yeah, in in the exam, you could do that, yeah, unless I say derive a general formula. Yeah, I wanted to make it more general. Yes, in this case, that helps you and simplifies it. That's true. But um this is not wrong. But what you're saying is also not wrong, and where you're applying sort of specific knowledge that you have about E of X and E of Y at the earliest stage. Here, my sort of goal was also to expose you to to this result, and I should probably put a box around this. So that this year is an important result. or reformulation of the covariance. E X Y minus EX times E of Y. Any question? Then let's do the 2nd exercise. Where you have um And I IID random sample. So this is now back to the univariate world. And where I runs from 1 to little N. So you've got N observations or N random variables. YI. So no bivariate, univariate world and You consider, you refine an object called Excuse me, you. New hat To be this fancy looking object. Amen. M of I want to end. Why I minus M. Squire. All right, so let's dissect this. You are looking for the argument that minimises this function, and the argument of that function is what? M. That's what I'm sort of telling you with the subscript. So you regard, let me put an unnecessary parenthesis around here. You regard this thing in parenthesis as a function. In M Little N And by our min, I mean, you want to minimise the function, but what you're after is Not the minimised value of the function, but the argument that minimises the function. OK. This here is a gentle bridge or segue into Linear regression. Because this year, uh must be asking this. It's called the least square estimator. Why? Well, squares, we're guessing has drew with this guy here, the the power of 2. And so we, we have a quadratic function here, and we at least we're minimising the value of this function by picking M optimally. And then now you go back to EE 1001. Who was your EE 1001 teacher? Name names. Was it Jose, ah, you would have done that.

SPEAKER 1
Who?

SPEAKER 2
Oh yeah, yeah, right, yeah. Both are both very knowledge. So they, they could, they could derive this. Easy, although they wouldn't want to do this for me. All right. So, uh, you, you were in good hands. So, What do you do? What do you do? Um So what in analogy, what, what we do what we will do next week is we have, in my, in my world, in my approach, two or three steps. The first steps, you see an optimisation problem, you switch off your brain and you go, Take the derivative. Second step Set equal to 0. Third step, solve. So, 3 steps. So it's almost mindless. Take derivative They go, so what's the function? So the derivative is So the function is in big parenthesis, so you are the the derivative of this guy here, and I'm too lazy now to write down the subscripts of the summation operator. It's clear that it runs from 1 tonne. This is what we're after and the derivative with respect to. M, right? So what's the derivative? What should I write on the right hand side? What's the Key word in it called algebra I don't know. It's a quadratic function, that there's an outer function. That's the quatic. The derivative of the outer function. Uh, 2 times. The function, and then you've got an inner function. So what, what should I write down on the right-hand side here? To To I say I start, you start with 2, that's this 2. Right, the idea of course comes from uh like there's a sight result. If you have the derivative of X squared with respect to X, that was 2 times X, right? So where's my squaring taking place? This is all in the picture here, right? So this goes 2 times. The function and You have a long sum of functions here. So you go sum, so let's let's write this again. Y I minus M. Now it should be to the power of 1, which we don't write down. And then what's the inner function? There's a negative M here. Right? So I should put a negative in front. All good. This was easy OK, thanks Jose, thanks Tu. Um, Um, yeah, OK. 2nd step, 1st order condition or set equal to 0. I go, all right. So -2, some. Y I minus M. Is equal to 0. Now that's where I usually say at the setting equal to zero step you turn the generic argument M into the unique solution that minimises the function. That's where you call it a new name. The new name that we want to give it is new hat. So when I write M here because I forced it to zero. That's where I actually want to call it new hat. Sorry for the, for the mess here. So That's where you're finding the unique minimizer, the argument that minimises the squateric function. And you solve now. Solve for new hat. So first you go, you multiply both sides by negative 1/2, you get, you get this out to you straight away. And then can you see. I actually, let's not do that. So we go, all right, we have got this function on the left, so let's write it down like so. Some of YI minus sum of mu hat. Is equal 0, right? So you go some of, so I should go like this. This is. Sum of YI is equal to sum of new hat. How many new hats do you have, in other words, so let me, let me remove the sideshow here. So you go, those are NU hats.
