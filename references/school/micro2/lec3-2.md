SPEAKER 0
This material has been reproduced and communicated to you by or on behalf of the Australian National University, in accordance with Section 113% of the Copyright Act 1968. The material in this communication may be subject to copyright under the Act. Any further reproduction or communication of this material by you must be consistent with the provisions of the Act. Do not reproduce this material. Do not remove this notice.

SPEAKER 1
Alright, about 5 past, actually 6 past I think on this one, so we'll get started. Welcome back everyone for our main lecture for week 3, it feels really loud. Um, we're gonna continue talking about, Choice under uncertainty, we're gonna keep talking a little bit about this model that we set up initially, this expected utility affected value model, uh, with the utility curve. We're also gonna bring in a too good model which will let us talk more explicitly about insurance, but let us more talk, give us an additional tool to work with when we're talking about choice under uncertainty. Just as a reminder, we went through some gambles last week, uh sorry, last time on Wednesday, and we sort of talked about expected value being the, you know, the statistically expected value of some gamble, um, and that was really problematic because it doesn't seem to match people's actual behaviour. And so instead we're gonna be using the expected utility as our main model of talking about behaviour. So expected utility is not the utility of the expected value, it's the expected utility, it's the probability of an outcome happening times the utility you get from that outcome. You add that up for each possible outcome. And we're gonna we're gonna essentially always use this, again, there are other options, but we're not gonna talk about them. And so there was a question last week we didn't, on Wednesday, sorry, that we didn't quite get to which was risk preferences. Can we talk about this in terms of risk preferences? And the answer absolutely is yes. Like there was a question sorry about the shape of the indifference curve. Is the indifference curve always, oh sorry, is the utility curve always that sort of con concave, concave shape, that downward slope, that downward bending shape? And the answer is, uh, not quite always, but usually. So when we talk about a person and and what's gonna depend on that, that's gonna depend on the risk preferences of the person. People are typical, well yeah, um we can talk about people being risk loving, risk averse, and risk neutral, and the core idea for risk loving, risk averse, or risk neutral is the relationship between that expected utility and the utility of the expected value, or if you like the certainty equivalent and the expected value, which are the same statements. And the way that we define people as being risk loving or risk averse or risk neutral is how they would respond to what we call a fair gamble. So a fair gamble is a gamble whose expected value is zero. Right, so, so it's a, it's a coin flip, you, you pay $1 and I flip a coin and on heads you get $2 on tails you get $0. Right, that's a fair gamble because on average you end up, you pay $1 and get $1 back. That'd be a fair gamble. Risk averse people, refuse fair gambles, risks loving people, accept fair gambles, and shockingly risk neutral people are indifferent regarding fair gambles. Right, if I, if you go to a risk neutral person and say for $1 I'll flip this coin and on heads I'll give you $2 and on tells, I won't give you anything, they'll say, oh I, alright, sure. I'm different, I'm happy, but I'm not equally unhappy. The risk neutral people are indifferent about these fair gambles. And as, as it says here, you can describe these in terms of expected utility, how these match with expected utility. Um, we refuse fair gambles because the, let's talk about accepting fair gambles, I think. We accept a gamble, we accept fair gambles when expected if we are the kind of person for whom, Yeah, let's go here actually. We accept fair gambles if we're the kind of person for whom the certainty equivalent, which is how much we in money terms how much we value the gamble. Exceeds the expected value, which is the, the money value of the gamble, which for a fair gamble is is zero. So if the money value that we place on a gamble exceeds zero, then we take the gamble, which makes sense because we're risk loving, um, whereas if we're a risk averse person, Then the certainty equivalent is less than the expected value. When we go and we see a fair gamble. It's expected value is 0, we value it at less than 0, and so we don't take it. And we'll see these in graphs. And the question was, are these curves normally bowed down, and the answer broadly is yes, because most of the, most people, most of the time act as though they're risk averse. There are exceptions to this for very small amounts of money, you occasionally see people behaving as though they are risk loving. Um, but broadly speaking, for major choices, certainly people behave as though they are risk averse. Not always, but mostly. So I want to do a little bit more before we do questions. Um, so when we talk about this, the risk preferences are really heavily encoded in that utility function, right? A, a risk averse person has diminishing marginal utility of money. So if we look at this person, if we have our person here, we have the amount of money, we have the amount of utility they get from that amount of money. If a person has this kind of shape of their indifference curve of their utility function, You of W This person is risk averse. We can see that from the shape of the utility function. We know this person's, they're risk averse. Because, and and this person has diminishing marginal utility of money, right, the marginal utility of money is the slope of our utility function, so for low amounts of money we have lots of marginal utility, for high amounts of money we have a lot less marginal utility, so the slope is getting smaller. So we have diminishing marginal utility of cash. And this person is also risk averse, right, we can see this from the graph, and we can say, well, Suppose we can get, I'm gonna go, yeah, call us a dollar. Yeah. $4 And we'll make it that we have, we have a gamble, we have a gamble option and we have a 2/3 chance of getting $4. And a 1/3 chance of getting. $1. That's gonna be our gamble, 2/3 chance of 5 of $4. Maybe 5. And a 1/3 chance of $1. We get utility from $1 utility from $5. Just gonna make this a bit more. Obvious for us. And so if we take this gamble, we can talk about our expected value of that gamble. Well there's a 2/3 chance of $5 only 1/3 of $1. I didn't have this prepped for numbers specifically, but we're here somewhere. What is 2/3 of 5 plus 1/3 of 1? Was that 10 to 11/3, that's not very nice, but that's fine. 11/3 is 3 and 2/3 dollars. Is our expected value. That's 2/3 of the way towards 5. This is our expected value of this gamble. I'm only gonna use numbers once. So I expect the value of the gamble, and so we can talk about. The utility of the expected value of the gamble. Just reading off the graph. We can also work out from these graphs, from this graph, the expected utility. Because with 1/3 chance we get the utility of $1. And with 2/3 chance. We get the utility of $5. And so our expected utility is 2/3 of the way towards $5 towards the utility from $5. And so we can do the same thing again, we do the same dotted line, and we go 2/3 of the way along. This gives us the expected utility. Of this gamble. And we see pretty immediately that the expected utility of the gamble is less than the utility of the expected value. Right The utility affected value. Yeah, value exceeds the utility expected utility, which is good, we want, didn't make a mistake, excellent. And so we call this person and so this person is indeed risk averse, they would rather have the expected value. Didn't have the gap, so if they take the if they get the expected value, the money, they get the $3.23 3 and 2/3 dollars, then their happiness is the utility of the expected value. If they take the gamble, then in expectation their happiness is the expected utility, and that is a smaller number, smaller amount, whatever, whatever it is here. And it's hopefully reasonably clear from the graph that the thing that makes that happen is the downward bendingness of the utility function. Right, because the utility functions downward bending, and we draw our nice little dotted dotted line here, and we go 2/3 of a 2/3 of the way along it to get the expected value, we go 2/3 of the way along it to get the expected utility on use in utility terms. Because the utility curve downwardly bends. The utility of the expected value is gonna be a higher up, it's gonna be above. The, the, the 2/3 midpoint, yes. Sure, so it'll, so, so why, why, why is it that that that our, our sort of dotted line here if you like, goes to, goes to here rather than to the origin. It's because in this in this example, the bad outcome is winning a dollar. And so it goes from the bad outcome which is $1 to the good outcome which is $5. In our previous example, I think the bad outcome was 0. Um, and so we go from bad to good. The key point being that for expected value we're going, 2/3 of the way towards $55 and 1/3 of the way towards $1 but also here, right here we also go, oh, I'm sorry. Here we also are going. 2/3 13 And that's driving the result. It's why we can do this, that's why the construction kind of works. We'll do the same thing with a risk averse person in a second. Sorry, risk loving person. This person's risk averse, the risk aversion is encoded within their utility function. Question otherwise questions problems? Cool. The whole 2/3 thing, I'll just, just in case this is helpful, the 2/3 thing is that the expected value of G is 23, 2/3 times $5 plus 1/3 times $1 whereas the expected utility. Of G Is 2/3 times the utility of the $5 plus 1/3 times the utility. Of the $1 and that's why for expected value, We're going 2/3 of the way along in the money sense, the $5.01 dollars, whereas for expected utility, we're going 2/3 of the way along in the utility sense, right, take the utility of $1 takes the utility of $5. Questions, concerns? We will quickly do the same thing for a risk loving person, using the same numbers cos we may as well. So our risk loving person, as wealth, they have utility from wealth. But our risk loving person is gonna have this kind of utility function, right? And uh uh you know, an increasing marginal utility of money. When we have little money, we have relatively low marginal utility, nice and flat utility curve, when we have lots of money, nice steep utility curve, because we have high marginal utility, so marginal utility money is increasing as we get more money. Yeah, it's worth And again, we can get $1 we can get $5 we can get $3 and 2/3 as the expected value. So the utility of the expected value is down here. Because that's how utility our expected value. Our expected utility. Of the gamble is higher. Right, so for this risk loving person, they like this gamble, right, this is rather, yeah, they, they, they would prefer the gamble to just having the money. Because if they take the gamble, they get the get the expected utility, if they take the money, the expected value, then they get the utility of the expected value is their happiness level, and the utility of the expected value is lower. And so this person would take, would pay 3. 2/3 dollars to be able to take this gamble. It's worth more than 3. 2/3 dollars to them. And so this risk loving person is increasing marginal, and that's clearly, hopefully, fingers crossed, clearly being driven by the increasingness of the marginal utility of money, because with increased marginality money we get that nice shape, that nice, you know. Upward bending shape to the diff to the utility function, upward bending shape to the utility function is what guarantees us that the expected utility is higher than the value of the, the utility of the expected value. Questions, concerns, promos. And we finish up with Just for just for completeness, is the risk neutral person. Which is a really boring one, but good to include, the risk neutral person has constant marginal utility of money, the slope of the utility curve doesn't change, so marginal utility is always constant, and this is not a very interesting example, but it's good to have as a, you know, for completeness. If they get $1 they get the utility of $1. If they get $5 they get the utility from $5. If they get the expected value. They get the utility of the expected value. And if we work out the expected utility, well, we go to that we do our dotted line. From the bad outcome to the good outcome. We go the same distance along the line for connected value and expected utility, and we get to the exact same point. And so our expected utility is equal to the utility of the expected value, this person is, Indifferent between receiving the money, the, the, the, the easy money, $3.03 dollars $200 versus taking the gamble. So they're equally happy either way. Ri usual person, constant marginal utility of money. Is happy enough with either the gamble or the expected value. Any questions, concerns, problems? OK. The next one I have in big letters. Because I clearly want to emphasise it, um, I've read so many exams where people will say something like, the the expected utility of these two gambles is the is the same, but gamble A is more risky and this person's risk averse, therefore the person takes gamble A. And I want you to not do that, because that's not what expected utility is doing, right? utility is already encoding the risk preferences. If the expected utility of two gambles is the same, that means that the person is indifferent between them. That means you've already included the risk, you've already accounted for the risk when we talk about expected utility. With expected value you haven't, but with the with the expected, sorry, with the expected value you haven't. With the expected value, you might be able to say something like that. If the expected value of value is great value, is it the same as the expected value of B, but A is riskier than B then. But expected utility already incorporates that, right? The risk preferences are encoded in that utility function. If our expected utility is is the same, then the person is indifferent, sort of definitionally, because the way we measure how much you like a gamble is by its expected utility. There's no tiebreaking rule afterwards, if you're expecting to do the same, then you take them the same. Um, just to really push this, it's also that, um, and also to push the risk preferences really are built into that utility function, you don't, You don't say this is their utility and also the person is risk averse. No, they're risk averse because their utility function exhibits the the shape that means they're risk averse. They're risk-loving because their utility function exhibits the risk lovingness shape. The reason why most people are risk averse is because most people have diminishing marginal utility of money. Which hopefully makes a lot of sense, right, diminishing marginality of money is a very reasonable assumption to make about human behaviour. When you go and do empirics, we observe significant at, you know, glo uh, lifetime earning levels, at least very significant levels of diminishing marginal utility of money. And so because of that, at large amounts of money, people are risk averse, people behave in a risk averse manner because diminishing marginal utility of cash. This ends this section for a second, and then we go on to more stuff, but any questions, so question, this is a good time for questions, is my point. Questions, concerns, problems. Yes. Is it possible you could have a utility function with

SPEAKER 2
both loving and.

SPEAKER 1
Yeah, so the question was, can you have both risk loving and risk aversion, um, and, and yes, right, we've been, we, we've been very hard and fast with our classification of people, real world, real people when you actually actually look at them, it's possible that people are risk loving for very small amounts of money, but then risk averse for large amounts of money, which would be something like a utility function of this kind of shape. Right, so for small amounts, we wanna take gambles, but for large amounts, we don't wanna take gambles. This is, this is possible, this is. Depends on exactly how you interpret the data that exists, but if you interpret the data in a particular way, this is the kind of behaviour you get. You also sometimes get data depending on, and this is beyond what we can do, but you do sometimes get data as well where people are risk loving in risk loving in losses, but risk averse in gains, but we're not gonna talk about that because we're gonna treat everything as zero being the being the midpoint, being the lowest value you can earn. You can have negative wealth, but if you allow negative wealth and you structure the questions in the right way and interpret things the right way, you get prospect theory, um, and you get, uh, this kind of behaviour. In the utility function. Wealth and utility. Depending on exactly how you interpret the data. Um, so the short answer is yes, and the long answer is all the things I just said. Yes. Yeah. Expected value of, OK, yeah, so, so I mean I I think I can talk about, I can talk about this to, to, to some extent certainly, um, so the idea is, Let's just go risk averse. We have Outcome number 1, right, as our as our bad outcome I guess, and we have outcome number 2. Itsaku.com. Uh, just filling in all the blanks, but this, this will answer your question, I, I hope this will answer your question. We have the utility from outcome number one. We have the utility from outcome number 2. This is all fine, love them. um, for our purposes we'll make them equally likely because it makes it makes the argument easier. And so, given these things are equally likely, if we want to talk about expected value. We want to find the midpoint. Yeah. Because vector value is is half outcome one plus half outcome two. If you want to fix utility, it's halfway along between between here, because it's half the utility of outcome 1 plus half the utility of outcome 2. So we're looking for the midpoint there. It's gonna be our expected utility. This is all, this is all OK still? Lovely, excellent. Having the dotted line between these things. Is handy because. If we go half of the way along the dotted line. If we think about the dotted line as going from left to right, and we go half the way along it, we get the expected value. If we think of the dotted line as going bottom, as going from bottom to top, going down from down to up. Then going halfway along it gives us the expected utility. And so the dotted line means that we get that nice relationship between expected, it means that we can go the same distance along it, halfway along it is gonna give us the expected value, halfway along in the left to right sense gives us the expected value, but halfway along it in the up to down sense, Gives us the expected utility. Perfect, it's a geometric tool to express that relationship. So it's just a a handy geometric tool, is that better? Fantastic.

SPEAKER 2
Is there any interpretation for the area between the utility code and the. Kind of like a high risk surplus kind of.

SPEAKER 1
No, if you want to do a risk surplus kind of interpretation, there is an interpretation there, but it's not quite that, and we'll talk about it in a second, but broadly, broadly the, the, the risk, the risk cost, I guess, um, is more to do with the certain, is more the, the, the gap. You either think about the risk cost as the gap between the certainty equivalent and the um and the, Expected value, or as the gap between, The utility of the expected value and the I think that's more the risk surplus, the the amount of money that's the, the area under the curve isn't isn't really something we can talk, isn't a relevant object. Cool. We're gonna draw that graph a couple more times today. Any other questions? Questions, problems, thank you for asking that question because that was really helpful to clarify. OK. So this is one of our main models for how we think about analysing risk, and we can talk about risk loving and risk averse, and we can draw a nice picture. The other way, the other model we're gonna use is using our true good model, we've developed over the last couple of weeks. So another equivalent way of thinking about choice under uncertainty is our too good model. Following the gamble, there are 2 possible states of the world, you won the gamble or you lost the gamble, and wealth in our two states are our 22 goods. Do I have another daughter's licence? Yeah. Um, it's not quite the the logic is not exactly the same as what we've been using the last two weeks, because the last two weeks we've been talking about a bundle of goods and you actually, and you do actually physically consume the bundle of goods, right? You, you get a bundle of goods that is 1 apple and 2 bananas, and you get an apple and 2 bananas, or you get a bundle of goods that's, you know, whatever it is, and you get that bundle of goods. Here the bundle is a bit less obvious in some ways, it's not quite a bundle of goods because you don't actually consume the good outcome and the bad outcome. It's kind of an, it's an a priority before the outcome of the gamble happens, there's some likelihood you're gonna get the good outcome, and there's some likelihood you're gonna get the bad outcome. And so we can model it in this in a similar way of a too good model, because a priori, you have some sort of decision weight on the, you have some sort of weighting you put on the good outcome, some sort of weighting you put on the bad outcome. Um, so we can still think of this in the same way as a too good model, but we do want to keep in mind that philosophically it is a little bit different because we don't actually consume both goods. That's gonna give us a bit more power, because we can get a bit more separability, but we don't actually consume the two goods. Um, And so wealth in our two states are our two goods. One thing that's gonna be handy here is, yep, one thing that's gonna be handy here is that the 45 degree line is gonna have meaning for us, because the 45 degree line that we call our certainty line is where the outcome that we get, the wealth that we get is the same in both states of the world. Because we're on that 45 degree line, then our wealth in the good state and our wealth in the bad state are are the same. Um, I'm also gonna claim in a second that a risk averse person is gonna have bowed in indifference curves. And so we're mostly gonna work with people who are risk averse because most people are risk averse, and so we're mostly gonna be working with bowed in indifference curves. This model, as we'll go through, is is a really useful model when probabilities don't change. When probability of outcomes can change, this model becomes really difficult and annoying to work with because utility curves, I guess indifference curves change in a way that's not very trivial or obvious, um, so this is gonna be a useful model when probabilities of outcomes stays the same. So, let's have a look at, let's have a look at our model. So we have State 1, state 2. Right, as the, the wealth that we acquire in state one, the wealth that we end up with in state 2. Our 45 degree line is meaningful, so I'll draw it as a full line in blue maybe. Ah 45 degree. Certainty line, Is a meaningful thing, is a meaningful object because consumption bundles on that 45 degree line, right, if I'm, if I consume bundle A, that means I get $10 in state one and also $10 in state two, so I get $10 for sure. I get $10 for certain, which is why this is the certainty line. So bundles along this give us an amount of money for certain. Ah I can leave that in. Our risk averse person's gonna have bowed in indifference curves, because our risk averse person, remember risk aversion means. Diminishing marginal utility. Of money That's what risk averse means. If a risk averse person had bode indifference curves, why? Well, because if we have a nice bode in indifference curve. And we think about point B. Point B we have lots of wealth in good A, $30. But not very much wealth in Goodby. That's right, in state. lots of wealth in state 2, not very much wealth in state 1. And this is a problem, and the reason why we might be, we might, the way I draw this, be be indifferent between point B and point A, even though point B has a lot more money in total, right? In point B, if, if state one and state 2 are equally likely, in point B on average, at at bundle B on average we get what is that, $16 whereas at A we get $10 for sure. But we're we're saying we're indifferent here, and the indifference makes sense from the perspective of diminishing marginal utility of money, makes sense from the perspective of risk aversion, because B is risky, right? B has a higher effective value, but it's risky because if state two happens, this is great, but if state 1 happens, this is terrible, and so from a risk aversion perspective, this makes sense that B might be different to A. From a, um, from a diminishing marginal utility of money perspective, hopefully this makes sense as well, because the extra $20 in A, Because it sorry, extra $20 in state 2. Is is nice, but it's only equivalent to $8 in state one because in state 2 we have a lot more money. Right, this extra $20 in state 2. It's nice, but it's only worth $8 in state one because in state two we have more money and so the $20 when we have money, is equivalent to the $8 when we don't have money. Because we have diminishing marginal utility of. All of which is to say, nice boding indifference curves, and as always there's gonna be an indifferent, it's an indifference curve map, right, we have lots of indifference curves for our person. Any questions? Questions, concerns? Risk aversion, low in different curves, and some reasoning why. The trickier one. Is that we also we also can do quite a lot more for this than we could with our standard too good model. There's a lot more structure embedded in this than our too good model. The reason why there's a lot more structure embedded is in our generic too good model, It was that the utility was just some utility of A and B. And we didn't have anything. That we could do further than that. But in our uncertainty too good model, We're talking about the expected utility of some gamble, and so we're talking about the likelihood of outcome 1 times the utility that we get from the wealth in state one, plus the likelihood of outcome 2 times the utility we get from wealth in state 2. And there's a lot more structure here. The utility functions the same, because we're still the same person whether we end up in state 1 or state 2, so utility function is the same there. We have this nice additive separability where we can pull apart the utility we get from state 1 and the utility we get from state 2. Which we can do because um, Because only one of these states actually ever happens, so philosophically, because only one state ever actually happens, there's not gonna be, it's, we don't want to have that your wealth in state two affects the utility if state one happens, because if state one happens, then state 2 didn't happen and what you would have gotten there doesn't matter. So we get this nice separability. So there's a lot more structure here, that structure means two things. That structure first of all, means that, Our indifference curves are going to be symmetric around the certainty line. Because whether state 1 is the good state or state 2 is the good state, doesn't. Doesn't matter, right symmetric around usually line accounting, accounting for different probability ratings, but accounting for different probability ratings it's gonna be functionally symmetric around the certainty line with some scaling. Um, so we're not gonna have weird shapes. It also means something very important, which is on the next slide, which is that where our indifference curves cross the certainty line, the slope of the indifference curves is gonna be the relative probability of the events that happen, of the the relative probability of the events. And the the reasoning for that, let's just draw a little. Quick little graph here. The reasoning for that is if we focus on points on the certainty line. We can talk about the marginal rate of substitution, call this point A. At 8 The marginous obstitution at point A, as it usually is, is the ratio of marginal utilities. And this is marginal expected utility. But with the expected utility of the gamble. Being the likelihood of the utility we get from the first plus, The likelihood of the 2nd times of the utility we get from the 2nd outcome. If we take our expected utility and we take the derivative with respect to W1. We get something that's actually quite nice, right, because if we're taking the roof with W1, there's no W1 here. It's that whole section is gonna just disappear. And so we get the probability of the good outcome times the marginal utility we get from the good outcome, but then the derivative of P2 times U W2 with respect W1 that disappears because there's no W1 there, it goes away. Similarly for, The wealth number 22, similarly for the marginal utility in state 2. This is not a super nice looking object, but, but on the certainty line, this is a super nice looking object, because on the certainty line, wealth in state one and wealth in state 2 are equal. And so if wealth in state 1 is equal to wealth in state 2 because we're on the certainty line, well then the the marginal utility of wealth in state 1 is gonna be the marginal utility of wealth in state 2 because the wealths are the same anyway. And so with those marginal utilities being the same. We can cancel that out and we get that nice outcome that just says, That the marginal utility is the relative likelihood of the events. And that tells us something that tells us that marginality is the relative likelihood of events. So if events are equally likely, then our then our slope here should be 1, I mean minus 1, but it's fine. Should be one, yes, do we keep referring to it

SPEAKER 2
as marginal utility or marginal Either is acceptable marginal utility

SPEAKER 1
and marginal expected utility are both fine here. As long as it's clear, which I think it should be here. Probably should call a marginal expected utility. But it's not Super So on the certainty line, the slope of the indifference curve should be that relative likelihood of events. Well that that actually gives us a lot more than it sounds like it gives us. Because that's gonna be true everywhere on the certainty line, right? It wasn't like that it was a relative like events and then some function of the amount of wealth that was there. It's just the relative like relative likelihood of events, which means that if we know the relative likelihood of events down here is is 1 to 1 and up here it's also 1 to 1, then our indifference curve up here it's gonna have to have that 1 to 1 slope. Up here it's still gonna have that 1 to 1 slope, 1 to 1 slope, 1 to 1 slope. So you can't have something that does all this and then also has, I don't know, it goes really steep here. But that's not possible because this is not the same slope as everywhere else. So on that certainty line, all of their indifference curves are gonna have the same slope. And that slope is gonna be the relative likelihood events, yes. Right, so I, I, I needed to be more careful with my wording earlier. They, they, they are symmetric accounting for the fact that the accounting for that issue. Um, so they're symmetric except they need to be, they're symmetric. I, ish, right, they're symmetric except that, They are a constant the slope is a constant multiple in every instance. Where if they're equally likely that multiple is one, but if they're not equally likely, the multiple isn't one. I wouldn't They're not quite symmetric, they're not, they're not symme they they're not symmetric, but if you expand the definition of what symmetric looks like, what symmetric means, then you can, then you can describe these things as symmetric. Um, but they're not symmetric in a symmetric sense. They're symmetric once you spin them around a little bit. Yeah. Yes, and the cross certain line sloping different curves is the relative of the events, and it means that slope is the same everywhere. This is our too good model, we'll use it for a we'll use it to do something in a little bit, but this is our main too good model. you went quite fast. Questions, otherwise, further questions, questions or issues. Excellent. OK. Yeah. We will press on because it's only 450, um, so. The main thing we're gonna, well the first thing we're gonna use this for is not so much gambles, but we're gonna use this to talk about insurance. um, and so we need to first off discuss, you know, why people might purchase insurance and also the nature of how exactly insurance works. Who of you currently has some kind of insurance that you have? Who has an insurance policy of some sort? If you own a car, you have an insurance policy. Who has phone insurance? You probably shouldn't have phone insurance, just saying. Um, it's not a good, it's not, it's not a good deal for you, but car insurance you should have. Um, so what, for those of you that have phone insurance, for those who have insurance, why might you purchase insurance? I think the answer here should be really straightforward, but you have insurance, why did you purchase insurance? I know you're eating this, I call you at a at a terrible time. Sure. Right, because you are willing to give up a bit of expected value in order to mitigate the risk. Right, you know that on average this is not a good deal for you in terms of effective value, but there's a lot of risk and you don't want to have to deal with that risk for whatever reason. Uh, and that's, that's the reason, that's the reason why people might purchase insurance. Ah, to mitigate risk. The way insurance works and the terms we're gonna be using, we're gonna be talking about premium, the premium for the insurance. The insurance premium is the amount you pay regardless, right? The way insurance works is you pay a premium you pay money to the insurer, regardless of whether the thing breaks or not, regardless of whether the good state eventuates or the bad state eventuates. If the good state eventuates, you get nothing back. If the good state happens, the insurance was in retrospect a bad idea. Right, because you didn't need it, you didn't use it, you just paid the premium and it was money that you lost. If a bad state happens, then the insurer gives you money. Typically either replaces the object in full or replaces the object partially. Right, there's partial insurance and full insurance which we'll talk about. Uh, so we pay a premium and in exchange in the bad state of the world, we receive a payout. In a bad state, we get a payout from them, but this word and this word premium is gonna be the the relevant word that we use a fair bit. We're gonna talk about insurance going along two axes of types, so we can talk about for a particular piece of insurance, we can talk about whether it's fair or unfair. Functionally, all insurance that you're actually gonna see that you could potentially buy is unfair insurance, unfair doesn't mean bad. We talk about this being, Actuarially Fair or actuarially unfair means on the probabilities, right, it's whether on average you lose money. Obviously any insurance that you are actually offered, on average you will lose money because if on average you would gain money, the insurer would not offer it to you. Um, we're also gonna talk about full versus partial insurance. Full insurance makes you whole, right, full insurance means that the payout that you get is sufficiently large that the that the wealth you end up with, if you like, in the good state or the bad state is the same. This is fully insured. You break your phone. Your insurer gives you the new phone that is the same. You crash your car, the insurer gives you a new car and pays any costs. Lots of insurance is partial, where you get some money back. So if you have things like health insurance is a bad example of this, but if you have, um, you might have partial insurance on your vehicle, which is gonna have a lower premium, so you pay less in the good side of the world, but if you crash your car rather than getting the full $10,000 value of your car, the insurer will only give you $5000. Right, this is partial insurance, and, and that would typically attract a lower premium because it's, it's less valuable to you, obviously. So fair and unfair, full and partial insurance. Any questions? And obviously, sorry, and these are both two distinct axes, right, you can have fair partial insurance, you can have unfair partial insurance, you can have fair full insurance, you can have unfair full insurance. You have, you have both. Most insurance in practise is unfair and in practise partial, though it might appear to be full and we're gonna analyse it as if it's full. Questions, questions, problems. Yeah, I've got time. Um, so let's talk about our utility curve model, let's go back to our, our, our old model, not too good model, but our old friend, our utility curve model, where we have our wealth, we have our utility amounts. We're gonna work with a person who's risk averse. And you own a car, right? Who owns a car? I own a car. About half, cool. So you own a car, you own a car, and if you don't crash your car, everything's lovely. Right, you're out here in, I'm gonna call this state one, the good state of the world, where you still where you own the car. In the absence of buying insurance, there's a chance that you'll crash your car. If your car is a significant component of your global wealth, it's not all of your wealth, you have other stuff that you own, but it's a big portion of your wealth. And so if you crash your car, your wealth is gonna drop down to state too. You crashed your car. With that a little bit further over actually. And so if you don't crash your car, things are looking pretty good. If you do crash your car. You're a lot, lot worse off monetarily, and you're also significantly worse off in a utility sense, but the difference is smaller, right, your, your 80% of your wealth was lost, but only like 2/3 of your of your happiness. Cause you have diminishing marginal utility of wealth. Right, you and in state 2, you still get to eat, you just can't drive. What is a decent likelihood of a crash for our purposes? Let's say you're an incredibly poor driver. What's a decent likelihood of a crash? Yep. 25%. You have a 25% chance of a crash and a 75% chance therefore, of not crashing. And so our expected value is gonna be somewhere about here. Right, 75% of the way towards not crashing, because you're a pretty bad driver. Unfortunately, the fact that you're a pretty bad driver is known to the insurance company, they've they've looked at your data and they've figured out that you're probably quite a bad driver and that you have a 25% chance of crashing. So they, they know this. And so if we go 2 3/4 of the way along, we get crypted value, if we go 3 sorry, if we go 3 quarter of the way along left to right, we get a cry to value, if we go 3/4 of the way along up to down. We get our expected utility. And from that we can get our certainty equivalent, the amount of money. Where if we had that much money, it would be equivalent to the expected utility, the utility of that much money is the expected utility. Any questions, problems so far? So this is our gamble, 75% chance of state 1, 25% chance of state two, state to value certainty equivalent, stric utility as shown. An insurance company comes along and they say we will fully insure you, so we don't need a full insurance. First, we will fully insure you. We're gonna offer you this insurance option, you pay us a premium upfront and in the event of a crash, we will make you whole. We will, we will deal with the problem that you have and give you a entirely replace your car, right, deal with all the issues. And we're gonna see a couple of different options. They come along and they say, We're gonna offer you an insurance premium that is, This much money. Right, your car's worth 10K and they're gonna say, take 5K as your insurance premium. What's your response? And so, and so you receive. And there's full insurance, right, so you get this much money, right, you get this much insurance, you get this much money in the good state where you don't, where you don't crash your car or in the bad state where you do crash your car. What's your response in that instance? Do you take this insurance? Any takers? Thoughts, pardon? No, why not? Perfect, because the because the the amount that you end up with by taking the, by taking the premium, by paying this big premium, getting I dollars, getting this, this I dollars for sure, this insurance dollars, for sure, is worse than the gamble. The premium was so big that taking this gamble is silly, right? You, you, The value of the gamble, the value of not insuring your car in money terms is the certainty equivalent. That's how much you value not taking the insurance in terms of dollars. If you take the insurance, you get less than that. I guess this would be a silly, silly thing for you to do. You would not, you would not choose to take this insurance. So this premium is. Not something they would offer you because they would know that you wouldn't take it. And certainly if you were offered this, you would not take it. We have a lot more time to get there, sorry, there may be questions. Any questions, questions, problems? OK. In a similar vein, If we think about a much smaller premium, a really, really tiny premium, so that you end up with dollars, this I dollars regardless. This is kind of the opposite problem. This one you absolutely take, this is spectacular for you, right, your, your utility jumps massively, you get I dollars for sure, um, so your utility is way up here. You're definitely better off. This is the opposite issue of the insurance company would never offer you this. So from the insurance company side, this is a terrible deal. Um, because not only is your expected utility gone up, but your expected value has also gone up. So on average, the insurance company is losing money on this, right, um. It's a payout of $10,000 with a 25% chance of happening, so this is gonna cost them on they they expect this to cost them $2500 and they're only gonna charge you $2000. So for them it's a bad deal. And so you just don't see this. You don't see this because they wouldn't offer it to you. And so we do get some bounds, this does give us bounds on the types of on the on sort of the levels of premium that are reasonable. So any premiums sort of down in this region, right between the certainty equivalent and the expected value, that's where full insurance is going to live in practise, because if we offer a premium, Of $3000. More than $2500 but not too much more than the $2500 expected loss. Then we can be in a nice position where your expected value has gone down, which means for the insurance company, they make money on average, so they're happy, but also, oh no. But also Your expected utility has gone up. And so you will take this on average, and so you will take this deal. Uh, you know that you're losing money, but also that the downside risk of losing your car is so great, right, it's such a terrible thing if you were to lose your car that you're willing to pay a little bit, um, a little bit of a premium over the actual risk to be able to do that. A little bit of a, sorry, I shouldn't say premium because we're using that term already, a little bit over the actual risk. Um, so you pay here $500 to alleviate your risk. Questions, questions, problems. Yes.

SPEAKER 2
Is I kind of like your new state one after you've taken.

SPEAKER 1
I is both your new state one and your new state 2. You take insurance, yeah, you take the insurance, you pay the premium and you get this amount I for sure. Because if state one happens, then you don't crash your car, all it is is you, you're in the same sort of world as state one but you've paid the premium. Um, if state twos, if you do crash your car, then you take the big hit of crashing your car, right, you take the minus $10,000 but then the insurance company gives you back $10,000.

SPEAKER 2
So if you were having a partial insurance, would that mean that you have, um, I is your new state one and of amount below that.

SPEAKER 1
Yeah, and we'll talk about that on the next, on the next slide, but we'll talk about it, have a short break and then we'll talk about it, yeah. Any questions then for 4 otherwise? Lovely, we'll take a short break, we'll reconvene at 3 minutes, at 4 minutes past I think actually, 3 or 4 minutes past, um, it's gonna take 5 minutes, have a walk, have a chill, and I'll see you all in a couple of minutes. Thanks. It It is. So it's right or wrong. This is right, yeah. The issue is marginal utility X, marginal utility Y. Is the utility with respect to X or the utility with respect to one. And then we and then we. Are terrible mathematicians and we cancelled the EU's. Oh, her legs. He's hopping around. You can formalise this, this is formalisable. This is just the idea.

SPEAKER 3
It used to be.

SPEAKER 1
No, the utility of the expected value, which I'll remove afterwards, so this is specific value you get this for sure, to work out the utility, we go up to the utility line. And then. Awesome Yeah Alright, 4 past, so we'll get back started. As a final thing for this graph, for this, for this one for full insurance, we talked about premiums that, That you wouldn't take, we talked about premiums that the insurance company wouldn't offer, and we worked out that the pre the premiums that, the insurance company would benefit from and that you would also benefit from, are where the premium brings us to having a certain, Certain consumption bundle, somewhere in this region here, somewhere between the certainty equivalent and the expected value. We can go a little bit further than this, and we could say something like, if the insurance company's offering you insurance, And they know all of the things about you. How much, what premium would they choose to charge, I guess is the is the question. If they really didn't know all of this precisely, what premium would they choose to charge? That someone might be able to tell me actually, what would they, how would they determine the premium to charge if they were profit maximising?

SPEAKER 2
Yeah.

SPEAKER 1
Yeah, out or just the edge above the, you know, 5 cents so that you end up with 5 cents more than the certainty equivalent, right, so they would charge you the premium so that you're getting basically the certainty equivalent because in that case you take the insurance, it makes you 5 cents better off, and you take the insurance and they've extracted all of that surplus out of you. So they've they've given you full insurance, they've given you, we haven't really talked about fantasy, they've given you full insurance, you're fully insured, but they've extracted all of the money out of you that they, they can. Um, What did I want to say there, uh, yeah, this is unfair insurance, deeply unfair insurance. Fair would be giving you the expected value. This is deeply unfair insurance, but you would take it and it's fine. The reason why in practise you would not typically see this is that while the insurance companies might have a lot of information about you, they don't have literally all of the information about you. Right, they don't see your utility, I mean you don't see your utility curve, but they certainly don't see your utility curve, they don't know the exact likelihood, right, you might be a bad driver, but does a bad driver mean that you're a 25% chance of crashing or a 27% chance or a 23% chance? There's a lot of uncertainty floating around there. And so from the. Insurance company's perspective, they're not gonna hit you exactly, they're gonna try and get their best bet and then allow for a little bit so that they can, they can definitely sell to you, but extract as much as they possibly can from you. So they're gonna figure out the best one to offer you that's maximises their expected profit conditional on, you know, the fact that you might or might not accept depending on what it's good about. So most of the time if you're accepting insurance, you do gain from it. In principle, according to this impression, according to this, any questions, questions, problems? Issues Cool, um, so there was a question about partial insurance, which is great because it's the next slide. Um, so for partial insurance, we have the same sort of set up, um, exactly the same setup, but instead of offering you full insurance, We're only gonna see partial insurance be offered, partial insurance means that we don't make you whole. We don't take as big a premium, typically, doesn't doesn't take as big a premium, but when the bad state happens, you're still, It's still bad for you. Right, so rather than taking $3000 in premium and giving you the full, full $10,000 of your car back, they might take $1000 in premium, but only give you $3000 back in the case of a crash. And so in that case we don't have any, we no longer have like the outcome that you get. For sure, it's an outcome in a good state and an outcome in a bad state, and so if we do, if we, you know, make up some numbers, if we have a premium that brings us down to here, this is gonna be, Uh, the insured, oh dear. Uh, the insurance in. The insurance pay the the amount you end up with if you're insured and don't crash your car, so you pay a bit of a premium, we move in a bit, so this is insurance too, the outcome when you don't crash your car. If you do crash your car, it's not so bad as it would have been because the insurance pays you some money, right, and they pay you money on, you know, on other premiums, so you move back a little bit, you move in principle, you move back a little bit because you still pay the premium in both cases, but then you get money back when you crash your car because that's, that's the way the system works. So we also have some sort of payout in the I crashed my car state of the world. And whether this is worth, so this is partial insurance, whether this is worth taking or not depends on the expected value of having taken the insurance, and it becomes pretty messy, uh, because if we want to look at this, if we want to work it out, we would have to take, I wanna actually change colour to a more obviously different colour. Um, is red a bit more obviously different, it's always hard to tell what's different. It's worse, blue is blue is clearer, more clearly different. Let's go blue then. How does, how does green, green's often either very similar or very different. Much of moness. Let's go blue. Is with some with with with a 25% chance you receive this utility and with a 75% chance, You receive this utility. There's no special reason why the expected value should be the same. Again, typically the expected value will fall because the insurance company wants to make money out, wants to make money out of you. Um, So we would typically see the expected value be lower, but you could, if this was, if everything was working really nicely. I'm gonna change to here. If everything's working really nicely, uh. And this is our new expected value. Expected value with insurance. Sorry. Yes, that's fine. Then we're OK, right, because this will be a graph of insurance that is actually doing what it's supposed to be doing. Partial insurance that is doing what it's supposed to be doing. Because you would accept this because your expected utility goes up. And the insurance company would offer it because your expected value goes down. And so this is partial insurance that does actually work out. But you can see this is pretty messy and figuring this out it's gonna be hard and it's gonna depend, and like, In terms of what the insurance company is offering you, there's two different things that they're offering you here. They're broadly speaking choosing, I mean they're technically they're choosing a premium and a payout level, but in practise they're choosing the, the wealth that you will have if you don't crash your car and the wealth that you'll have if you do crash your car, right, is the, the essentially things that they're choosing, and they're able to vary those two different numbers to try to get more money or less money out of you. Um Yes. I made them up, the insurance company decided, decided that in the good state you would end up with I2. And in the bad state you'd end up with I one. Yeah. It's not a larger pre it's not a larger premium, it's the outcome in the bad state. So in, we'll go we'll go back to here, go back to the the full insurance case first, um, just to, I, I'm answering your question, I'm just gonna do the full insurance case first because it's easier. In the full insurance case, the way that the full insurance case works, can I undo things here? OK, excellent, is the insurance company offers you a premium. Of this much. That's the size of the premium. In the good state of the world. You would Receive this Much wealth, but instead you pay the premium, you receive that wealth, you receive that wealth and pay the premium. In the bad side of the world. You would, without insurance receive this much wealth. But what actually happens is, in the bad side of the world, you've paid the premium. Because you pay the premium regardless. And then the company gives you enough, gives you the money that is the entirety of the entirety of the difference between the good state and the bad state, the entirety of the size of the loss. So then the insurance company pays you. This much money. The full difference of the loss, and so you end up being being indifferent between the the good state and the bad state. Yeah. Yeah. Here it's a similar sort of story, it's just that the payout's smaller. You in the good state, you pay the premium. You would receive this much wealth, but instead you receive that wealth and pay the premium. In the bad state, you would receive this much wealth. But instead you receive that wealth, which is no car, you pay the premium and you receive, A payout. And so you can think of it in terms of the insurance company choosing the size of the premium and the size of the payout. Which is fine, that's how, that's how, certainly when you go and look at insurance, that's how it's displayed, um, but you can also think of it in terms of a prac in terms of, you know, the important things for your choices, what it affects is your wealth level when you don't crash your car, your wealth level when you do crash your car. And so you can think of the insurance company just directly picking I2 and I1. But either way it's fine. Does that make more sense? OK. So if they wanted to, if they wanted to give you more money in the bad state, they could just give you a larger payout and not and not change the premium. There are 2 states, but you pay the premium before the state of the world is realised. So the way the insurance system works is at the start of the year, you pay your car insurance. And you've paid it. Yeah, because it's only a partial insurance, you don't get a payout that fully covers your car, you get 3000 back, not 10. Perfect. Excellent. And if, and as I say, if this is all structured really carefully and really closely, you can end up with a situation where the insurance company is made better off because your expected values fallen, and you are also made better off because your expected utility has gone up. And this can happen with partial insurance, as with full. And this is not a particularly great way of modelling partial insurance. Right, it's fiddly, it's not nice. We want it, we're gonna want it that way. Any questions? Otherwise, questions, problems? Concerns, yes.

SPEAKER 3
That's all just What If they Yeah. Well above we would still like if they offered us a really crappy premium which is like just above our original inspector utility, we would choose to go for.

SPEAKER 1
We would choose ah you would choose, yeah, so, so it's still ordinal in the sense of. And an insurance offer is good only if the expected utility of taking the insurance exceeds the expected utility of not taking the insurance. Um, certainly if you have multiple insurance offers and expect utility of insurance one is up here and utility of insurance 2, option 2 is down here and utility of no insurance is down here, then you would take option one. And the next model will be much better for analysing that. Um, Any other questions, finally, before we talk about two good models? Fantastic. So we also talk about our too good, we can also use our too good model to investigate insurance, because it's, A really good model for talking about insurance. I'm actually gonna tweak how I do this slightly, but that's not a problem, um. State 1, state 2. We had our certainty line, ah no I shall do it in full. We have a 45 degree line. Which is our certainty line. And we have a bunch of indifference curves, because we are risk averse, we're gonna have nice bowed in indifference curves. For ease, I've drawn this so that the good outcome, the bad outcome are equally likely just because it's easier to draw those, um. Like it's right, because it's a lot easier to draw those. I'm actually not gonna worry about having any different curves yet. We're gonna have one in different scarf. Sorry for those drawing on paper, my apologies, um, we have our, Uninsured, call you, bundle you is our uninsured value. When the car crash happens. It's really bad for us. Right, this is. When the car crash happens, our utility in state one really, is really bad, our utility in the car crash. It's not great. But a utility in the. Good state was nice and high. A utility in no crash. It's nice and high. This is good for us. Or you can think of this as wealth, I think it's actually wealth technically. Yeah. Wealth in the car crash, wealth in not the car crash. I've drawn this so that we're talking about these things being roughly equally likely. And one thing that means is that we can talk about the expected value. This is the expected value of being uninsured. Ah, I don't want to use you for uninsured. Taking the gamble, taking the risk. Being And that Soft line that was drawn there. This is our What's called our actuarially fair line. Any bundle along this line? Gives the same expected value. Alright, so all these things, all these points on this line are the same expected value. So it's, it's an iso. I mean the same, it's an ISO expected value one. As opposed to an iso an indifference curve we might call an iso utility line, because it has the same utility along that line. Good. We're gonna use that term ISO a lot more when we talk about production. But I saw expected value is the expected value is the same, iso utility where the utility is the same, which are our indifference curves, right, indifference curve or iso utility line. Concerns, problems here. Fantastic. Let's talk about different types of insurance, different things that might potentially be offered to you in terms of insurance and where you might end up on this. Right, so one option might be, and we'll do one option first and then we'll talk about things that don't work. One option might be full fare insurance. The insurance company comes to you and they say, We will, you know, there's a 1 in 2 chance, where this is drawn there's 1 in 2 chance you'll crash your car, your car's worth $10,000. We will charge you a premium of $5000 and make you whole if things go wrong, so that your expected value is the same. And we will make you whole, full fair insurance. We can talk about our full fair insurance, that's going to be. Full fair insurance. Is right here. Point FF full fair insurance. You're fully insured because you're completely indifferent between whether the the good state or the bad state happens, whether you crash your car or not. You're fairly insured because your expected value has not changed. They charge you the amount so that they charge you in in the appropriate proportions so that your expected value doesn't change. So you're fully insured, you're fairly insured. You would never be offered this, this would be a silly thing for the insurance company to offer you because they can do a lot better, but in principle they could offer this to you and you would accept, and but hypothetically this is your full fare insurance. Concerns, problems. Alright, let's look at some levels of insurance that you wouldn't ever be that that wouldn't ever happen, right, that wouldn't ever be, be a thing that actually occurs. So one thing we're gonna focus on, we're gonna think about, no, no, let's think about. All up here. Why would we never see insurance? In this big ugly red area here, being being existing in the market. Exactly, right, if you were to take this, you would end up with positive expected value, right, your expected value would increase, right, if you somehow, somehow end up up here somewhere, your expected value has gone up, which means the expected value for the insurance company has gone down. The insurance company we think of as being risk neutral. I should expect value for the insurance company has gone down, which is bad for them. So we don't see this because the insurance company becomes worse off, they never offer this. So all this insurance up here, this is all, never happens. What about I will actually leave that on there because it may be helpful. What about down here? Oh Too far. What about insurance down here? Why do we never see this being taken up in the market? Why does this insurance never never happen? if we put a look at data, why would we never see this? Yep, no-one would exactly, no-one would accept it, you're on a lower utility you you would be on a lower indifference curve, you'd be on some dodgy indifference curve down here and that's lower than where you started, so why would you ever take this? This is it's terrible insurance, you just don't accept it. And so that's never seen. The other part that we will say is never seen, though the argument for it's a little bit different. Is what about areas, And then I'll decide whether to get rid of this or not. What about areas down here? Why do we never see That kind of insurance, why do we never see insurance, To focus on the one that hasn't been covered already. Down here. It's kind of a weird one. Yeah. Not more likely, because this is, the probabilities haven't changed here, but we will talk about that in a second. It's saying that you get more money in the case of a crash than in the case of not a crash. It's saying that you have a, you, you've got your car, your car is worth $10,000 and in the case of a crash, the payout will be more than $10,000 right, because your wealth in the bad state. Is is greater than your wealth in the goods, your wealth in the bad state is greater than your wealth in the good state, and so you would prefer to crash your car. For insurance, this is not a good outcome for them because then in practise you will crash your car, like you will actively try and crash your car, which is a moral hazard issue which we'll talk about in a second. So this is knocked out for a different reason, which is not quite within our models yet, which is a moral hazard issue, but you can kind of see why this would never exist, right, because it, it changes the incentive so much that it doesn't work. All of which is to say, the only things that we're gonna potentially care about are the things in that little, that little slice, that's not covered yet. Those are the potentially, the potential insurances, the insurances that you will take. And that the insurance company will offer to you and where you're still better off in the, in the state where you don't crash your car, right, where you can say where you can take steps to avoid, anyway, um, so we're in this little, this little white regions all the left, all that's left. I'm gonna get rid of the red stuff, it's handy, but I want the space, I want the, the cleaner diagram. So we give her that little, that little wedge. We've already pointed out one point on that wedge, the full fare insurance, but we can talk about other insurance options. So we can talk about some insurance option here, for example. This insurance option here doesn't change your expected value. So it's fair But it's partial insurance, right, you're on the same ISO expected value line, it's actuarly fair insurance, that's all fine, but this is fair. But it's also partial. And it's partial because. You receive more in the good state than in the bad so you receive more outcome, more, more wealth, if you crack don't crash your car than if you do crash your car, right, this is no crash. It's crash. So anything along here is gonna be fair and partial, anything along anything along our ISO expected value line is fair partial insurance that the insurance company offers you and that you would, the insurance company would be willing to offer you and that you would be willing to accept. And that's fine. Questions? Lovely, we can talk about. These points down here, right? Insurance. They offer you an insurance that means you end up consuming at somewhere like here. And someone like here is going to be the the other one, right, it's full insurance, but it's unfair. You take it cos you're on a higher indifference curve, right, you take it because you're on some different curve up here somewhere, so it's good. And it's full insurance because you're on the certainty line, you see the same outcome in the good state and the bad state, but it's not fair, right, you are losing expected value, you're on a lower IO expected value line, and so this would be our, Full Unfair. Insurance. So we have full fair insurance on the corner, full partial insurance on that ISO expected value line, full unfair insurance on the certainty line, and of course, Anything else that's in that region that you would accept. But um. But isn't fair and partial or full and unfair or full and fair, anything in that area there, that's your, Unfair. And partial Insurance. Right, so strictly inside that, strictly from the top right, strictly inside, it includes anything on that line on the on the indifference curve. Because as we did in micro one, in the case of being indifferent between taking an option and not taking the option, we tiebreak in the direction of taking that option. Taking the notion of taking it, so you would we say that you would accept those insurances when you are indifferent. Unfair partial insurance. You can see this is in some sense, I, I, I certainly, I should say, I find this a lot nicer to work with, especially for partial insurance, because rather than having to say that the partial insurance is a mixture of this, uh, is a mixture of this state and this state in the appropriate proportions so that this is the expected value and there's a lot of things that are going on to explain what the insurance is. The insurance offer is, We offer you an insurance that means you consume here. This is, this point here, this is insurance I, this is what you, this is what you're being offered. The end. Is it good for you? Well, is it a is it above the indifference curve, then it's good for you, done. Is it good for the insurance company, or is it below the expected value line? I saw I saw the expected value line, yes, good, good for the insurance company. So I find this a lot easier to work with. For these kinds of problems, again, if the if the um probabilities don't change, probabilities change, this becomes really messy because the probabilities also affect the indifference curves, and so this becomes very messy once your probabilities change. Uh This is mostly yes, there is one more point, but any questions, questions, concerns, issues, yes. Yeah, sure, so fair insurance is, let's go back to what we have it on, I think they have it on a slide, don't we? Oh, not quite. So fair insurance is actuarially fair insurance. Fair insurance is where they offer you a piece of insurance and, It's what you would naturally, I I in some ways it's what you would intuitively describe as fair insurance, it's um, There's a, it's it's your, it's your expected value doesn't change, it's the short version of the of the phrasing, trade value doesn't change, the long version of the change for for example, If there's a 1 in 2 chance of a bad thing happening. And they're gonna give you full insurance for it, but it's so it's all into a bad cha, but 1 or 2 chance of a bad thing happening, then, For every $1 they charge you in premium, they'll give you $2 back if the bad thing happens. If there's 1 in 3 chance of the bad thing happening, then for every $1 they take from premium, they'll give you $3 back in payout. So it's that the premium payoff ratio is the same as the probability of the bad outcome. So, is it the same as the relative probability of the outcomes? Um, which guarantees you that the expected value doesn't change. I'm worried about those that going because we do have some things we need to talk about afterwards, yes. Unfair partial, yeah, did I say that? Yes, unfair partial. Anything in that shared region is is unfair partial insurance. Unfair doesn't mean bad, right, unfair isn't like evil, right, unfair insurance just means not actuarially fair insurance, right, it means that the insurance company on average makes money, um, but you can in principle still increase your utility because they're they're, They're taking some of your expected value, but they're also taking away some of your risk. So if you're risk averse, then, then that's fine, right, because as long as if you're you're risk averse and they're not, and they're not because they're huge compared to you, um. Then it's fine, it's still good for everyone. Say insurance is evil. Yes, that, yeah, cool. OK. Any other questions, because otherwise there's 2 things, there's two sort of minor extensions, oh there's one more thing here and then 2 minor extensions. Any questions here? Profit maximising insurance company. If we had our insurance company, and again they knew everything about you, they knew the actual risks, and they knew the actual utility functions so they had your actual indifference goes, basically if they could see this, What would they choose, what insurance would they choose to to sit you on? Where would they choose to have you consume? Which bundle, how would they decide the insurance structure? So the benefit they gain is them sucking expected value out of you, that's what they're trying to do, right? They're trying to suck as much expected value out of you as they possibly can while still having you actually accept the insurance. Thoughts? Probably Perfect, right, they're gonna sit you on the same utility curve. They wanna, as I say, they wanna suck that expected value out of you as much as they can, so they're not gonna give you extra utility because, you know, the simple version of this is if they were putting you here, why would they do that when they can charge you a higher premium and pull you down further towards that utility curve? Why, why would they, why would they offer you? Why would they offer you this? When they could offer you this and you would take it either way and suck them on you. So it's gonna be, it's gonna definitely be, oop, yeah. It's can definitely be on the utility curve somewhere, on the indifference curve, sorry, on the curve, so it's gonna be somewhere along here. Question then is where along that utility curve would they choose to would they choose to push you to? Cos there is actually an answer.

SPEAKER 2
Yeah. That diagonal line where you're paying the where you're getting the full um. Perfect, it's gonna be on the on that on the

SPEAKER 1
certainty line where they're extracting the, where they're making you, so they're giving you full insurance, they're gonna be giving you full insurance down here. This is our profit maximising insurance. Not for you, obviously, this is awful for you, but it is profit maximising for them, and we'll talk about why in a second, yep. Why wouldn't a profit maximising insurance company. Because they can do better by offering full insurance. Assuming there's no moral hazard, which we'll talk about in one second, they can do better by offering full insurance. This is being driven by, This result Right, this result that says the slope of the indifference curve is the relative probability of the events is driving this result because what it means, or the impact of that is when we go and we look at our iso iso expected value lines, those are all the slope of those are also based on the relative probability of events, uh, and so on this oh no. So when we're here, let's draw it in a light colour, when we're here, the slope of this line is also the slope of slope our difference curve is also the slope of our iso expected value line. And so if they were to offer you partial insurance somewhere here. They're gonna be offering you partial insurance on some isolated value line up here. They can do better by offering you full insurance because full insurance pushes you back onto a pushes you down onto a lower ISO expected value line. It reduces your expected value by more, which is to say it increases their expected value by more. Uh, and so this is why we get, The profit maximising insurance being right down there at full insurance that is unfair, that makes you indifferent between taking and not taking insurance, yeah.

SPEAKER 4
Decreasing because I'm a bit confused because it's on both. What we're actually Like when you talk about like expected value decreasing, what does that actually?

SPEAKER 1
Sure. Hopefully, um. There are 2, there are 2 parts to this. Well, we'll cover your, we, we will cover your question, but there are 2 parts. I'm gonna use a new graph because it'll be easier with a, with a new graph, I think. Uh, certainty line. Difference curve. Initial point. And so, we can talk about the, Points where the expected value stays the same, is that OK? this being I saw expected value, the expected value is the same. Everywhere along here Because if you lose a dollar in the good state, but you gain a dollar in the bad state, then you're for equally likely events, then your um value stays the same, yeah. So everywhere along there it's some If we focus on this point here. This is where um it's not just that the expected value is the same as every other point in this line, it's that the expected value, it's that you receive that money for sure. Right, and so this is the expected value of, The Gamble G. Because You receive the expected value of the gamble G regards. Is that OK? If we talk about reducing the expected value. One way of thinking of that is, well, if we, if we move down the certainty line, That's moved down quite a way. If we move down the certainty line, we're talking about reducing our expected value. Alright, so this is Expected value of, I don't know, something else. We move down there etc. but then we can still go back and we can say, well, what's the IO expected value line of all the things in A? Well, it's the things where if we gain, A dollar in the good state, but lose in the bad state, or we gain in the bad state and losing the good state still has the same expected value. This is a lower expected value expect I saw an expected value line, which gives the expected value of this new point. Does that answer your question? Fantastic, excellent. Um, So we have a fair insurance in our too good. Not nice. Yes, profit maximising insurance. OK. Any other questions? On this stuff. Fantastic, OK. Bonus contents. Bonus doesn't mean not accessible, bonus means. Part of the course, bonus content, we don't have slide score, but we have bonus content. The bonus content we're gonna talk about, the main bonus content we're gonna talk about here is we're gonna talk about. What about moral hazard? And how it is distinct from adverse selection. Both are important, both are interesting, especially in an insurance framework. Both are really important and really interesting. Now we said in the previous slide that a profit maximising insurer will offer full unfair insurance, full insurance that makes you indifferent between crashing a car and not. If they really do that properly, I mean properly properly, and they would actually, so I think phone, phones are probably a better example of this than a car, because if you're in a car crash, there's additional expenses that are kind of hard to measure. What about phones, right? So you break, you have phone insurance, you have full, Phone insurance, it's deeply unfair so that you're just barely interested in taking it, but you accept it because you just barely take it. The question is, what happens then? Who has their phone insured? Phone insured? Very few people, that's surprising, OK, um, those who have their phone insured, let's, we're gonna have a real hope here, is your phone in a nice thick case that keeps your phone well protected? No case, right, this is our example of moral hazard, right, the other two are bad examples, but here we have an example of moral hazard. I also have no case. I mean I have this little piece of. Plastic, floppy nothing, that's all I have, um, either a moral hazard, which is that when you buy the insurance, yes, it has the insurance effect, right, it changes your outcome in the good state and the bad side of the world, but it also changes the behaviour that you take, right, taking the insurance has take having insurance or taking the insurance, Has behavioural effects. When you take the insurance, you are less likely to take the steps to avoid the bad outcome. Right, so if you take out your phone insurance, you are less likely to get a big clunky case for it, right? If it's especially if it's fully insured, why would you, if it's fully insured and you no longer care if your phone breaks or not, because if it breaks you just get a new one instantly and you're indifferent between breaking and not. Why would you take steps like putting your phone in a big thick case to keep it protected? Because you get a new phone anyway, who cares if it breaks. Whereas if you're not insured, Then maybe you do put your phone in a big thick case, right, maybe you do take those actions that result in a lower probability of the bad outcome happening. And so moral hazards is this idea is exactly this idea that when you take the insurance, the probability of the good and the bad state actually changes. And as we said before, our, our model here is quite bad at doing that, but the but the the utility curve model is is pretty decent at managing that, um, because you can just change the, you can change the um probabilities pretty easily. So moral hazard is a major issue, it's a major issue with all kinds of insurance, particularly car insurance does have significant moral hazard problems. The, the car insurance is not, is rarely gonna be right at that corner point of full faring of of that of that profit maximising insurance, because if they offered it to you, if they offered the profit maximising insurance based on your uninsured behaviour. Then once you're insured they would expect you to become a more dangerous driver, and so they would lose out because they so they would potentially lose out because you're a more dangerous driver and there's there's issues there, and this is why companies, specifically this is why companies might offer partial insurance, because partial insurance has a lower moral hazard effect. Because if you're fully insured, you don't care, and so you take no action to avoid the bad outcome, but if you're only half insured, or if you receive half of the value of your car back, well then you're partially insured and partially insured, then you still have incentives to avoid the bad outcome, not as strong as if you are uninsured, but you at least do have some incentives. In the case of things like car crashes, this is not a great example because even though they might make you financially whole, there's additional costs in the case of a car crash, right, physical injury, all that kind of stuff which you don't wanna, don't wanna deal with. Um, moral hazard has significant impacts in things like health insurance. If you have really good health insurance, Naturally, it may be the case that you do less things to look after your health. Whereas if you know that if I, you know, I, I know that if I break my leg, I am I'm gonna die. I'm gonna take a lot of actions to not break my leg. Whereas if I know that a broken leg, you know, I just go to Medicare and I go to the hospital, like it sucks, but you know, it's fine. There's a moral hazard issue there, right, we don't avoid the bad outcome as much. So moral hazard is that taking this insurance or having this insurance has behavioural effects. And that's the thing we have to worry about when you're designing insurance and thinking about insurance, if you're doing actuarial studies, anyone doing actuarial studies, actuarial? None, um, they worry about a lot, right, because it's a thing, it's a problem. Any questions on moral hazard? Questions, concerns, Problems. OK. The other issue, which is a which is still an issue around insurance, but it's an issue around insurance and choice under uncertainty, but it's a different kind of issue is what we call adverse selection. This is, this was really bad, I mean, the US health system is absolute, absolute garbage dumpster fire, it's terrible, but when they, when they went to try to fix this, when we went under Obama in the, I guess mid 2000s. Now, um, went to try and deal with this, adverse selection was a big part of the problem they faced, and they dealt with it through a particular manner. Adverse selection is not that you change your behaviour when you take the insurance, it's that when you look at a population of people, particularly something like health insurance is a good example of this, you look at your population of people, and if you offer everyone the same insurance, which is broadly how you have to do, you can condition it a little bit, but broadly speaking, you offer everyone the same insurance. Then the people who are high risk will take that insurance. And the people who aren't high risk. Won't take the insurance, right, if you have a, if you, if your hidden variables, stuff that you know about you that isn't observable to the insurance companies mean that you're high risk, you're like fantastic, this insurance looks like a great deal for me because I know there's a 30% chance that I'm gonna have a heart attack the next year and the insurance company doesn't know that. And so I take the insurance. Whereas if you're an and the insurance company has built in into their payment structure a 5% chance that you're gonna have a heart attack next year. But if you know that unbeknownst to the insurance company, you actually have a very low chance of a heart attack in the next year, right, you have a 1% chance rather than a 5% chance, you take that you just, you just go, oh, I'm just not gonna take the insurance, it's just not worth it for me. And this isn't, this is what we call adverse selection because what we're seeing is only the people who are high risk take the insurance. And this causes huge problems because if only the high risk people are taking the insurance, Then the insurance company can't make money off the whole package, off the off the insurance they're offering. They're offering insurance saying if the average person takes this, we will make a bit of money. And then they offer it out there and only the high risk people take it and suddenly the insurance company isn't isn't making money. So the insurance company goes, oh, this is terrible, we're gonna have to increase our premiums. But the effect of increasing the premiums is that all of the moderate risk people drop out of the drop out of their pool, because for the moderate risk people it's no longer worth buying the insurance. And so now you have a moderate, you know, you know, a fairly expensive insurance plan that only very, very high risk people are taking and then, you know, like high risk people are taking and then the, the only slightly high risk drop out and as we keep going, the lower risk people are dropping out and dropping out and dropping out, and the premium's getting higher and higher until the entire market collapses. And this is the problem of adverse. Selection The way that the way that the Affordable Care Act in the US deals with this is that they functionally forced you to buy insurance, um, so you were required to buy insurance, um, under this act. The way the Australian government supports private health insurance is that functionally, uh, you're required to buy private health insurance to support the private health insurance industry. Um, I am not personally a fan of this. Medicare is fine, anyway, it doesn't matter. Um, but is adverse selection problem is an issue, this was, there's a, there's a Nobel Prize attached to this by Aillo. For sort of formalising and clearly identifying this, If you go into markets, when a market has adverse selection, that's pretty bad, but there are ways to handle it when a market has moral hazard, that's pretty bad, but there are ways to handle it. When a market has both adverse selection and moral hazard, it's really, really, really bad. And things like health insurance have both moral hazard and adverse selection, and they, they, that's a, it's a very hard thing to deal with when these things are in combination, it's worse than, If, if moral hazard makes things 1 point harder to deal with and adverse selection makes things 1 point harder to deal with, having them both together makes things more than 2 points harder to deal with, right, it's a, it's a cumulative problem. Um, it's it's a sorry, it's a more than cumulative problem. If you have both of these together, um, and they're related to choice under uncertainty, so we get to include them here. Any questions on, and but I wanna, I want to be clear here, these are different things. The mechanism of action is very different for these two things. Moral hazard is when a person buys insurance, their behaviour changes and so their probability changes, adverse selection is a population level issue. It's that only the people who are high risk are taking the, taking the insurance in the first place. Um, applies to health insurance, it applies to any kind of insurance, it applies to. I mean insurance is our main, um, but these things happen in lots of circumstances. Any questions, questions, problems, yes. Right, so the story I told for adverse selection was kind of saying that insurance companies are offering the same policy across the board, and as you say, that's not true, right, that you do offer different policies, um, in some cases you offer different policies in terms of how much, much insurance you take, so in Australia when you go to an insurance company, they'll offer you, You know, 12 different plans that you can take in terms of how much insurance, so, what level of partiality you have of your insurance, um, but especially in the US context, for example, they, they will look at you and go, you are high risk and so we'll offer you an expensive insurance plan, that is also a thing that happens. I'm not sure if that happens in Australia, I honestly don't know, I don't think so, um. But in principle you could, in principle you could say I'm gonna look at you and I realise that you're high risk. The issue is the the the reason why you still have adverse selection, even in that case, is that the insurance company can only see some things about you. The insurance company looks at you and they look at your medical history and they look at all these things about, and they look at you, you know, the behaviour that you have, and they say based on what we can observe, We think you're this risky. The problem is there's lots of things about you that you can't observe, sorry, that they can't observe, that you might know but they don't. Right, they look at you and go, you're a picture of health, and we're gonna give you a, uh, we're gonna give you super cheap insurance and you, you're sitting there going, ha ha, little do you know I'm actually deeply unhealthy, um, and so you take the insurance, even though you might look healthy from the outside. Um, So that's that's that's the idea, right, that there's there's hidden variables known to the person that aren't known to the insurer. If you have the opposite where there's stuff known as the insurer but not the person, then you get the opposite of that. Positive selection, I guess. But that's not practical. Any final questions? Questions, comments, problems. Lovely, in that case, we will finish up here. If you have any issues you can come see me now, else I'll see you all next week where we will talk about choice over time and also the assignment. Thanks. And probably the timing for the mid-semester exam, I would expect. Thanks.
