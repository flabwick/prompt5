SPEAKER 0
This material has been reproduced and communicated to you by or on behalf of the Australian National University, in accordance with Section 113% of the Copyright Act 1968. The material in this communication may be subject to copyright under the Act. Any further reproduction or communication of this material by you must be consistent with the provisions of the Act. Do not reproduce this material. Do not remove this notice.

SPEAKER 1
Alright, about 50. So we will. Yes. Welcome back everyone for lecture 3 now we're on to week 3 for micro 2, where we get to really do something that is completely different than the things we did in Micro 1. Finally, right? This thing so far, 2 good models, we kind of saw a little bit of micro 1, we're not gonna use 2 good models. We we're gonna do something to this week which is different than what we did in Micro 1, and we're gonna talk about choice under uncertainty. Because if you recall back from micro one, we do have some stuff to finish off, but when you go back to micro one, all of our micro one analysis was all about certain certain outcomes, right? Do you want $2 or $3? But lots of economic analysis isn't about certain. And outcomes, lots of economic analysis is, do you want to take this risky option or this other risky option? Do you want to do this action, which has a number of different possible outcomes with different probabilities, or this other action that has this other range of outcomes with this other range of possibility right range of probabilities for those different outcomes. And that's what we're gonna be talking about a bit today. Before we do that, we have some elasticity stuff to finish up from last time, and before we do that, are there any admin things I should talk about at the moment, that anyone can think of? Yes. We will know officially when the midterm will be in the next couple of days. I think examinations will release it in the next, I believe the next couple of days. Um, we're still in some negotiations because there were some, there is some minor issues that the college is talking to the centre, uh, so we should know soon, but I don't have exact dates. I think officially it's week 4, but, but it hopefully, which is, which I guess is in a couple of days, sorry. I would I cannot guarantee, I would strongly expect it'll be on Friday of week 6. But I can't guarantee this. Otherwise, any, oh, and the exam will cover conditional on no conditional on it being on Friday of week 6, it will cover all material up to the exam, right, so week 5 material is covered in week 62, all of that's accessible. The stuff that we do in week 6 will be in principle as accessible, um, because I've had bad things happen if you don't, if you don't do that in the past. But I'll talk more about that once we have a date. Otherwise, any other questions? Concerns, I mean, issues. Lovely. As I said, we need to finish up elasticity, which we'll do mostly pretty quickly, but we will talk about it briefly here. Um, so you recall from my, so we finished, we did, we talked about, you know, own price elasticity of demand, right, um, percentage change in quantities, make a percentage change in price last time, but you can also talk about cross price elasticity of demand, right, elasticity is a really, really general concept because it really is just the percentage change in one thing as you make a percentage change in another thing. And so cross priceity demand is a very common thing we want to care about. If the price of some other good changes, how does that affect demand for the good I'm interested in? Right, the price of pasta changes, how does that affect the quantity of rice that I choose to buy? And this is what cross price elasticity is. Definitionally, we can talk about it in terms of percentage changes. Just as before, we can break this down into the derivative of QX with respect now to the price of good Y times the price of good Y over the quantity of good X. You can also do this in log form. So it's the same as before, it's just instead of the price of the good itself, we talk about the price of the other good. Which might have an impact, it might not have an impact, cross priceity might be about 1, but it might be something completely different than 1, right, could be zero, as we will see. You can also talk about income elasticity of demand, right, how does your demand change as your income changes, and again in percentage terms. If income goes up 10%, how much more of good extra do I buy? And as before, it's the same thing, right, it would just use income instead of instead of something else. Uh, these log forms can be useful sometimes, they're always useful, but they can be useful sometimes. These are definitions we'll talk about a we'll go through a couple of quick examples, but any questions, questions or concerns here definitionally speaking. What about the substitutional. Which what, how would you want, how are you wanting to define substitution elasticity of demand? How are you wanting, how are you wanting to define

SPEAKER 2
that? Uh, they see that one of one person changing one product. To change in price of those. So.

SPEAKER 1
Oh sure, so in the tutorial question there were some optional ones right at the end there, right? Um, yeah, which, which were actually meant to be taken out, um, but I forgot to take them out. Um, so, so one of those was, uh, as the price ratio changes, was what the was what the question was in that one. And so for that you could talk about the price ratio elasticity of demand, and so you might have the um, How demand changes. As the price ratio changes. So keeping income fixed but allowing the price ratio to change, and what what change happens in demand in that context, um, times. PX over PY. Over QX, that would be an example of a way to talk about that. So the idea is that electricity is a super general concept, it's just. Senator change something As we make some changes something else. OK, so we can do some, do some examples quickly, we're working with a specific utility function here, so a specific demand function I should say, which is that, We, our demand for good X is such that we spend 40% of our income on good X. Our demand for good Y is such that we spend 60% of our income on good Y. That's what, that's what these things here are saying. Um, quantity of good X is 0.4 times I divided by the price of good X means that PX times QX our expenditure on good X is 0.4 I, right, it's 40% of our income. Similarly, our expenditure on good Y is 60% of our income, and we want to calculate elasticities at these points, right, and talk about how price changes have an effect. So for the own price elasticity, which I think we ask for first. We go through and we say well own price electricity is this is is the elasticity here, which is the derivative times PX over QX. We need to know that derivative QX over PX to work this out, and so that derivative is gonna be, what's the derivative in PX? Of 0.4 I. Times PX to the -1, times 1 over PX, right, but taking derivatives to the -1 makes this look a little bit easier. We take a derivative, right, 0.4 is a number, so it's just a a scale of multiple I income, because we're talking about partial differentiation, I is treated as a, as a number, it's just a fixed number, and so we treat it the same way that we do 0.4. It's just a scale of multiple. And then we have PX, the variable of interest to the power of -1, and so we pull the -1 down and we subtract one from the power, and we get -0.4 IPX to the minus 2. Which if you like, Looks like this. I feel like I'm too loud, I feel like there's reverberation, am I being too loud if I too, am I too loud, or is it fine? Nope. So we have the derivative now, we know that it's minus 0.4 I over PX. I was gonna say PX times PX cos it's PX squared. I have a reason why I'm wearing it like that, but this is fine. And then we multiply that by PX over QX. When we talk about these things, we don't really want QX floating around, we want our our um our elasticity to be in terms of fundamental objects, not choice objects, right? QX is the amount we choose to consume, um, it's not great to have that, have our, have our final outcomes in terms of things we're choosing, we want our final outcomes in terms of the things we are stuck with, our independent variables, so in terms of prices. So let's take that QX and make it 0.4 I. PX to the minus one. Guess what QX is? It concerns problems, And this is super nice because tonnes of stuff disappears really quickly and easily here, because the 0.4 cancels with the 0.4. The I cancels with the I, the PX cancels with the PX. PX PX times 1 over PX is just one, so these things cancel out. And so literally everything's cancelled here. Except The -1 out the front. And soliticity is lovely, it's just -1. If price goes up by 10%, then we consume 10% fewer goods. And that's gonna be true whether we start off at price of 23 100, or whether we start at price of 43 100, doesn't matter for this particular utility function, the elasticity is always the same. This is an example of a constant elasticity of demand function. Um, because our demand here has constant necessity, it's always -1. Any questions? Questions, concerns? Partly our intuition for this should be OK, because if we're spending 40% of our income on good X, Always, which is what our demand function says, if the price of Good X goes up by 10%, we want to keep spending 40% of our income on good X, the only way we can do that is if we buy 10% less of it. Um, and so it does actually it does, you know, work out nicely in that regard. Right. And that's the 1st 2 of these. Any questions, problems? Cool, we can do cross price elasticity, right? How does our demand for X change the price of good Y changes, and this is even easier, right, because the elasticity of good X as the price of good Y changes is how much. This changes times the price of Y. Over the quantity of X. So our measurement of how fast our demand for good X changes, the price of good Y changes, any takers on what this number's gonna be, we can write the answer down straight away. When this is our demand for good X. Someone's whispering it, there's a couple of little whispers around, the whispers are right, someone who's whispering it can say it louder for me. That was a tiny bit louder, but it was still pretty quiet. Yeah, it's 0, there is no effect, right, um, because the derivative as we change, How much, how does our demand change as we change the price of good Y? Well, it doesn't, right, so a partial derivative 0.4 is a number, I is a number, PX is a number. This is a derivative of some number with respect to the price of good Y, there's there's, there's no change, this doesn't change as the price of good Y changes, um, and so the elasticity is just. Zero here, which again shouldn't be super surprising from our intuition perspective, if our demand function is spend 40% of our income on good X. Right, on, on rice, and when the price of pasta changes, well that has no effect on how much rice we buy because we spend 40% of our income on with rice and rice still costs $1 per kilo, so we're just gonna keep buying the same amount of rice when the price of pasta changes. So I crossed by the system here, yes. is the The For perfect compliments, no, no, but the idea is good. Um, if the price. But no, the idea is good. The issue is, it could be the case that one good is extremely expensive and it's a huge portion of your expenditure and one good is very cheap and it's a small portion. Same as in the, in the tutorial question, for example, right? Um, and if the cheap, if the, if the, if the very cheap good becomes 100% more expensive, that's quite a small change in the cost of the of the whole bundle, whereas if the cost of the expensive good goes up by 100%, that's a big change in the cost of the bundle. Um, so the idea is good, but it's not quite right. Yeah, OK. And you can see that in the coffee example, if you go and do the numbers for the coffee example, you get, uh, you would get elasticities for coffee of of nearly 1, and you'll get elasticities of um sugar as nearly zero. the same OK. I wasn't sure if that was Yeah, yeah. OK good. OK, otherwise, any questions? Cool. And of course we can talk about income elasticity, right, how does our demand change with income, and it's the same, same here. I've actually got Q of Y here, so let's do it in Q of Y as we change income, elasticity of QY, income elasticity of, of rice, our pasta good if you like, um. Well, the derivative here with respect to I is just 0.6 divided by the price of good Y. Income is income, quantity of good Y is 0.6 I, times the price of good Y to the -1. Just by working through the derivatives and subbing in the value for Q as as whatever it is, and again we go through, and a bunch of stuff. Cancels. Everything cancels. And so our income in the city is one, again, not super surprising. From our intuition perspective, because we spend 60% of our income on good wine, if our income goes up 10%, we should therefore be spending, but be buying 10% more of good wine. None of these, none of these amounts are super surprising given the intuition, but they do accord with what we expect, which is, which is good. These, these demand functions I should be careful saying this, but these demand functions are very standard kinds of demand functions, um, for real world applications, because we normally assume Cobb Douglas utility, and these are the kinds of demand functions you get from Cobb Douglas utility. Right, so when you use Cobb Douglas, these are the kinds of things you're really sort of assuming in the background. That's really all we have for, for the elasticity, any quick final questions? It's calculation, we talked about it conceptually. The good Excellent. So today, today we're talking about uncertainty, right, the actual important thing for today. Um, so as I said before, all of our analysis in micro one, all of our analysis so far here, we've had certain outcomes. We've had, do you want $2 or $3? Do you want 1 apple and 2 bananas or 2 apples and 1 banana? Whether the questions are easy or hard, that's, you know, these are the kinds of things we're working with. But lots of lots of real world economic choices include uncertainty. We don't know the outcome we're gonna get from some action. We get some, we, we take an action and it produces a gamble which produces an uncertain outcome, right, so we might have a gamble that means we get $2 for sure, we might have some other gamble that means we have a 3-quarter chance of getting $3 and a 1 quarter chance of getting nothing. Right, that would be a gamble that would that we could ask about. Right, in the real world we're talking about should I buy insurance? Right, because we buy insurance, and if we need to use insurance, it was a good thing to buy have bought the insurance, and if we don't need to use insurance, then it was a bad thing to have bought the insurance, right, so we have to look at two gambles, no insurance. Which gives us really bad outcomes, something bad happens versus being insured, which gives us sort of roughly equally, roughly equally kind of slightly less good outcomes regardless of whether the bad thing happens or or or not. Right, stock prices, they can go up, they can go down. You might think there's a, you know, 20% chance it goes up, 30% chance it goes down, and maybe it stays the same, or whatever, lottery tickets, right, there's uncertainty built into lots of choices. We're gonna have, we're gonna mostly for our purposes today, be working with utility over money, but there's no special reason you have to be restricted to that, you can talk about this over generic actions and generic outcomes. We're gonna talk about money because it's a bit easier, and we can talk about a few extra things. When we talk about probability, there's two ways of thinking about probability. There's a there's a frequentist kind of idea of objective probability over the on 51% of days in the last year, the stock market has gone up. Right, this is a frequentist objective probability. I roll a dice and there is a 16th chance that I get a 6. Frequentist objective probability. We can also talk about probability in terms of a subjective probability. Tomorrow, I believe there is a 51% chance the stock market will go up, which is a different kind of statement. It's really a statement about degree of belief rather than a statement about objective reality. Um, For most of our purposes, it's not really gonna matter, because if you if you if you subjectively but truly believe that there's a 51% chance that the stock market will go up tomorrow. Then you're gonna act as though there is a 51% chance, and so if we're talking about explaining human behaviour, degree of belief is just, is, is more or less, more or less, just as good as frequent to subjective probabilities. So we're mostly gonna think about this in terms of, um, we're we're gonna conflate these a lot for our purposes, for for for for this class at least. Um, so it's not really gonna matter whether we're thinking about statistical probability or degree of belief probability, um, we're gonna treat them the same way. OK, any questions so far, questions, concerns? Yes.

SPEAKER 3
Objective Yeah, but you'd have to do it Are we then just gonna look at the case, well, we'd like to know. It's unknown.

SPEAKER 1
We're not so, so we're not gonna deal with situations where information is unknown, we're not gonna deal with with difficulties like that. Um, certainly economic analysis does when we talk about ambiguity aversion and and attitudes towards ambiguity, and multiple priors and all that kind of stuff, there's a whole lot of behavioural literature to deal with that. We're not gonna do that because this is a 2 year course where we have 1 week to spend on uncertainty. If it was a 3rd year course and we had a semester to do it, then we'd do all those things. We're not gonna do those things. Um, OK. I need you guys to make choices for me, just just by hands up choices. So which of the, you have two options for gambles, you can take action A or action B. Action A gives you $2. For sure, I'm not gonna actually do this. I have in the past, I should have brought money, bear in mind. Action A gives you $2 for sure. Action B gives you a 3/4 chance of $3 and a 1 quarter chance of receiving 10 cents. Take a moment to consider your choices. Who goes for option A, Action A. Most people. That's annoying, option B. OK, no, that's about half half. That's OK. Option A and B, about half half. That's, that's hopefully still fine. Hopefully. Get rid of options A and B. Right, now focus on C and D. You can take action C. Action C gives you $20 million 100% chance. Option D gives you a dice roll on a you have a 3/4 chance of $30 million. And a 1/4 chance of 10 cents. Take a moment to consider your options. Who takes the 20 million for sure? Who takes the gamble for 10 cents? OK, good, so we do have. I'm gonna call this almost all, so I think that was fair and a couple of people. These people are insane, but that's OK. So, there's a reason we did all that, right, and part of the and and you can hopefully see the reason is that all we've really done is scaled up the numbers. I mean they didn't scale up the 10 cents, but it's 10 cents. Right, all we've really done is scale up the numbers, but a lot of people did change their, did did change their behaviour, right? A lot of people chose, uh, chose B over A, but also chose C over D, which is sort of flipping of preferences in a, in a, in a, in a certain sense. Um, And so that's a little odd, but let's investigate further. So one way that we might think about the value of a gamble is expected value, right, the weighted average of the possible outcomes. And so if we have a 50% chance of $2 and a 50% chance of $3 then our weighted average is, you know, a half chance of getting $2 and a half chance of getting $3. I'm not even gonna ask you for this one, is $2.50. Shocking, this is our expected value of this gamble. We can take more complicated things, right, we could have more options, a 30% chance of $10 a 50% chance of $12 and a 20% chance of $20 and again it's just, you know, a 30% chance of $10. And a 50% chance of $12. And a 20% chance of $20 and we add these up and we get $13. And this is fine, right, this is our way that we might think about analysing the value of gambles, right, is the expected value. Uh, you'll notice, as in your stats courses, for those of you that have done any level of stats courses, the expected value, the thing that we call the expected value is different than the value you expect to get. Right, in the second one here, you can, you have, there's some certainly some notion that the expected value is $12 but then the expected value is $13. Um, so it's a bit of the, the, the nomenclature is frustrating and annoying. Expected value refers to the mean. Right, it's the expected mean, rather than the mode or the median or something like that, so it's not the most likely outcome it's not the middle outcome, it's the mean outcome, which is annoying, but, This is the Navy convention, we're stuck with it. Um, so this is our expected value, questions, concerns. Comments, lovely. OK. The problem is that for those people who picked B over A but then also picked C over D, their stated preferences are not consistent with maximising expected value. In fact, in anyone who picked, in fact, for everyone, for everyone except those couple of people who picked D over C because they're crazy, um, the choices that were made were not consistent with the expected value. And we can see that pretty easily, right, most people chose C over D, but the value of C, expected value of C. I should say. The expected value. Of Gamble C was $20 million cause you got that for sure, whereas the expected value of D was $22.5 million because it was a it was roughly $22.5 million it was a three quarters chance of $30 million. Which is $22.5 million. So if you were just caring about your expected value, you are much better off choosing you were better off by $2.5 million choosing D, which is a lot better off, right? So whatever it is that people are using to make the decisions, whatever it is that you all use to make your decisions, it's not just expected value. Right, we can't just say what is the expected value, work that out, people choose the higher one. That's not that's not what people chose. It also can't just be people hate risk. Risk is bad and we don't like risk, because a lot of you, about half of you chose A over chose chose B over A. About half of you for the low numbers, about half of people chose B over A even though B does come with some risk. Right, so there has to be something going on, there's something else happening here, um, and we need to sort of figure out. What else is happening here, um, I suspect I kind of do know what else is happening here. Um, but we'll talk about how we're gonna do it in economics. Questions, so we can't just do, sorry, we can't just do expected value, we can't just do avoid risk at all costs. We're gonna have to get something that that balances those two issues. Questions, questions, concerns. Problems. OK. Cool. So one thing that is going to come up is what we call the certainty equivalent, and so our gamble Dee was this gamble here, most people took $20 million instead of the gamble. But there's clearly some amount of money that would make you indifferent between having that much money and having the gamble. Right, and for most of you, for almost all of you, 20 million wasn't enough. But what if I said 20, what if I said, um, yeah, $20 million wasn't enough. What if I said 29? No, that would be the other way, 20 million was too much because people took $20 million people took $20 million.20 million. What if I said $10 million? Or this gambled. Right, 20 million, you take 3 million, but what if it was 10 million versus this gamble, who takes the 10 million? Yeah, less, but that's still a lot of people. What if it was 1 million or this gamble Dee, who takes the 1 million? A couple of people, not heaps, but a couple. As you can see for each person that M is gonna be different, but for each person there's gonna be some level where you're where you are indifferent between that amount of money M and this gamble, right? For a lot of you it was somewhere between that 1 and 10 million level. And this, this amount of money, whatever it is for each individual person is called the certainty equivalent, certain equivalent of some gamble, it's the amount of money that would make you indifferent between the gamble and the money. And again, for most of us here, it was somewhere between 1 and 10 million. Some people were higher, some people was lower. But of course there's no special reason to think that this certainty equivalent, the thing that makes you indifferent is the expected value. It might be for some people, but it might not be for other people. And that's fine, right, different people have different preferences. Not too bad. Any questions, questions, problems. We're gonna do some graphing or some stuff soon. OK, cool. So the way that we're gonna work this problem out is we're gonna work this out using what we call rather than expected value, using expected utility. And so we have our utility, we have a utility function, utility function says for each level of wealth, how much utility do I gain from that wealth. So UW is the utility gained from having wealth W. Different wealth levels give different utility levels, and we can talk about the expected utility of some gamble. Uh, it's the weighted average of the utilities of the possible outcomes as opposed to the weighted average of the values of the possible outcomes. So if we go at our, go to our, our options C and D example, we can have wealth, we can have utility that we actually get from that wealth. This is gonna be our, our you function, I'm just drawing this as a line of some sort. Here I've drawn the line that will give us some, some help here, but that's OK. And our options were get $20 million for sure. That was one possibility, but actually no I want to focus on the other possibility, um. There was an option that where we got $30 million. With a 3/5 chance and we've got essentially no money with the other chance, we'll just, the 10 cents will call $0 because it's easier. So this is our utility of $30 million just reading off the graph. If we have a 3-quarter chance of getting, if we have a 1 quarter chance of getting 0, and a 3-quarter chance of getting $30 million well then our expected utility is going to essentially be the 3-quarter chance of getting, $30 million right, that's gonna be the utility that we would, that's gonna be our expected utility from the gamble. Doing this in a slightly strange order, which is why I'm just like making sure everything works here. That's gonna be our expected utility from the gamble, plus the utility we get from, from nothing, but that's from 10 cents, but we're just gonna say that's nothing. We worked out the expected value. This was the expected value of our gamble. Was 22.5 million. We're 3/4 of the way between 0 and 30 million. We're 3/4 of the way. Here as well. Who, oh yeah. Ah. That's why we can do this, we can do this sort of object here. I hope Yeah, yep, we're good. We have our expected value, we have our expected utility on this graph. Yeah. Any questions, concerns? Problems. OK. Same distance along, same proportion of the distance along. We can talk about this graph is efficient now for us to be able to talk about, I go back, certainty equivalent. Certainty equivalent is the amount of money I'd have to give you to make you indifferent between the amount of money and the gamble. This is the expected. This is our expected utility of the gamble, this is essentially how much happiness we derive from the gamble. If I give you 22.5 million, I've given you too much money. Right, because if I give you 23.5 million, that's point, if I give you 23.5 million, the utility you gain with for for sure, the utility you gain from that is way up here somewhere. Right, if I give you 20 million, I've given you too much money. Because the utility you'd gained from that. He's he's up here somewhere. It's too high. So the amount of money that will make you indifferent between that amount of money for sure and this gamble Dee is gonna have to be, This amount of money, whatever this is, call this, you know. Z amount of money. So if I give you Z dollars for sure, then the utility you get from that is. We look at the utility we gain from getting Z dollars for sure, and we see that utility from Z dollars is the same as the expected utility from that gamble. So this is what we, so, you know, I'm gonna stop calling it Z. And I'm gonna start calling it The certainty equivalent. A certainty equivalent of that gambled, of that gamble that was 30 million, maybe 30 million, but maybe not. And it's on the way I've drawn this, it's some amount less than $20 million. It's $18 million with the way this graph's been drawn, this particular utility function's been drawn. So we've got a whole bunch of things going on. Because we're talking about the expected expected utility of the gamble, certainty equivalent of the gamble, the expected value of the gamble, we get, we can get all these things on there, on the, on the one graph. We can get some, you know, we can pull information out of this. Questions, questions, problems. There is one more thing to add onto this graph but it makes things, starts making things really messy, but I will add it, but any questions before I add that last thing onto the graph? OK, the last thing to add on to these graphs, on that we can add on to this graph is the, the utility of the expected value of the gamble. Right, so we can talk about if we were to get the expected value of the gamble, how much, how much utility would we have gotten from that, and that's, well that's the expected value, this is the expected, Value of the gamble, and we just draw up to the utility line and then along. So we draw up to the utility line, and then along, and that's gonna be the expected, the utility of the expected value of the gamble. And so you get pretty natural things like the utility of the expected value of the gamble is higher than the expected utility of the gamble. If the certainty equivalent is less than the expected value. These are the things you would normally expect to see, not for everyone, not always, the things you would normally expect to see in a lot of cases. We have more to talk about, any questions? This graph is complete now, I believe. Yes. I can use, I was actually gonna use this, this for this graph, but we've done it, done it for this now. Any questions, concerns? Yes. Yeah, because there are a lot of things and they sound like they're very similar, right, because we talk about the utility of the expected value of the gamble versus the expected utility of the gamble, um. So utilities are to value the gamble versus. The expected utility. Of the gamble, the difference is where you apply the is is is when you apply the um, the probability and where you when you apply the utility function. So the utility of the expected value of the gamble, Is we first work out the likelihood of, so probability of outcome one times the, the, I guess value of outcome one, plus the probability of outcome two times the value of outcome two, that's detected value, and then you apply the utility to all of that. Whereas the expected utility of the gamble is we look at the the the likelihood of getting the utility that we get from outcome one. Plus the likelihood of getting the utility that we get from Outcome 2. So the main thing we care about is expected utility because we're either gonna be in the world where we have $30 million and we're gonna experience that world and get some sort of utility from that world, or we're gonna be in the world where we have, no, where we have 10 cents, and we're gonna experience the utility of that. And so what we really are talking about is having different probabilities of being in that $30 million world and how happy that makes us versus the probability of being in the $0 world and how happy that makes us. It's not really interesting in most cases, most cases to talk about the utility of the expected value, cause it doesn't come up, it's not like we get the expected value and then we experience it, right, we experience the world. As the world ends up being with different probabilities. So, excellent. It's a good question, it's a good way of asking that question, thank you. Any other questions? So for generic world, oh sorry, yep. Are There are, and we'll talk about them. So the question was, are there other ways the utility function could look? The answer is yes. It's in like two slides. OK. So for for generic utility, whatever, and working these things out, the graph is handy, um, when you have specific values, it can just be fine though as well to just plug in the numbers, and that's completely fine. Right, we have X being a 50 cents of $2 and a 50 50% chance of $3. We have our utility is the square root of the amount of money that we get, and so the expected utility, well there's a 50% chance that we experience, we that we receive the utility of the experience of having $2. And there's a 50% chance that we have the, We get the experience of receiving $3. And so a half Route 2 plus a half route 3 is, That amount. About 1.7, 1.57. That number doesn't really mean a whole lot because it's in mutuals, which is kind of a weird measurement of, of things, um, so if we wanna really ground, like that 1.5 is, that 1.5 eels can't be compared to $2 because 1.5 is number of eels and 2 is number of dollars, and so we just can't compare those. To make our comparison more meaningful, we want the amount of money that is equivalent to X, so we want to find the amount of money M. So that the utility of M is that 1.57. Right, so how much money would we need to make us indifferent between that money and this gamble, and that'll give us a more reasonable outcome, right, and it's gonna be, we would expect it to be something about 2.5, probably a little bit less than 2.5, um, and if we go through and do this right, so this is saying that um the square root of M should be 1.57, which is M should be 1.57 squared, which is, About 2.47, right, $22 a little less than $2.5 which is what we would have expected, right, because we're a little bit, and we'll come to this a little bit risk averse, we don't really like risk, and so to take that risk we have to pay, we, we have, we would be willing to pay 3 cents to avoid the gamble, broadly speaking. Sorry, yeah, 33 cents to avoid the gamble. This is fine, we can do this more complicated objects, the expected utility of this big long thing, option Y, and we can work out the expected utility is, Just 0.3, Route 10, 0.5 route 12, etc. um, and then the interesting thing is the amount of money that is equivalent to this gamble Y, the certainty equivalent of good Y, and again we're looking for the amount of money so that uh route M is that 3.58. Which is to say M is 3.58 squared, which gives us $12.78. And this is again a little less than the expected value. So if this person here, the certainty equivalents are a little less than the expected value. For this person here, our certainty equivalents are a little less than the expected value, recall the expected value of Y. It was $13. The expected value Of X is clearly $2. And so these outcomes coincide with what our what we showed in the graph earlier on our earlier graph. The certainty equivalent was a little less than the expected value. And these numbers work the same way, which is always nice. Questions, concerns, problems. Alright, so we've done all this work to introduce this idea of expected expected utility and how it works and what it looks like, um, and so we would really, really hope that our previously stated preferences are actually consistent with that, because we've done a lot of work here and if we've done a lot of work and developed all this theory and didn't explain our preferences, that would be kind of annoying. Uh, but obviously it does, right, otherwise I wouldn't have done all this work. Um, so I'll say the preferences from earlier, particularly D over uh the the people who, who flipped their preferences, that's consistent with with expected um expected utility. So if we, if we take a particular utility functional form of log utility, which is empirically for large amounts of money, seems to be pretty close to the way the utility function that people actually have. I'm couching a lot of ifs and a lot of sort ofs around that for a reason, but empirically when you go when you test people for large amounts of money, like for in the millions of dollars, this seems to be pretty close to what it actually is. What the log means is that if you double your money, you become X units happier. Right, and so if you double your money again, you still become X units happier. Double again you got. The impact of that is that the marginal value of wealth, the marginal utility of wealth gets small fast, right, if you have a million dollars, an extra million dollars is really, really good. If you have a billion dollars, an extra million dollars is nothing, right, it makes no difference at all. And that's what this log utility does for us. But if we go through and we work out right, you go A, we got $2 for sure, log 2 is 0.69. B, we had a three quarter chance of $3 and a 1 quarter chance of 10 cents, we go through and do the numbers, we get 0.25. A is better than B, and most and and a lot, a lot of people certainly chose A over B. Is this right? Yeah. Um, I actually want those to be Something strange has happened there. Let's focus on the second part, I'll review that and come back to you next week, like on Friday, because that's a bit, something strange happen there. Anyway, um, for the second part, we get the thing that we expect. The diminishing value of money, um, means that that extra $10 million from $20 million to $30 million isn't that worthwhile, right, it's nice, but it's not that worthwhile. Um, and so you're much better off choosing C over D. C gives you 16.8 oodles, D gives you only 12.3 oodles, um, because the extra 10 million doesn't do all that much compared to the one quarter chance of having nothing. Um, and so that's what we see here, right, so we with the expected utility, we get to rationalise that observed behaviour, that behaviour of people choosing C over D, even though they might have also chosen B over A, although we haven't quite got that here, but we can rationalise it. A bit annoying. Questions, questions, concerns. Before we take questions and concerns. Comparisons are pros and cons. Cause there are pros and there are because there are cons to this expected utility framework, right, the expected value is clearly much more streamlined. Right, there's a, there's no weird extra utility function, which isn't really unique anyway, as we talked about in previous weeks, and which varies between and which definitely is different for different people, right, some people might have a log shaped utility, but some other people might have a, Square root shaped utility and some other people might have a linear utility and it depends on the people, and that's kind of a bad, that's kind of a bad thing, right? So EV is much more streamlined, the downside of expected value is it's way too restrictive. There's a whole bunch of observed behaviour including what we saw in class today, which is just not rationalizable using expected value. So it's, it's. Way too restrictive. The problem with expected utility is that almost always is, right, is that much more observed behaviour can be rationalised, but it also means that our predictive, more our predictive um use of it is not as strong because my, even if you can, even if you really carefully measure my utility function, your utility function could be completely different. And so just knowing how I behave doesn't necessarily give me a whole lot of insight into how you're gonna behave. Um, and so this is a bit of an annoyance, right? OK, this is a I I certainly a downside is that it's much less constrained but it's maybe too unconstrained, maybe. Right, there are still things that it can't do but can't rationalise, but more observed behaviour is rationalizable. Um, if you talk to economists, economists will always use expected utility. Right, if you go to an economist and say the expected value for an individual decision is this, they'll go, OK, we don't care, we care about expected utility. If you're talking about like, Government projects, expected value can be useful, certainly, but for individual decision making, expected utility is the thing that we use. Questions, concerns. Almost like today, I think, I'm gonna skip the last one I was today. There are lots of other things out there that aren't expected utility that other people use. If you go to finance people, they use an entirely different system for risk. I'm not a finance person, so if this is wrong, that's fine. This is like one of the ways you can talk about risk reward, right, so finance some some people some people. Finance will use this kind of system of um maximise the expected value subject to the variance, so the risk level not being too high. Sometimes you'll talk about the expected maximising the expected value minus variance in some or standardation in some sort of way, um. And that's fine, that's what they do, and it's fine, but it's not what we're interested in, it's not what we're gonna do, right? There's some overlap, what we do, but it is different. If you go in and say, and use this kind of logic or the expected value minus variance kind of logic, it's not gonna fly with us cos it's not the way economists work with risk. It's fine, it's just a different thing. If you go and do a bunch of behavioural economics, um, you can talk about a whole bunch of other things, right, you talk about rank dependent utility, we can talk about multiple priors as we're talking about, so Maximin utility, alpha max, there's a whole bunch of stuff you can do there, um, so, you know, there are other things, this isn't the only thing that's out there. We're nearly done, we're not, we're not done, but it's the thing, the thing that we're going to be doing is expected utility, even though there is all this other stuff out there and I'm very happy if you go look at those things, we're just not gonna work with them, we're gonna work with expected utility because this is, again, we have a week. Um, I was hoping, I was, I said I was gonna talk about your questions about shapes of indifference, shapes of utility curves. We didn't have time, we will talk about it first next time. As the preface to it, as the sort of the, the intro, um, it's gonna make a difference in terms of whether we think of you as being risk averse or risk loving or risk neutral, right, and different shapes will have different implications in that sense. That's all we have time for, if you have any issues, you can come and see me now, otherwise I'll see you all on Friday. Thanks.
