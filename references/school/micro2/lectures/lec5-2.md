SPEAKER 0
This material has been reproduced and communicated to you by or on behalf of the Australian National University, in accordance with Section 113% of the Copyright Act 1968. The material in this communication may be subject to copyright under the Act. Any further reproduction or communication of this material by you must be consistent with the provisions of the Act. Do not reproduce this material. Do not remove this notice.

SPEAKER 1
Alright, about 50, so we will get started. Welcome back everyone to the first day of autumn. Um, it's raining, it's cold. We're here. Um, good, well, well done on managing to get in through the rain. Um, today we're gonna be continuing our discussion on game theory. Uh, so we got to where we got to where we got up to last time was that the big nice thing for Nash equilibria that we said that we claimed that we claimed the micro one and we claimed last uh on Wednesday as well, was that these things always exist. And then we found some Nash equilibria for the prison's dilemma where you get a unique, where you get a unique Nash equilibria, which is interesting cos it's not Pareto optimal. Um, you get a battle of the sexes kind of game, which is interesting because you get multiple equilibria, and then we talked about the matching pennies game, which is our, our direct competition game, um, where there's no Nash equilibria, and that's kind of a bad sign because our whole thing of why we thought Nash equilibria were good was because they always existed. And so, why are there any, what happened, what's going on? And the issue is that we're, we're not being sufficiently rich with what we're allowing people to do. Pure strategies are not gonna be sufficient. We're gonna need to talk about mixed strategies, so where we can randomise over our actions. randomising over our actions does not mean behaving completely at random. It's we do action A with probability 40% and action B with probability 60%, right? So we allow, we allow weighted, weighted probabilities on these things. And so as it says here, run a mixed strategy and and allowing extending our ideas to allow for mixed strategies is what's gonna give us that um guarantee of existence. I'm not gonna prove the guarantee of existence, it's an interesting little proof that he that that was done, um, but it's not something that we're gonna do here, um. So mixed strategy equilibria. So a mixed strategy is a probability distribution over the actions of the player. And so the mixed strategy isn't just I do action top, it's I do top with 30%, middle with 40%, bottom with 30%. Um, when we talk about mixed strategies, we, a, a kind of mixed strategies are pure strategies, right, so we would still, if within the, the broad idea of what is a mixed strategy, the strategy that says I do top 100% of the time and everything else 0%, we, we still call that a type of mixed strategy, just for, for. Ease of discussion. Um, a mixed strategy profile is in a collection, um, is in a collection of strategies, which is one mixed strategy for each player other than one pure strategy. And the payoff for a given strategy profile is the probability weighted average of their payoffs, so it's the, it's the likelihood of a particular outcome happening. Overall outcome happening times the payoff you get and you sum that overall the possible outcomes that can happen. So if I, well, and we'll see this as an, we'll see this in examples in a second. And of course, we talk about a Nash equilibrium if each player is maximising their payoff, given the strategies, the mixed strategies of all of the other players. So it's the same concept, it's just rather than focusing on pure strategies, we allow for mixed strategies, we allow for people to do something with 40% chance and something else with 60% chance. And just pay off becomes something we have to have a bit more work to get. Yes, we'll start here first. Any questions, problems, yes. Can try pure strategy? So a a pure a pure strategy is what we've always been talking about. A pure strategy is we, we, we do an action with, with, do I have a, do I have a block here? A pure strategy is player one place top, right? But the pure strategy player one place top is the same thing as the mixed strategy of player one place top with a 100% chance, and C with 0% chance and B with 0% chance. Um, and we still call that a we I, I know it's not strictly a mixed strategy, right, the mix, there's no mixing, but we still call it a mixed strategy to just for our ease of discussion. OK. Excellent. And so we're gonna extend our world now to mixed strategies, not merely pure ones, which does give us a lot more power, but also puts a lot more, requires a bit more work. Ah, so consider our match in Penneys game. I'm gonna describe this cause I find it easier to describe this as a penalty shootout game. You have a goalie who is trying, you, you have end of the soccer match, um, there's a tie, they do a penalty shootout, um, you have a striker who's shooting at the goal and trying to score, and a goalie who's trying to stop them, and the goalie wants to jump in the same direction the striker strikes, and the striker wants to strike in the opposite direction to where the goalie's jumping. Um, so it's, it's a match in Penny's game, right, one side wants to match and one side wants to not match. Um, it's functionally in the, in the, in the real world, these games are functionally um simultaneous, right, the goalie has to jump before they can see what the striker decides to do, has decided to do, the striker has to shoot before they see what the goalie's decided to do, right? So it is functionally symmetric. So, functionally simultaneous. Um, And so if we have this kind of game, we solved this just before, solved this on Wednesday, there were no Nash equilibria in pure strategies. If you were the goalie here, or the striker I guess really, but if you were the goalie here, what do you think would be a good thing to do? If you're allowed for mixed, yep. Yeah, you, you want to randomise, right? So if you're the goalie and you're always jumping east, you're screwed because then the striker will always strike west and you get nothing, right, if you're always jumping west, then you're screwed because the striker will always strike east, and similarly for the striker, right, the goalie will always will always go in the right direction. So intuitively you wanna, you wanna randomise. Going a little bit further than just saying randomise, we also want to say that you want to randomise equally. Because if there was any asymmetry in how often you go in some particular direction, right, if you go in, if you jump west, if you as the goalie jumped west a little more often. Then the striker can always should ultimately always strike east and win most of the time. Right, so if you go if you're, if the goalie's jumping west a bit more often, the striker can win most of the time by by by striking east. If the goalie's jumping east, most of the time, the striker can then win most of the time by striking west every, by striking west continuously. Um, it's only, it's really it's only in this particular instance, intuitively, only if you're perfectly randomised, if you're evenly randomising, going east and west half the time each, that there's no way for the striker to, to exploit that fact and, And win most of the time. That's our intuition, which we want to try and formalise, yes.

SPEAKER 2
Why does it matter to randomise if they're going simultaneously, because if, for example, the goalie was deciding only going west all the time and the striker is 50/50 between one and the other, you'll still get uh 50% saves one way or the other.

SPEAKER 1
You will, but if we're talking about, so the, the, the question was if the functionally, I may have gotten the the the the wording wrong, but if the goalie's always jumping east and the striker's going 50%, H In terms of outcomes, you're exactly right. In terms of the outcome of this, you're exactly right that the that they both win half the time. From an equilibrium perspective though, this is, is quite a different issue, right, because there's big incentives here for the striker to change their action, right, if this was the case, then the striker should, um. Should shoot west every time, and would improve it so, so, so you're right in terms of outcome, you're not right in terms of incentives. That makes sense, but yeah, excellent. don't anyway. Any questions? Otherwise. So let's try and formalise this at least, at least a little bit, right, not necessarily heaps, but like a little, um, and so we'll plop down some, we'll say probabilities, right, we'll say, how do I do this, yeah, yeah. Um, The striker is gonna shoot east with some probability P. And therefore is gonna shoot west with some probability 1 minus P. I had this little way around, but it won't matter. Um, If that's the case, yeah. If that's the case, what does the goalie want to do? Right, so from the goal, we're looking now from the goalie's perspective. So what happens if Case number 1. What happens if P is greater than a 1/2? What happens if the striker is most, as we as we sort of argued just before, what happens if the striker is mostly going east? Right, striker is mostly actually I don't want to quite put it this way, I wanna do a slightly differently than this. I wanna look at the goalie's perspective, and I wanna look at the utility for the goalie for the goalie can go, yeah, for going east. Conditional on whatever the striker is doing, right, what's the utility for the goalie, conditional on what the striker is doing. The track goes east the probability P where's the probability 1 minus B. So we're going, we're going east with probability P. We end up here and we get a utel. With probability 1 minus P. We end up here, and we get -1 nele. -1 value to us. And so this is P minus. 1 plus P2P minus 1. Concerns, problems. If this is a problem, let me know because we need to discuss this if this is a problem. Amazing, excellent. Then we jump ahead, right, utility for the goalie of going west. Conditional on how what the what the what the other person is doing, what the goalie's doing, well, with probability P we live down here and get minus 1 nele, we lose. And with probability 1 minus P, we live here. And we win. You know, our usual. So minus P plus 1 minus P, which is, One. And so my utilities can go in different directions, if I jump east, I get 2 p minus 1 neutels, and if I jump west, I get 1 neutel, for sure, well. It seems too high, doesn't it? What have I done wrong? Oh, heat in the 2nd 1, yeah. Yes, I missed a, I, I dropped a minus sign. Thank you. 1 minus 2 p.m., like 1 seems way too high. That looks better. And so the question for what the goalie wants to do is, Is 2P minus 1. Bigger And 1 minus 2%. Like that's our utility from. Utility for going east. Utility from going west. And we can Muck about to try and solve this, right, uh, we'll add 2 P to both sides. We'll add one to both sides. We'll divide by 2. What about 4, sorry. So going east is the right thing to do, is the optimal thing to do if P is bigger than half. We did the maths, it's the same math that gives us the, so the result is the same as our intuition. Our intuition was, if the goalies most, if the striker's mostly shooting east, then we as the goalies should, should be, should be jumping east, and when we do the numbers we we get that as as our result, which is, East is better than west, for the goalie if P is bigger than half. Similarly, west is better than east if P is less than a half, and jumping east is indifferent to jumping west when P is equal to 1/2, right? So if all things are if all these things are equal signs instead, then we get that we're indifferent between jumping east and jumping west. That's the goalie. And you can do the same thing for the goalie, we won't do it because it's the exact same argument, but you can do the same thing for the goalie, right, for the goalie, you can do the same thing for the, um, for what the from the striker's perspective, right, you say the goalie is going east probability que, west probability 1 minus Q. You do it lap, it's exactly the same because the because the problem is entirely symmetric. And I don't want to get that last point there yet, I want to go here first. As we said, if the strike is going both ways equally, the goalie is indifferent between any strategy, and going east is just as good as going west. And if going east is just as good as going west, then going east half the time is just going east half the time and west half the time is just as good as going east all of them. Going east half the time and west half the time is just as good as going west all the time. Going east half the time, west half the time is as good as going east. 4 40% of the time the west 69. You see my point, right? Any mixture is fine. If the striker is, is evenly going between east and west, then, then me as the goalie, I don't care what I do. Because I get one, I get I get I get 0 usuals anyway. In expectation I guess very usual anyway. And we can do the exact same straight statement for the goalie, from the goalie's perspective, if the striker is evenly going each way, then I don't care what I'm doing, right, then anything that I'm doing is fine. Which means we can spot down a Nash equilibrium here, which is, which we want to find the point where neither person has an incentive to deviate, and it's exactly what it's what we argued before. We have neither person has an incentive to deviate if both people are evenly mixing, right, if the striker and the goalie are both going each way 50% of the time. Because as soon as, because neither of them has a positive incentive to deviate, both of them don't care what they're doing in the sense of, given what the other person's doing, every action of mine, every strategy of mine gets me zero utils, so I don't care what I'm doing. But as long as I'm doing this mixing. This even mixing, then my opponent also doesn't care what they're doing, and so they're also happy to do the even mixing. So for Nash equilibrium, the fact that we're looking for no positive incentive to deviate is actually quite important. Right here, our people are indifferent, they they will be fine with deviating. They will be indifferent between deviating from their current strate strategy, but there's no positive incentive for them to deviate, they don't become better off when they change their action or change their strategy. OK. Any questions or problems here? Right. Because we like graphs, you always like graphs, we're gonna throw a graph at this, and we're going to, before we even start, we're going to, apologise. For the awful image that is going to appear here. For reasons that we will see shortly. So we want to do our best response graph. We'll try and keep it as similar to this as we can, um, so east and west. So here we have. Let's start from the goalie, the goalie shoots east. Sorry, the striker shoots east. He equals 1 Shoots west equals 0, and then, In here is P equals 12. And we want to think about the best response for our, the best response profile for our goalie. What was, what's our goalie gonna wanna do? From our goalie's perspective, they're gonna be doing something between jumping west, Jump west. And jump east Potentially mixing these things here, they jump west, jump jumping east is Q equals 1, jumping west is Q equals 0, right, and so they might mix evenly would be Q equals 1/2. Oop. 2 equals 1/2 is they mix evenly. And so we want the best response. What is the best thing for for for our, for our, you know, start off by looking for the best thing for our goalie to be doing, for different actions, different strategies of our striker. Right, our striker, each strategy of our striker corresponds to some point along here, because, you know, if they shoot east, that's Pals 1, if they shoot west, P equals 0, if they mix evenly, it's equal half. If they mix mostly shooting east, we're over here somewhere, mostly shooting west, we're over here somewhere. And so we can talk about the best response for our, for our different person, for our, for our goalie. And so, we do the easy, sort of the easy end points first. If our, Striker is shooting east. A striker is shooting east, what does our goalie want to do? They call me, easy ones. Pardon? Jump east, yes, I, I put the wrong round. shooting east, we wanna jump east, so blue. We wanna jump east. I think our image is not gonna be as bad as it could have been, which is lucky. We're gonna jump east. What about if, Our striker is only mostly shooting east. Right, shooting 2/3 of the time, what's our goalie wanna do? It's the best thing for our goalies do. Yeah. They jump east, right, that's still the best thing for them to do because then they win most of the time. There's a, there's this kind of intuitive idea that that if our, if our um striker is shooting east 2/3 of the time, we should then jump east 2/3 of the time. It doesn't quite work that way because we can't correlate. If we could correlate, yes, but we, because we can't correlate, um, we don't know on any particular occasion whether they're jumping east or west, the best thing to do is to always jump east. That's gonna be the case all the way up until we get to that P equals to 0.5 point. It says it's gonna be part of our best response function. We're gonna do the, we're gonna jump jump around a little bit. What about shooting west, right, if thou, I'm just gonna say this actually, similarly, if our striker is shooting west all the time, then we want to jump west all the time. And if our striker is shooting west 2/3 of the time, we want to jump west all the time, and that's gonna be the case. Whenever our striker Is shooting west most of the time, we want to always jump west. The tricky part is what happens when P is a half. What happens when our striker is evenly going between both directions, half the time going east, half the time going west, as we sort of try to argue it is as the goalie, we don't care. Any choice that we can make is equally good, we get zero usuals and expectation regardless, and so we should, we, we don't care. Anything is the best response. This is where best responses are a little bit tricky, they're not functions, they're not like for this strategy, what is the best response, it's for this strategy, what is our best response? What is the collection of. Of best responses. And for P equals a half, there's lots. Oh no. P equals 1/2, there's lots, right? Any strategy is equally good, right, equally happy jumping east all the time, jumping west all the time, jumping east and west half the time, jumping east mostly, west mostly. It doesn't matter. All these things are equally good. And so this is our best response. Function This blue is our best response function for the goalie. It's a function that takes in things on the X axis and spits out a Y axis option object. Or objects. Any questions, questions, concerns? Yeah. OK. Fantastic. Now we're gonna flip this around. Now we want to look at this from the perspective of the striker. This is a bit harder because we naturally think because we're, you know, 12 years of of high school mathematics, we naturally think of the different X values, what are the Y values, and unfortunately when we think of this from the striker's perspective, we're saying for different Y values, what is the relevant X value. Um, so we'd have to do have to flip around our thought process a little bit, which is, which is frustrating. So these are all the different values that we have for, for what the goalie could choose to do. What is the best thing for the striker to do for those different levels, and like, we can see as an example, if we, if the striker, sorry, if the goalie is always jumping west, then the thing we as the striker wanna do is we wanna jump east, right, because, sorry, we wanna shoot east because we wanna shoot the the opposite direction to wherever the to wherever the goalie is jumping. Got a couple of smiles, people who have realised the picture that we're gonna end up with here. Um, similarly, if the goalie is, and, and that's the case, right, if the goalie is mostly jumping west, then we end up, then we always want to shoot east. In a similar vein, if the goalie is jumping east, always, the goalie is always jumping east, then we wanna shoot west all the time. We want to shoot west all the time, and if the goalie is mostly jumping east. We also want To shoot west all of the time for the same reasons we discussed. And when we get to that Q equals a half point, because of the symmetry of the problem, when we get to that Q equals a half point, uh, when we get to the goalie is equally likely to be jumping east and west, then we as the striker, we don't care, we get 0 usuals regardless of which way we go, um, and so any strategy is just as good. And we get what we get, right? It's unfortunate, but here we are, um, so we get our best response graph for our matching pennies game. Part of the reason we really like best response graphs, they can be very useful in sort of terms of sort of thinking about what's going on with these things, um, is that we can pull out Nash equilibria from these very, very quickly and easily. And if you can get a best response graph, you can pull out a Nash equilibrium immediately because, Nash equilibrium is where each player is playing a best response to what the other person is doing, so I'm playing the best response to what you're doing, you're playing the best response to what I'm doing, and so we're all we're looking for, I'll just label this, this is our best response for the striker. All we're looking for is points where our best response curves intersect. Any points where the best response curves intersect is going to be a Nash equilibrium. And in this case, it's here, right, this is our Nash equilibrium, let's go green. This is our Nash equilibrium. At P equals a 1/2, Q equals 1/2. So we can pull out mash equilibria from these graphs, yep. Yeah. Right, so we're focusing on the, the best response for the striker. That that, yeah, sure. So we're focus on the best response for the striker, we need to be, again, it's a little bit tricky because we're taking in the Y axis value as the as the argument and we're spitting out the X axis value, um, so for the striker's perspective, we're saying, well, if, If the person is jumping east 90% of the time. What's the best thing, what's the best thing for me to do, and it's to go and strike all the time and it's to go and shoot west all the time. Um, so that's, that's, yeah, is that OK? Yeah, excellent. Um, and yeah, and we get Nash equilibria out of this really quickly and nicely and easily. Um, this is also, though I won't go into a lot of detail for the at least for the two player two action case, the the, the, the structure of best response graphs also gives you why there has to exist a Nash equilibrium, um, at least one Nash equilibrium, either one, either 12 or 3 Nash equilibrium, um, for these kinds of games. Um, because the best response for the striker has to go from the bottom to the top. Right, because you have to have an and as a a choice that you make when the goalie is jumping west and a choice you make when they're jumping east, so the the line has to go from the bottom of the graph to the top of the graph. The red line has to go from the bottom to the top somehow. And the blue line has to go from the left of the graph to the right of the graph, somehow. If you've got one line that goes from the bottom to the top and one line that goes from the left to the right. Those lines have to cross each other somewhere, um, so we get a sort of a visual argument for why we need to, why a national equilibrium must exist, um, which is something at least. How are, yeah. Any questions, concerns? Promos.

SPEAKER 3
horizontal Yeah. Where he's indifferent Yes, yes. A inclination to one side and so wouldn't the striker's response be to shoot.

SPEAKER 1
O Yes, so that is why, that is why, so the description you've given, the exact description you've given is why is why this point here, This is not a Nash equilibrium, or not a Nash equilibrium. Um, because if, because, if the goalie is, oh sorry, if the striker is shooting, P equals a half. Then the goalie is happy living at the little black dot I've just drawn, right, living at at at Q equals 2/3. Uh, and they, they, they're fine with that, that, that's from their perspective that's fine. But it's not a Nash equilibrium, because if the goalie is, if because of the, yeah, if the goalie is jumping east at Q equals 2/3, then the best thing for the striker to do, Is to is to go west all the time, so. It's an interesting point, but it's not, it's, it's, it's not a Nash equilibrium, it's just an indifferent, it's indifferent for one of the players, but it changes the incentives for the other player in a way that makes it not a Nash equilibrium. Questions, comments Right, so here we did a whole lot of maths and a graph and all this stuff, and basically what we found was the thing that we could kind of argue anyway, um, which at one level makes us go, well then why are we bothering to do all this if this is all we get out of it? And the point is that we start with something easy because it, the course for intuition and then we look at a problem where we probably don't have a good a good intuition for the answer. Right, so we took our Battle of Xs game, we've simplified a little bit, so, um, you get 1 point for going to your preferred option, 1 point for going to the option with your partner, um. And yeah, and that's what we get here. Uh, actually we've tweaked this Battle of Sexes game, so we've we have simplified it here, but it has the same flavour as Battle of the Sexes. You wanna go with your partner, you want to go to your preferred outcome, conditional on going with your partner, and you really don't want to be alone. So it's, it's a simplified battle of a sexist game. In terms of Nash equilibria, there's clearly, without doing any extra work, there's clearly two pure strategy Nash equilibria here, uh, which is both go to the ballet or both go to the boxing. Those are the pure strategy Nash equilibrium. Um, But if we ask about mixed strategy equilibria and whether there are any, the intuition's a lot less clear, it's kind of like there might be others, but then there might be a pure tra um sorry, a mixed strategy equilibrium, but there might not. I would argue that it's, it's unclear whether there's a mixed strategy equilibrium here or not. And if there is a, sorry, and if there is a mixed strategy equilibrium, it's very unclear what that looks like, what that's gonna look like. Right, if, if I if I tell you there is a mixed strategy equilibrium. And cos there is one, I I we'll say, but there is one. My intuition. Would probably be that the mixed strategy equilibrium is both people go to ballet and boxing equally often. And that intuition's gonna turn out to be wrong. Right, and we'll see, we'll see what what what actually happens here. So we're gonna plop down some, we're gonna, we're gonna try and figure this out. The wife goes to the ballet with probability alpha and there oh sorry, let's just put it over here, the probability alpha and therefore goes to the boxing the probability 1 minus alpha. The husband goes to the ballet with probability beta and therefore goes to the boxing with probability 1 minus beta. What do I do this? And so we can work through the same thing, same way that we work and there's other ways you do this, but the same, we can work through this the same way we did last time, we'll get those best response functions, um, so for the husband. The utility for the husband of going to the ballet. Conditional on how likely it is that the wife, Goes to the ballet. Well, the husband going to the ballet, there's one there's an alpha, there's an alpha chance that the husband gets one neutel, there's an alpha chance that we end up here and we get, and the husband gets 1 neel, and there's a 1 minus alpha chance. That we end up with the husband going to the ballet and the wife going to the boxing. Uh, in which case we get nothing. And so our expected utility from going to the ballet is alpha. We do the same thing for the boxing. Conditional on how likely it is that the wife is going to the boxing. Well, we're probably the alpha, we're gonna end up here and get nothing. And with the complementary probability 1 minus alpha, we're gonna end up here and get 2 eels. This is 2 minus 2 alpha.

SPEAKER 4
And so, yes, sorry, yeah.

SPEAKER 1
Line between ballet. Conditional on, so it's it's, it's the utility for the husband of choosing, yeah, so it's a good point, so it's this thing here, um, It's, it's just the way we sometimes write functions in for these kinds of functions because the husband, we're talking about the utility for the husband, they get to choose this thing that he's choosing to go to the ballet, and then it is, there's different phrasings that you can use here, um you can use uh conditional on or such that. So it means either conditional on the value of alpha, which is something that we, is going to affect our payoff but we don't get to choose, or such that alpha is whatever it is, because we don't get to choose it. Here I think conditional on alpha is the is the phrasing to my mind that works best, but it's the same as such that alpha is whatever it is. We often So it's just a second term in our function, but it's a term we don't get to choose, so we, we put it over in the conditioning area. So we either go to the ballet, we get alpha, or utilities in expectation, or we go to the boxing and we get 2 minus 2 alpha utility in expectation, and so just like before we can say, well, for the husband, the ballet. Is better than the boxing. If and only if alpha is better than 2 minus 2 alpha. Sorry for the similarity between 2 and alpha. Which is 3 alpha is bigger than 2, which is alpha is bigger than. 2/3 And so the cut-off point. Isn't half half, it's something else, right, if the hus if the if the if the wife is mostly going to the ballet, but mostly means really mostly, right, if the wife is going to the ballet more than 2/3 of the time, then the husband's gonna join then the husband wants to join them at the ballet, always. But if the husband's got, and you can kind of see this, right, if the wife's going to the ballet sort of half of the time, if the wife is mixing half, half, ballet half and boxing half, well then when, when we go to the, for the husband's perspective, we can go to the ballet and get one, or we go to the boxing and get 2, and if those are equally likely, well then we should just go to the boxing and every time and and hopefully we win, cos when we win we get two usuals instead of 1 usual. Um, which is also where that 2/3 number comes from, right? Going to the boxing is twice as good for the husband that's going to the ballet, so going to the boxing with his wife is twice as good as going to the ballet with his wife. And so it needs to be that the, in order for the ballet to be worthwhile, the wife needs to be going there at least twice as often, twice or more as often. Um, and if it's, if the wife's going exactly twice as often, then those two things cancel out, right? The wife goes to the ballet twice as often as the boxing, which is the alpha equals 2/3. Wife goes twice as often as to the boxing, boxing is twice as good, and so we're indifferent between, we would then be indifferent between going to the ballet or boxing. So that's sort of the intuition for that 2/3, right? Al is bigger than 2/3, the husband's gonna go to the ballet, so if the wife is really often going to the ballet, the husband will join, if only a little bit often or not often, then the husband goes to boxing. You do the same argument for the wife, and you get beta is beta, beta of a third being the being the cut-off point for similar reasons. She's doing fine for time. Um, And these are our best, these are ultimately gonna be best response functions, um, and the, the key point I guess is that when we're at that 2/3 level, or, or 2/3 of beta, 1/3 for alpha, sorry, 2/3 for alpha, 1/3 for beta, then the husband is indifferent between any strategy, the wife is indifferent between any strategy, so for the same reasons we saw before, we're gonna get a new Nash equilibria where both people go to their preferred option 2/3 of the time. Because if the wife is going to her preferred option 2/3 of the time, the husband doesn't care what he does, he's indifferent between all his options. If the husband's going to his preferred option 2/3 of the time, then the wife is indifferent. And so we end up with this situation where there's no where if both people are going to their preferred option 2/3 of the time, there's no positive incentive to deviate, no one has a, has a strict incentive to change their actions. Similarly to the previous one, but the intuition was a bit less clear. We need, we really did, I I think at least we needed the mathematics to be able to, to figure out our intuition properly. We'll do some graphs, we'll do a graph in a second, but any questions, questions, problems? Excellent. We can do our best response graph, same as the previous one. We're gonna have The The husband goes to the ballet. What the hell. The husband goes to the ballet, which is which we throw around, beta equals 0. Betters one, sorry. Husband goes to the boxing. That was Norton. The wife goes to the boxing. Alpha equals 0. The wife goes to the ballet. Which is Alpha equals one. We do our best response, we'll do the husband oh sorry we'll do the best response for the wife first because it's the easier one. So for different choices, different strategies of the husband, we want to know how far up and down this line is, right, how what the best response for the wife is. If the husband's always going to the ballet, the husband's always going to the ballet, then the best thing for the wife to do is to always go to the ballet, right, your husband's always going to the ballet, you're very, very excited because you get to always go with your partner it's your preferred option. This is spectacular for you. So for the wife, we're gonna be up here when the husband's always going to the ballet. As the husband becomes less and less likely to go to the ballet, you're gonna keep going to the ballet all the time, or are you gonna keep going, 00, you're gonna keep going to the ballet all the time. Until we reach some kind of critical level, which we'll get to in a second, where you start going, where you're gonna start going to the boxing all the time. If we focus on the, the, the husband going to the boxing component, the husband's always going to the boxing, then you go, well, I guess I'm stuffed here, the husband's always going to the boxing, I need to always go to the boxing, otherwise I. I am alone at my preferred event, and as the husband's less and less likely to go to the boxing, you're gonna keep following up to a certain point, and then there's gonna be some point where this cut off changes in you and you are indifferent. And we worked out our indifference was at beta equals 1/3. Was a bit was that's really not too close. Was it beta equals 13? Right, where if the husband's going to the boxing 3 of the time, sorry, going to the going to the boxing 2/3 of the time in the ballet, 1/3 of the time, you're going to your preferred thing. A third of the time and your least preferred thing, 2/3, you become indifferent, right? The ballet is twice as good but happens half as often. Um, so you don't care whether you go to the ballet or boxing, and you are indifferent between any of your strategies, right, going to the ballet all the time, going to the boxing all the time, mixing half, half, mixing in some other way, are all just as good for you. And so we get our Best response for the wife. This graph's gonna look different than the previous one. I don't have to apologise for this graph. Any questions, problems? Excellent. We do the same thing for the husband then, but different, for different um strategies of the wife, what does the husband, what is the husband gonna want to do, um, and so if the wife is always going to the boxing, where are we point, if the wife is always going to the boxing down here, then the husband wants to also always go to the boxing because you want to be with your partner there. And so that's over here. My wife's always going boxing, husband always goes to the boxing. If the wife is always going to the ballet, then you want to always go to the ballet because you want to be with your partner, right? So that's up here. As the wife becomes if we focus on boxing, as the wife. Goes to the boxing less and less, but still pretty much all the time, you're gonna want to keep going to the boxing because your wife is there and you and and you like it. Um, so as your wife goes less and less, even if it's, you know, 90% of the time we go to the boxing, as the husband, we're still gonna follow them all of the time. And even if the wife is going equally likely to ballet or boxing, if it's equally likely ballet and boxing, you look at that and you go, right, well, I have a 50/50 chance of being wherever, wherever the wife is, I'd rather be there, I'd rather then go to the boxing and hope that I get lucky at the boxing rather than go to the ballet and hope I get lucky at the ballet. Um, so we are again going to continue going to boxing. And as we worked out, Alpha equals 2/3 is the critical cut-off point. Right, so alpha equals 2/3 is our critical cut-off point, where we go to the ballet 2/3 of the time and the boxing 1/3 of the time. That's where we're indifferent And so our best response, so filling in all the bits, our best response. For the husband For the various options the wife can take is shown. Yeah. And we get our 3 Nash equilibrium, we get our Nash equilibrium where we both go to the ballet, we got Nash equilibrium where we both go to the boxing, and our new, uh, and our new Nash equilibria. Where we have this unusual mix. We have this mix where we are 1/3 of the 2/3 of the time going to our preferred option, 1/3 to our less preferred option. I have one more thing to say here, but we're largely done for this section. Any questions? Problems? 3 national equilibrium, yes.

SPEAKER 2
to construct a case where you had two of those lines overlapping each other so. of Ah, The question was, is it possible to have

SPEAKER 1
it so that you end up with a with a continuum of Nash equilibrium? It, it is, but not in the way that you're thinking of, um, so something that we won't worry about is you can have situations where you're indifferent between the two actual actions being taken, so you could have it that's um that's, The husband in in a situation for example where the husband always gets zero utility regardless of what happens, and the wife always gets zero utility regardless of what they choose, then you don't really get nice clean lines like this, you end up with just everything as the best response to everything else. That's the circumstance where you can get a continuum of continuum. If you have the, you have um uh if basically if all of these 8 numbers are all different, that's a bit too strong, but if all of the numbers are all different, then you will not get a continuum of. Nash equilibrium. Uh, it can happen in other circumstances, but this, this has too much structure to allow for a continual equilibrium in, um, except for the weird kinds of things. OK, one more thing here, not all of these Nash equilibria are equally good. Right, the Nash equilibrium where they both go to the ballet is great for the wife and sort of OK for the husband. The Nash e where they both go to the boxing is great for the husband and sort of OK for the wife, and the Nash equilibrium where they both go to their preferred things 2/3 of the time, it's actually quite bad for both of them. Um, it's the best they can do given what the other person is doing. But it's still pretty terrible because there's such a high chance that you are going to be ships in the night and like and miss, your partner, right? Because there's a 2/3 chance that you go to the boxing and there's a, There's a sorry, there's a 2/3 chance that your partner goes to boxing and there's a 2/3 chance that you go to the ballet, and so there's a 4 and 9 chance you just don't go to the same thing, um, which is the worst possible outcome. Um, so it's actually quite a bad Nash equilibrium in terms of welfare, but it is still a Nash equilibrium. It's still the best that both people are still doing the best they can given what the other person's doing. And again, obviously, silly in the sense that you would just talk to your partner and arrange beforehand what you would do. Any questions, final questions on this, we've got one more slide for stuff and then we'll probably take the break. Any questions, concerns? Spectacular. These things always look a little bit strange, because it looks like the, when you're looking for Nash equilibrium, it looks like what you're trying to do is not really to maximise your utility. It kind of looks like what you're looking for is places where you're indifferent between your different actions. But yeah, sorry, where you're you're trying to make an action that means that your opponent is indifferent about their choices. Um, and that kind of is what we do look for for these proper mixed strategies. Um, it needs to be the case when we're looking for these proper mixed trategy equilibria, we need to be choosing our probabilities, each person's choosing the probabilities so that the other person is indifferent between the actions that they're taking the proper mixed strategies. Because if I choose my probabilities so that you're indifferent, and you choose your probability so that I'm indifferent, then we're both indifferent and so we're both perfectly happy with the choices that we've made because any choice for us was just as good as any other. Um, so it's a, it's a bit weird, right, but it means the other per if you choose so that the other person's different, then they're willing to mix. If they do the same thing, then you're willing to mix, and so we get an equilibrium, it's a strange process, but it does work out, and this is how we tend to think about these things. Um, you're trying to make the other person indifferent about their choices, and if they're trying to make you indifferent about your choices, then you end up with everyone being indifferent, which is good cos then you can choose randomly. At least in the 2x2 case. Larger cases, as we'll talk about in CTs are a little bit different but not significant. Yeah. Thus ends this component of the lesson on this stuff. Are there any questions because this is the last thing we do, we do continuous action after the break, so any questions on simultaneous action mixed strategies. Lovely, in that case, we will break now, we'll break for 5 minutes, we will come back at 2 minutes to the hour to talk about, Continuous actions. Thanks. And if you have any questions, you can come see me now, which I don't think I said, but I've said it now. Hey, hey, um, uh, my name's Ari.

SPEAKER 3
uh, I was an auditing student till like last week, and we got the result last week, which is pretty late. Um, I wanna know first thing about tutorials, um, because my timetable is you can't enrol in. So do I just show up to, um, that will

SPEAKER 1
be fine. Well, I, I believe I can still enrol you, so if you shoot me an email personally to my to my account, um, james. Taylor@u. Um, I, with your, can you, can you see my timetable? You just can't enrol. I can't but you can see it, yes, um, I can enrol you manually, but I can only enrol you manually in a class that doesn't have 25 students. So if you have a look at the list of classes that are there, find one that doesn't have 25 students, let me know which one and I can add you to it. If that's 25, I just, I just can't do it, it's outside of my abilities about the midterm exams, yes,

SPEAKER 3
uh, do you have to add me to uh.

SPEAKER 1
If you're enrolled as normal then there shouldn't be any issues, um, because I got I was before, um, joining

SPEAKER 3
2101, I was in econ1101, yeah, and uh I got examination email for the one I, I would check with

SPEAKER 1
um RSC inquiries because it's kind of an admin question, but if you're enrolled in this class, then you should attend the exam for this class, yeah.

SPEAKER 3
Uh, no, but, or, or, but like I sent an email to Student Central and they told me I have to ask Doctor Steinhauser to manually ask examinations to take me off the list. I don't, that's completely unnecessary.

SPEAKER 1
Um, if you're no longer enrolled in Ecom 101, then. Even if you're on the list, it doesn't matter, right, there'll be a seat in the in the examination room, you don't sit there, they won't get your exam, it won't make any difference, um.

SPEAKER 3
And, but with, uh, micro to, um, yeah, should RSA

SPEAKER 1
inquiries and that's not something I, not I, I have I have a vision on. Shoot RSC enquiries in email, um, and they'll make sure that everything's fine.

SPEAKER 3
Um, and also last thing, um, with the consults, uh, is it strictly the questions you bring up strictly limited to the course or and economics in general?

SPEAKER 1
If there's, if there's time and space, then we're happy to chat about whatever, um. In economics, if there's a lot of people there, we then we do try and contain the discussion to course material, um, because some people that have questions they want to ask, um, but if there's no, if there's not too many people around, then, then yeah, chat about you thanks.

SPEAKER 5
Oh, because I know the textbook that we used last

SPEAKER 4
year.

SPEAKER 5
strategies. Alex, how accurate is it? How like close to.

SPEAKER 1
Um. For the early part of the course it's a little bit different. Later parts of the course I draw more directly on the textbook, it's like pretty good, but yeah, but it's

SPEAKER 5
usually so it's like I don't know I. Oh, but I'm like fine if I use this one and then I won't be like. really Cool, thanks.

SPEAKER 4
Yeah Yeah Yeah How Alright, welcome back everyone.

SPEAKER 1
We went one minute over on the break, so we have lots to cover, no, one minute, one minute's fine. Here we go, alright, let's say. Almost, what we got there. Right, welcome back everyone. Um, we've finished up on our our our one hour quick discussion on mixed strategies. We now talk about games with continuous action. They're ultimately gonna end up looking similar in some ways, but they are different in other ways, right? Uh, in particular that really nice thing of like all of these best responses being perfectly, being perfectly, you know, vertical or horizontal, we're gonna lose that when we talk about if, if we were to do this in that way, um, but yeah, so continuous actions are a little bit different, it's not that we. Do the most extreme option or the, you know, the most extreme option on this side or the most extreme on this side, and we just do them with different probabilities, it's that we have a continuum of actions that we can choose to choose to do, right, so it's not a probabilistic thing, it's a we choose an action and our action is, We do a thing half-arsedly, right, we do a halfway point something something. So things like oligopoly competition is gonna be our key example of this. If we talk about oligopoly competition over price, it's as a firm, we choose the price, and the price could be anywhere from 0 to as high as we want it to be, right? That would be the price is the price that we can choose. And the outcomes we get are not necessarily linear in the price and in fact typically are not linear in the prices that we choose, but the price is gonna have an effect. The price I charge will have an effect, the price you charge will have an effect on me, sorry, the price I charge will have an effect on all of us, the price you charge will also have an effect on both of us. So it's still, it's still a um a game theory kind of problem, because there is that strategic interaction. But it's not, or at least it's most easily not done as a normal form payoff matrix kind of game, right, because we talk about, and we we're gonna talk mainly about oligopoly competition over quantity, because that's the one that gives nice results and interesting results. Um, if it'll be talk about oligopoly competition over quantity, I guess you could do this in a normal form payoff matrix kind of game where I choose some quantity of production between 0 and 10,000, and you choose some quantity of production between 0 and 10,000 and you get a 10,000 by 10,000 matrix. But it's not very convenient to do it that way, so we're not going to do it that way, uh, and so instead we're gonna kind of need to use formulas to talk about these problems. Um, so this is actually this is instances where there is a continuum of actions we could take, it's not just make 0 or make 10,000, it's 0 units, 1 unit, 2 units. How many units do I choose to make? Um, and that's gonna be our, our main example here. Any questions conceptually on what's happening? Conception on what the, the difference here is. Lovely. So our, as I say, our key example for this is gonna be what we call corno competition, which is oligopoly competition where the firms are choosing the quantity of the good to produce. So firms are choosing how big they are and then are selling goods ultimately for the price that is determined by the market after they decide how big the firm's gonna be. Um, so we have two firms competing, we keep things as easy as we possibly can by having two firms, initially. We keep things as easy as we possibly can by having identical homogeneous goods. So if I make it good or you make a good, it is the from the consumer's perspective, it is equally good. They are the same good, they for the same function that it's the same thing. And so the way we compete is that I'm gonna make Q1 units and you're gonna make queue 2 units, and the price is then determined in the market so that demand clears. So then demand determines the, the price of the goods, so that we both sell all the goods we produce. Um, the firms know all of this, they're choosing to maximise profits. We're gonna keep our life as easy as we possibly can, because we're seeing this for the first time by having no cost of production. So we can make goods come into being instantly for free, and then we sell them according to the demand function. We don't want to make infinitely many goods, even though they're free, because if we make infinitely many goods, then the price gets because demand or demand looks like the price gets driven to zero, and even though we have, you know, 100 million goods, we sell them for $0 each and that's no good to us. Um, so there are still reasons why we don't want to overproduce the goods, even though they are free to make. Any questions, questions, concerns here? Right So again, I know there's some formulas here, but we're trying to keep things as easy as we can, um, we're going to have a nice linear demand because that's gonna be easier for us, so I shouldn't say price here, I should say something like demand here. Have nice linear demand. And demand is price equals 100 minus and I'm gonna use capital Q. And capital Q is the total amount of production, because again, from the consumer's perspective, all the goods are the same. And so whether I've made the good or you've made the good, it doesn't matter. What matters is the total amount of goods that have been made. Um, and so it's a pretty standard demand function, quantity, price. Downwards sleeping. I'll put it at 100, we put the the maximum demand of 100 because. That's what we did. Keep things as easy as possible. From that we can talk about the profit for the individual firm, and again, even in the absence of um costs, so in, sorry, sorry, I should say, in the absence of cost, profit is just revenue. So technically speaking, the profit for the firm of producing Q1, so we're using Pi for profit, which is very annoying, but it's because we've got P P is for price and so we need a different symbol for profit. I think in the accounting and finance, I think you guys use P for profit, is that right? Any finance or accounting people around, you can help me out here? Doesn't matter, because we've got, because we're stuck with P for price, we need something else, we use pi for profit. Um, so it's the Greek P. Um, so profit for firm one from choosing to produce Q1, again this question from earlier, conditional on firm 2 having produced Q2, so we use that condition along cos we don't get to choose that, we get to choose Q1, but we face Q2, we're stuck with Q2. Normally this would be revenue minus costs. But there are no costs, so it's just revenue, which is why it's just price times quantity. And price determined by demand clearing. So our price is 100 minus Q1 minus Q2. And so we get our, our profit functions as shown here. And so we get that nice clean trade-off. Having more stuff is great because we have more things to sell, making more stuff is bad because it drives the price down. And so there's that trade-off between those two things. So whenever we talk about profit maximising, it's not gonna be produced to zero, because then we're not going to sell, it's not gonna be produce infinitely many cos then we then we get price of zero, it's gonna be something in between there. Questions, concerns, and, and we have the same thing for firm too. Questions, problems, all good. OK, and so the question then is, well, if this is what our profits look like, how do we maximise this thing? And so we need some form, we need some way of maximising our profit here. Um, and so our tool that we're going to use is this new mathematical tool that is literally this one page for our purposes, um, which is, if we have some problem which says choose some variable in order to maximise some function. Which is exactly what this problem is, it's choose Q1 to maximise i1, choose Q2 to maximise i 2. Then the solution for this, the way that we, sorry, the way that we solve that problem is actually very, very straightforward. It's, we take the derivative and we set the derivative equal to zero, and that's it, that's what we do. Um, there's a bunch of other things that you can do around this, but that's what, for our purposes, that's what we do, um, because I think it is useful to have some sort of idea of why we're doing that. Is we're gonna have, if we do this as X and F of X, right, for so generic as a generic functional form, we want to find the thing that maximises the X value that maximises F of X. Well if F of X has, I don't know, this kind of shape, which is not an uncommon kind of shape to have, that's set a bad example, let's let's really just keep it nice and easy, let's make it look like what profit looks like. Alright, this is what our function looks like. We want to find the thing that maximises F of X, right, this is, this is clearly the maximum that it reaches. The thing that maximises that is what we call X sometimes use a little star here to be the optimum, the thing that maximises F of X. And you see, hopefully, immediately, that a property of this point X star is that the derivative of the function is zero, right, at that particular point, the function is flat. Um, and so this is why it is that we can use this, this tool, right, we just say, Where is the derivative 0? If the derivative is not zero, we're not at a maximum, because if the derivative is not zero, then we can, We can go along a little bit and get somewhere better, or, or we can go back a little bit.

SPEAKER 4
And get somewhere better.

SPEAKER 1
And so we want, we want to make the derivative 0. If you do further work. Then you're all good. There's lots of work you can do in this. I made a meme, oh no, I didn't make, no, I didn't upload, that's sad. Um, it's fine. Um, I made a thing, it didn't didn't, but it didn't get attached. We're fine. If you do, you can do a lot more work than this, right? This is one slide of optimisation for unconstrained optimisation of one variable. It's not even all really of optimisation of unconstrained of one variable. If you do E at 1001 or math 15, they'll talk about second order conditions to make sure that you're not seeing a minimum. Or a saddle points, if you do the course that we have that is literally called optimisation, um, then you'll talk about this in multiple like when you have lots of different choice variables, when you have lots of different kinds of constraints and kinds of constraints, because this is a tool that is used across huge swathes of economics and huge swathes of econometrics, right? This is just the most basic simple version of it, which is gonna be more than enough for our purposes. Um, so this is our tool, right, we take the derivative, we make it zero, and we find the thing that solves that problem, solves that equation, and we'll see that in a second. Any questions, questions, concerns, problems here? Excellent. So we have our corner competition, we have our profit for our two firms, our firms are profit maximising, um, we, we maximise by choosing the thing that for each firm, they maximise by choosing the thing they get to choose, and not choosing the other things, they're only choosing the thing that they choose, um, and so for firm one. They're gonna maximise their profit by choosing Q one that maximises profit. And so we want to choose Q1 that maximises i one, and as we just said, the way we do that is we take the derivative with respect to Q1. So of this with respect to Q1, that's fine, but pretty horrible, right? There's a multiple of things in here where there's a thing to do with Q1 and then it's times another thing to do with Q1, which is awful, we have to use the product rule. It's a lot of work. What would be a better choice rather than using the product rule to solve this? No, we'll be better off, yep. We'll just expand it out, that that gets rid of the need for the product rule and product rules, yeah, it's fine, but like if we don't have to, um, so it's 100Q1 minus Q1 squared, minus Q1 Q2. And that's a lot easier, that that's, that's now there's no product rule issues, it's, it's a lot easier, it's just a, you know, it's a polynomial in Q1. Um, and so a 100 derivative of 100Q1 with respect to Q1 is 100, 100. The derivative of Q1 squared with respect to Q1 is 2Q1. The derivative of Q1 times Q2 with respect to Q1 is Q2, because we're doing partial differentiation, and so Q2, because we're taking derivative with respect to Q1, Q2 is treated as a constant. And so this is the derivative of profit, this is how profit changes as we change the amount of production that we're doing. And we set this equal to 0 to try to find. The optimum We make this equal 0, so that we get the get the optimum, um. And we then do some algebra to try to find this. 2 Q1 minus, plus Q2 equals 100, actually gonna isolate Q1 because that's the thing we want. 2Q1 equals 100 minus Q2. Which is Q1 or Q1 star sometimes. Is 50 minus Q2 over 2. How much do we make, we make this much. Of the good, that's our profit maximising amount. Conditional on how much our opponent's making. If our point's making lots of stuff, we don't make too much.'s making only a little bit of stuff, we make more. Any questions, if sorry, if our points like 0 stuff, Q2 equals 0, then we're a monopolist, right, then we're a monopolist and we go, given the particular demand function, given demand that looks like that looks like this, and costs, marginal costs that look like this. Then we get our marginal revenue curve. Which we know is twice as steep and so we produce 50 units, right, from micro 1 we would expect that when Q2 is 0, Q1 would be 50. But here we're able to say for other values of Q2. What we choose to do. Any questions, concerns? Things to ask about? Lovely, and we do the same thing with firm 2, we'll do this one a lot quicker because it's the same thing. It's a derivative of Q2 in i 2. Again, we don't want to do the chain rule, so we'll expand out. Preset to be 0, which gives, 2Q2 is 100 minus Q1. Which is Q2 Equals 50 minus Q1 over 2. And it's hopefully not that surprising that we get very symmetric answers here, because the problem was symmetric, so you would expect the answers to also be symmetric. And this is where we do have to do a little bit of work, because our best response for Q1, so here, so if we do a best response graph? I do, OK, cool, um, and so our best responses are. These things here, Q1 as the best response to how much Q2 we have, Q2 is the best response to how much Q1 we have. And we can solve this to find Nash equilibria, right, so if you want to find Nash equilibria, we're looking for when Q2 is the best response to the actual value of Q1 and Q1 is also the best response to the value of Q2, looking for the for the instance when both of these equations are satisfied. Um, and so we need, uh. Q 1 to equal 100 plus, I'm gonna write Q2 for the moment. But then we also need Q2 to actually be, 100 plus Q1 over 2. We just sub in the value for Q2 because we're solving these equations simultaneously. And so Q1, actually 2Q1 equals 200 plus Q1 over 2. So what is that? 2.1, so 1.5 Q1. Equals 200, which is Q1 equals, 400/3. It looks too high. 100 in the news. Yes, there is definitely, ah yes, there's meant to be a yes, yes, thank you. There we go. Let's try again. 50 plus 100 plus Q1 over 4. That looks better, right? Better, hopefully better. Q1 is. 50 plus 25 plus Q1 over 4. So 3/4 Q1. Is 75. Again doesn't, isn't quite right. If we solve this and don't make mistakes. Um. We get that each firm produces 33 and 1/3 units of the good. So each firm is producing 1/3 of the total maximum amount of demand, right? If you recall our demand function, if we think about this again through the through the demand function concept, um. Our demand function looked like this. Out to 100 and 100 here, I guess. Is what our demand function looked like, costs were 0. Our monopolist produces 50. Anopo produces half the demands that that maximises their profit. What we're seeing here with the oligopoly is that each oligopolist, so monopolists half of the half of the maximum that's that's that's the maximising level. For our oligopoly, when we have two firms in our oligopoly, each of our oligopoly firms is producing a third, which means that the total production is 2/3 of the maximum amount, um, and so if we have 2 firms, we end up with, 66 and 2/3, right, we end up with more stuff being produced. From a welfare perspective.com for this? No. From a welfare perspective, this is good, right, the welfare maximising level, this is now drawing, drawing in stuff from micro one, but you've all done micro one. Our welfare maximising level, given that costs are zero here, the wealth maximising level is to produce and sell 1 is to produce and sell 100 goods. Like that, that's where marginal benefit equals marginal cost. Um, so that's the welfare maximising level. The profit maximising level for the monopolist was to only make 50 goods, which was very bad, lots of dead weight loss. The oligopoly is better. It's not perfect, but it's better than the monopoly, because we in total produce 66 and 2/3 with two firms. So the, I shouldn't say the opoly, the duopoly is better than the than the monopoly here. But still far from being optimal. Any questions, concerns? Big things to claim here. Yes.

SPEAKER 2
The mistake we made before the Q1 should be 100 minus Q2 over 2.

SPEAKER 1
Oh, is that what it is? I've copied this part in wrong. Yeah, look at that there, yes. So the problem was that I transcribed here incorrectly, and these should be minuses. That is why we had massive problems. Thank you. Again, if you do this correctly then you do get the like. The 3rd amounts. Gonna be good for the next slide. Be important and useful for next time. Any questions, any further questions then? Questions, problems. Thank you for finding the error, it's always nice when you do find them, find the issue. OK. We do like to have these best response graphs because we've, you know, we've developed this as a tool, so we should use it. Um, we know that our optimum level, our best response, Q1 is a function of Q2 is, Is 100 minus Q2 over 2. Our best response for for firm 2, given what firm one makes is 100 minus Q1 over 2. And so realistically we're talking about production amounts between 0 and 100, right, those are the those are the, well actually between 0 and 50 are the realistic production amounts. We would never make more than 50, it would be it would be dumb, right, there's there's no choice that our products make that would make us more than 50, so we'll just go with this. Um, so we'll have Q1 equals 0. Q1 equals 50. Q2 equals 0, Q2 equals 50. And we can build our best response functions, because the way we've drawn this graph, we'll start off with the best response for best response functions for firm 2. Because we can say at different amounts of firms one firm one's production. How many of the good do we want to make? So if firm one is making 0 goods. So we're here If firm one's making 0 goods, then as firm 2 we want to make 50 goods. Oop, sorry, I dropped a 5 here for some reason. If I'm wanting 0 goods. We as firm 2 want to make 50 goods. We read it off the graph. If firm one's making 50 goods, which is the most they could plausibly want to make. Then we want to make 100 minus 50, which is 50/2, which is 25, so we're gonna, we're gonna want to make 25 goods. So there's gonna be points on our best response. And if I don't know if we can find other points here, but we kind of should be able to intu it from here, if firm one makes, 25 goods, then how many goods we make, we make 100 minus 25, which is 75, 75/2, which is, whatever it is, what is 75/2? 37.5, right, it's up here, halfway between 25 and 50, 37.5. And we see that because this is linear, right, this is the equation for a line, it's just 50 minus 2 to 1, so it's an equation for a, a straight line, and so our best response is this nice straight line here. Which I wanna make sure I do in in blue for consistency. Our best response for firm 2. And as noted previously, unlike mixed strategies for continuous game, continuous action games, it's quite likely that these things are not horizontal or vertical, and here it's not, here it's at an angle. We can do the same thing for firm one, we'll do it in red, the same thing for firm one, for the different choices that firm 2 can make, make, how much do we want to produce. If firm 2's making nothing, then Q2 is 0, and so our best response to that is to make 50 goods. If Firm 2's making 50 goods. Then 100 minus 50 is 50, divided by 2 is 25, so we want to make 25 goods. Right, so our best response to Q2 making 50 is to make 25. And as before, it's linear, it's a straight line, it's it's an equation for a straight line and so. It's gonna be our Best response for firm 1, given what firm 2 is doing. And again we see this idea of the, the, the best ones firm one is going from the top to the bottom, the best responses from firm 2 is going from the left to the right. Those lines have to cross somewhere. And where they cross is is here at the Nash equilibrium. And the Nash equilibrium is each firm makes 33 1/3 units, right, each firm makes a third of the total makes makes a third of the maximum or if you like makes 2/3 of the monopoly output. Depending on exactly the assumptions you make. But we can actually glitter, it's where the best response lines cross. That's it. Questions, questions, concerns, problems here with. Continuous action games. OK. Do we do Bertrand? Excellent. Corno. So this was, this is called corno competition after the, after the bloke Corno, um, you get a bunch of qualitative results out of these things, right, cause the, the, I mean the the number that this is 33 1/3 is not really a very interesting number, right? We don't, I don't care. What I care about is the qualitative results. What do we learn from this about about the way competition works? And some of the things we learn about this are we learn things like profit is strictly positive. This is a big difference from, say, perfect competition, right, you think back to micro one, in micro 1 when you talk about perfect competition, one of the outcomes from that was profit gets driven to zero in the long run. Here there's none of that, right, profit's positive, profit is is positive, um, which is fine, right, we don't make comments whether that's good or bad. Total quantity produced is more than the monopoly. This is great, right, this is a good, this is a qualitatively good thing. So, yeah, or whatever. This is a this is a good thing, we can, we can actually sit down and say this is good, we're happy with this, right, this means that there is less dead weight loss relative to social optimum, right, we're closer to the social optimum because the monopoly massively underproduces the um the duopoly doesn't underproduce by as much because the duopoly makes more in total. Each firm is smaller. But the sum of all of the firms is bigger. Which is great. Uh, we get things like the total profit, what we haven't quite done here, we get things like the total profit is less than the monopoly profit. We haven't done that quite here, but you can you kind of can do that if we draw a little quick, quick graph. Um, in fact, no, first off, we'll say, we'll say why this is the case. Why would total profit be less than the monopoly? Broadly speaking, because the monopoly is unconstrained, monopoly gets that demand and gets to choose the thing that maximises the overall profit that is earned by the firm side of the equation. Whereas if you break up the break up the monopoly and have a duopoly instead, as we've been studying here and have a duopoly instead, each firm doesn't get to keep all of all of the firm side profit, and so they're competing against each other, and part of the thing that that does is that drives down their profit, right down the total amount of firm side profit. And we can see that in our graph. Where we have our demand. And we have our. Monopoly quantity, again, costs are all set to zero here for ease, we have a monopoly quantity here, um, and the monopoly price. And the monopolist got to choose anywhere along the demand curve that maximises the total firm side profit, and they chose this point here, and this was the thing that maximised firms firm side profit, and firm side profit is is price times quantity. Our duopolists. Are choosing differently because of the incentives they face, they choose differently and they produce, A total amount that's that's bigger than the monopoly. Which means they also charge a lower price. Like it's a lower price in the market than what the monopolist would charge. And this is less firm side profit, and we know it's less firm sized profit because we know the thing that maximises firm side profit, and the thing that maximises firm side profit is the monopoly level, and this is a different thing, and so it therefore must be a smaller thing. Um, and so we end up with smaller profit for the, for the, Entire firm side, right, it's not that each duopolist is less profitable than the monopolist, which is also true, it's that the sum of the profit for the duopolists is less than they would get if they were just, is less than the profit for the single monopolist. Right, profit goes down not by 50% but by more than 50%. Uh, total surplus is more than a monopoly, for reasons we've talked about, uh, basically that monopolist underproduces, but we, but the joist underproduces less. We haven't included costs in this analysis, but you can, and all of the qualitative results stay pretty much, say well stay the same, right, the qualitative results are are are are all the same. Some of the really clean quantitative results aren't quite the same. You're not gonna get that nice clean monopolist produces half the maximum, and each duopolist produces a third that we got here, but you're gonna get still the bulk of these qualitative results will still firm, we still will still hold. Throwing extra firms into this analysis again, we haven't, but you can do so pretty easily, and the results you get are again still pretty much what you would expect the results to be, which is more firms is better. As you have more and more firms, you get closer and closer to social optimum as the total amount of total amount produced, and it's not that hard to include. OK. That's Cora. Any questions, questions, concerns, issues. Corno competition is fantastic and it's nice because of, I would say, broadly speaking, two reasons. It's really nice because the results you get are pretty close uh sort of kind of match what you see in the real world when you go and you look at duopolists compared to monopolists and 3 firms and 4 firms compared to 2 and 3 firms, you get these kinds of things happening, these qualitative results seem to seem to work. It's a silly way of modelling because the way that we've said this is our firms are competing over quantity. Our firms choose how much to produce and then the price is set by the market, which is, I would argue, not in accord with our natural intuition about the way that firms work, where firms choose a price and then they sell however much they can sell at that price, which is how presumably firms work. Um, and so Bertrand competition, where there's tonnes of time permitting, so that's good. I didn't expect there to be, I just wanted to cover myself. Birch and competition where there's where there's uh birch competition. Deals with that issue about the modelling being really weird, um, and so, we have our firms, they're competing, they're producing homogeneous goods, but we're gonna choose prices. So our firms are gonna compete by picking a price and then our, our consumers come and they see the prices and the way that the competition's gonna work is that they see the prices and they buy from the firm, if they buy, they buy if they want to, right, so according to demand, if they want to, from the firm that's charging the lower price. Right, so there's a, there's a massive there's a hypothetically, the way we're thinking about this is there's a mass of consumers, which all have different marginal benefit, marginal utility from consuming the good. They come to the market and they say, my margin utility is $3 and this product costs $4 and that product costs $2 I'm gonna buy the $2 product because it's cheaper, or I have marginal utility of $6 and the goods cost $8.09 dollars and I buy nothing because they're both too expensive. Um, so we buy from the cheapest, uh, we, we, we, the quantities are set by the market, so it all production is cleared. If one price is lowest, everyone's gonna buy from that firm, because if, Firm one is charging $2 and firm two is charging $3. It's not like there's some people that just decide to pay the $3 everyone buys from the $2 firm. So we had a discontinuity here, right, between charging less than someone and not charging less than them. Um, so everyone buys from the lower priced firms. If the price is the same, sales are split. The firms understand all this, and they maximise profit rationally. We are gonna have a marginal cost here, it's important for this analysis, but we'll just have a constant marginal cost to keep things easy. So little C is the cost of producing each, each good. And this is Bertrand competition, so it's another way of thinking about duopolies. Any questions on the structure of this? Structure of the model, it's part of the structure model, it's part of the structure of the model. Demand here for for firm one looks a little bit uh looks a little bit annoying, um, because overall demand is is a 100 it's sort of P equals 100 minus Q, um, but we need to think about our our demand function a little bit. We're gonna break it down into little pieces, like this is the overall thing, but we can break this down to pieces so it's a bit more, bit more explicable, right, if, We're the cheaper option. Remember demand This is our overall demand based on quantity and quantity and price. If we're the cheaper option. Everyone who buys something buys from us. If we're the cheaper option, everyone who buys something buys from us, and so the amount we sell is $100 minus the price, right, we picked the price, we charge $10 and so we sell 90 units. So we're the cheaper option. If we're the more expensive option. If we're the more expensive option, then no one buys from us, right? Yeah, we we, yeah, we charge $10 but also the other firm charged $8 so like. Why would anyone buy from us, no, no one buys from us. And if we're both charging the same price. Then we split that demand, and the total overall demand is going to be 100 minus the price that we've both agreed that we both end up charging, but we each get half of that. So this is why we get the, the middle one, right, if the prices are exactly the same, then, We each take half of the total amount, total size of the market. So we do get a bit of a weird looking demand function, but it's just because we have this, this flip that happens at the price being the other person's price. If we charge a little bit more, we get no sales, charge a little bit less, we get all the sales, if we charge exactly the same, then we split the market. Questions, concerns? As before, we're gonna take our profits, and our profit is revenue minus costs, there are now costs, right, so we do have C times Q1 for the cost of producing, cost for firm one to produce Q1 units, because there's a, there's a marginal cost of production. Questions, questions, concerns, structure here. So if this is the case, what are our best responses going to look like? Because our best responses here are gonna look a little bit odd. I think I've simplified the best responses here, yeah, um, I thought this one's gonna look a little bit odd. I think graphically it's gonna be a good way of doing this. marginal cost. Let's put some numbers cos it's gonna be easier. If our opponent Is charging 20 bucks for the good. Right, you're probably charge $20 for the good. What's the best thing you can do? You don't want to charge $21 for the good cause then you sell nothing, which is terrible, right? You don't really even want to sell it for $20 because if you sell it for $20 you're gonna be splitting the market with them evenly. What you wanna do is you want to sell the good for $19.99 right, as close as you possibly can to what the other person's saying, then you get all the market and you also, yeah, then then you take home all the market but keep the price as high as you can conditional on the fact that you get to take home all of the market. That works as long as the price your opponent's charging is more than the marginal cost, right, because if it costs $2 to make each good and your opponent's charging $2 then there's no more scope for you to undercut them, right? You can't charge $1.99 because then you're losing money on every good that you sell. Um, so your best response is a reasonably straightforward idea of sell, charge a price that is a tiny bit less than your opponent. As long as that amount is still more than the marginal cost, or as long as that, I, I should say, as long as that amount is not is not less than the marginal cost, it's probably the better way of saying that. So a little bit less than the as long as you're not going below marginal cost. Is gonna be our our our best response. The problem is, if we're focusing on equilibrium, on Nash equilibrium, which is our our solution concept for most of these kinds of things, that really limits us quite badly, um, because any price, if I'm charging any price, You're gonna undercut me, the only way that you can't undercut me is if I'm charging marginal cost. I'm not gonna charge less than marginal cost, then my profit's negative and I would prefer to exit the market, but I could, if I charge marginal costs, profit's zero and that's, that's OK, right, um. And there's no way for you to undercut me. So if I'm charging marginal cost plus a little bit, it's not gonna be an equilibrium because you're gonna undercut me, and if you undercut me then I'm gonna want to undercut you. And if I undercut you, you're the one wanna undercut me, and there's not gonna be any way to get an equilibrium outcome going. The only way to get an equilibrium outcome is for both people to charge marginal cost because it avoids that capacity for undercutting. Um, And this is the outcome that we get for Bertrand competition, right, if firms are competing over price, both of our firms, even if we only have two firms, the price gets driven down to marginal cost. sort of Immediately or instantly or or however you want to phrase the thing in terms of equilibrium, the price, the only equilibrium price structure is prices marginal cost. Which is spectacular for consumers, right, because from the consumer's perspective, this price is as low as it could possibly be. And total surplus is maximised, social welfare is maximised, this is, this is great for the, for the society, um, it's bad for the firms because the firms make zero profit. Um, there was a question, is there a question here? OK, Um, this is, this is virtual competition, right, this is another way of working with um of of modelling duopolies. Any questions on the modelling of this one, yes. Because if you're charging a fraction above sea, you're how, how big a fraction are you charging above sea? Right, so that's the question is, is there, is there a smallest possible fraction? Um, so the way we typically the way we typically do mathematics modelling, whatever, um, there is no there is no such thing as a smallest possible fraction, right, if you're charging a cent more than C, then I can charge 0.5 a cent more, and then you can charge a 25% of a cent more, and I can charge 1/8 of a cent more. Um, and so I, I, I see where you're coming from. And in practise, you'd be talking about these firms charging, you know, 5 cents more than cost, um, but in terms of just the modelling itself, it is the the only outcome we get as an equilibrium is that they charge at marginal cost. Profit's still 0 at if they're charging at marginal costs, and so the firm is indifferent between doing this and leaving. But there's no positive incentive to leave. Um, so again, Nash equilibrium is there's no positive incentive to deviate. This firm is making zero profit, they don't, they can't do any better than zero profit, so they don't need to change. Is that, yeah. I think, sorry, yeah. Yeah, so the question is what happens to you if you extend out to end firms. If you extend this to end firms, Birch and competition, it makes no difference, right, because in Bertrand competition we're we're already working in a world where price gets pushed with two firms, price gets pushed down to marginal cost, um, and so we already have perfect we already have the outcomes of perfect competition even with two firms. With C no competition. It's a really interesting question, and it's a question you'll address mainly in your tutorials. So it's, it's a, it's a, it's a good question, which is why it's one of the two questions um for this week, um. Excuse me. Uh, the quick answer being The, the Slightly longer answer being, It's a very good thought, and we should check to make sure to see whether it's true or not, because there are circumstances where we, where we have models where taking N firms, as N gets very, very big, looks like perfect competition, looks like infinitely many firms. But there are other models where. doesn't happen, um, and so whether this one is one of those models where lots and lots of firm where you know, N goes to infinity looks like infinitely many firms, or when this whether it's a model where N goes to infinity doesn't look like infinitely many firms is something to investigate and worry about. And you'll find out in tutorials which one this is. OK. Following on more from your question, I think actually is I want to talk a little bit about modelling for a second. Right, both of these models are trying to capture our idea of duopoly competition. Right, they're both saying there's two firms and they're competing by producing homogeneous goods. How are they competing, so the premise is different. Um, what's, so the premise, right, the premise is similar, right, firms competing. Two firms competing onerous goods. The modelling choice is a bit different for these two firms, it's clearly different for these two firms, right? In one case we talk about firms produce and then price is determined by the market and the other firms choose a price and production level is determined by the market. Um, both. Can be argued for, right, you can, you can make outside of model arguments why you might want to model a particular problem as firms choose quantity, take the quantity to the market and then and then price figures that out, price figures out what you're doing. In the long run, that seems like a maybe a better system because like, if you're a farmer, you, you, you make your goods and then you take them to the market and, and figure out the price that works that lets you sell all of it. Um, and then if you're making lots of profit, you'll produce more stuff the next year, or if you're making bad profit, you'll make less stuff the next year, right? Um, and so there is kind of a, a, a, a realistic idea there. But certainly for short-term things, Bertram competition seems pretty reasonable, right? You have your stuff, you've made it, you're going, you have your stuff, you've made it. Oh sorry, um, not that, not that at all. You go into the market, you, you have the price that you want to charge, you post the price and then whatever sells sells. And that seems also pretty reasonable. So these are not unreasonable things, but what's interesting is that the results are completely different. I mean completely different, right? Our corno duopoly had, had strictly positive profits, some dead weight loss, but less than the monopoly dead weight loss, um, And we can throw up and some, you know, some some profit but less than monopoly profit, whereas our Bertrand competition, Had totally different equilibrium outcome, which was everyone charges at marginal cost, and all profit is zero, and there's no dead weight loss and everything's grand, right. And so the results are completely different, right? So results can change the the the moral of all of this story. Do I wanna do this? No, probably not. The moral of this story is results can change a lot depending on the modelling assumptions that are made, right? Um, if you go and you see modelling, sometimes, you know, you see this, people say I have modelling that shows this, and you're like, cool, how did you do that modelling, right, what assumptions did you make to end up with the conclusions, right, did you assume, In your model of duopoly that all competition was Bertrand competition and therefore that there was absolutely no need for more than 2 firms, or did you not assume that, right, because you get different outcomes depending on the particular modelling that you use, um, so we need to be careful if we're relying exclusively on modelling. I think we are gonna actually call sequential games a, Time permitting that we're not going to permit, so we won't worry about the sequential games component. Um, if you would like to ask us about sequential games, we're happy to talk to you about sequential games, but we won't include it as part of the course for this year. Are there any questions about our continuous action games and how we might think about them? Or anything else we've talked about today. Lovely, one more thing, one more thing, don't flee. Um, next week, as dis as discussed, next week will be a revision week. Um, so in in both lectures, because when the exams in both lectures we'll be doing revision, um, I will be posting a discussion forum thread where you can ask questions. In those weeks, I'm very happy, I, I, I'm ecstatic to take questions from the floor. I'm also very happy to take questions from the discussion board posts. If you have questions that you really, really want covered, I'd recommend chucking them on that discussion board post cos then I can prepare for them properly, um, whereas from the floor is it is a bit more ad hoc, obviously. Um, so that's what we'll be doing for next week. Uh, if you have any issues, you can come see me now, otherwise we have a 7 minute early mark, so enjoy the rest of your day in the rain. Thanks.
