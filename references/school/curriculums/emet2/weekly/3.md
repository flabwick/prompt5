**Unit 1: The Sample Average and the Central Limit Theorem (CLT)**

*Concepts and Ideas:*

* The sample average ($\bar{Y}$) as a random variable
* Mean of the sample average: $\mathbb{E}[\bar{Y}] = \mu$
* Variance of the sample average: $\text{Var}(\bar{Y}) = \frac{\sigma^2}{n}$
* Standard deviation of $\bar{Y}$: $\sqrt{\frac{\sigma^2}{n}}$
* CLT: Regardless of the distribution of individual $Y_i$, $\bar{Y} \sim \text{Approx. Normal}(\mu, \frac{\sigma^2}{n})$ when $n$ is large
* Exact normality if $Y_i \sim \text{Normal}$
* IID assumption for CLT validity
* The use of histograms to demonstrate CLT numerically via simulation
* Normal approximation visualised using exponential distribution as a base for $Y_i$
* Standardised form of $\bar{Y}$: $Z = \frac{\bar{Y} - \mu}{\sigma / \sqrt{n}} \sim N(0,1)$

*Methods Expected:*

* Derive mean and variance of $\bar{Y}$
* Identify when CLT applies
* Standardise $\bar{Y}$ using known $\mu, \sigma$
* Use simulation or histogram as a visualisation tool to understand convergence to normality

*Non-required/Off-syllabus:*

* Derivation or memorisation of specific PDFs (e.g., exponential, gamma, binomial)
* Applications beyond the sample average (e.g., sums or medians under CLT)
* Formal proof of CLT

*Relevant Visuals:*

* Diagrams: Histograms of sample means for varying $n$ (e.g., 5, 30, 100), compared to standard normal curve
* PDF curve of the exponential distribution
* Overlay of standard normal on standardised histograms

---

**Unit 2: Hypothesis Testing for the Population Mean**

*Concepts and Ideas:*

* Null hypothesis $H_0: \mu = \mu_0$
* Alternative hypothesis $H_1: \mu \neq \mu_0$
* Use of sample mean $\bar{Y}$ as estimator for $\mu$
* Test statistic: $Z = \frac{\bar{Y} - \mu_0}{\sigma / \sqrt{n}}$
* Use of sample standard deviation $s$ to estimate $\sigma$
* Critical value for 95% significance: $\pm 1.96$
* Definition of rejection region using tail probabilities (2.5% each side)
* Probabilistic reasoning: sample mean as one draw from a distribution
* Decision rule: reject $H_0$ if observed $\bar{Y}$ lies outside critical region
* Importance of randomness and sampling variability in inference

*Methods Expected:*

* Conduct a one-sample z-test using known $\mu_0$, $s$, $n$
* Determine rejection region and p-value via standard normal distribution
* Assess whether sample evidence supports or contradicts $H_0$
* Interpret test result probabilistically (not deterministically)

*Non-required/Off-syllabus:*

* Formal p-value computation beyond rejection region logic
* Tests at significance levels other than 5%
* Use of t-distribution instead of z-distribution

*Relevant Visuals:*

* Standard normal curve showing $\pm 1.96$ bounds
* Shaded rejection regions in tails
* Plot showing observed $\bar{Y}$ on the distribution

---

**Unit 3: Confidence Intervals for the Population Mean**

*Concepts and Ideas:*

* Confidence interval: range of plausible values for $\mu$
* 95% CI formula: $\bar{Y} \pm 1.96 \cdot \frac{s}{\sqrt{n}}$
* Interpretation: values of $\mu$ consistent with observed $\bar{Y}$
* Connection between CI and hypothesis testing (CI excludes $\mu_0$ ⇒ reject $H_0$)
* Estimation of $\sigma$ using sample variance $s^2 = \frac{1}{n}\sum (Y_i - \bar{Y})^2$
* Role of large $n$ in robustness of $s$ estimation
* Distinction between $s^2$ and unbiased estimator (dividing by $n-1$)
* Definition of standard error (SE): estimated standard deviation of $\bar{Y}$, $\text{SE}_{\bar{Y}} = \frac{s}{\sqrt{n}}$

*Methods Expected:*

* Calculate confidence interval for a population mean
* Estimate standard deviation using sample variance
* Use confidence interval to assess hypothesis consistency

*Non-required/Off-syllabus:*

* Alternative confidence levels (e.g., 90%, 99%)
* Small-sample adjustments (e.g., t-distribution with degrees of freedom)
* Exact derivation of sampling distribution for non-normal populations

*Relevant Visuals:*

* Confidence interval line centered at $\bar{Y}$, extending $\pm 1.96 \cdot SE$
* Overlay of hypothesised $\mu_0$ for comparison
* Comparison of two confidence intervals (when comparing two groups)

---

**Unit 4: Statistical Inference and Estimation Theory**

*Concepts and Ideas:*

* Definition of statistical inference: learning about population parameters from a sample
* Parameter: fixed unknown value (e.g., $\mu$), estimate: observed value from estimator
* Estimator: rule/procedure, e.g., $\bar{Y} = \frac{1}{n} \sum Y_i$
* Estimate: result of applying estimator to sample, e.g., 50 kg
* Estimators are random variables; estimates are numerical values
* Expectation of estimator $\mathbb{E}[\hat{\theta}]$
* Bias: $\text{Bias}(\hat{\theta}) = \mathbb{E}[\hat{\theta}] - \theta$
* Unbiasedness: $\mathbb{E}[\hat{\theta}] = \theta$
* Variance of estimator: variability across samples
* Tradeoff between bias and variance
* Efficiency: within class of unbiased estimators, minimum variance
* BLUE: Best Linear Unbiased Estimator = linear, unbiased, minimum variance
* Gauss-Markov theorem: $\bar{Y}$ is BLUE for $\mu$

*Methods Expected:*

* Identify whether an estimator is biased
* Compute bias and variance of estimators
* Demonstrate that $\bar{Y}$ is unbiased
* Apply Gauss-Markov logic: no other linear unbiased estimator has lower variance

*Non-required/Off-syllabus:*

* Bias-variance tradeoff visualisation or curve
* Formal proofs of Gauss-Markov
* Use of non-linear estimators

*Relevant Visuals:*

* Distribution of estimator values centered (or not) on true $\theta$
* Histogram of simulated estimates from repeated sampling
* Diagram comparing two estimators: one biased, one with higher variance

---

**Unit 5: Comparative Confidence Intervals and Differences Between Groups**

*Concepts and Ideas:*

* Comparing means across two independent samples
* Estimator for mean difference: $\bar{Y}_1 - \bar{Y}_0$
* Variance of mean difference: $\text{Var}(\bar{Y}_1 - \bar{Y}_0) = \frac{\sigma_1^2}{n_1} + \frac{\sigma_0^2}{n_0}$
* Standard error of difference: $\sqrt{ \frac{s_1^2}{n_1} + \frac{s_0^2}{n_0} }$
* Confidence interval for mean difference: $(\bar{Y}_1 - \bar{Y}_0) \pm 1.96 \cdot \text{SE}$
* Application to policy or intervention evaluation (e.g., prep course impact)
* Independence assumption between two samples
* Using sample standard deviations in place of population values

*Methods Expected:*

* Construct a confidence interval for difference in means
* Calculate standard error for difference in independent samples
* Test whether difference is statistically significant
* Interpret inclusion/exclusion of 0 in confidence interval for difference

*Non-required/Off-syllabus:*

* Paired samples
* Tests for unequal variances (Welch’s t-test)
* Bootstrap confidence intervals

*Relevant Visuals:*

* Side-by-side CIs for each group and their overlap
* CI for difference showing whether 0 lies within bounds
* Tabular comparison of group means, SDs, and CIs

---