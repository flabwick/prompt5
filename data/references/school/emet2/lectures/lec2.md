SPEAKER 0
This material has been reproduced and communicated to you by or on behalf of the Australian National University, in accordance with Section 113% of the Copyright Act 1968. The material in this communication may be subject to copyright under the Act. Any further reproduction or communication of this material by you must be consistent with the provisions of the Act. Do not reproduce this material. Do not remove this notice.

SPEAKER 1
All right everyone, good afternoon. Hello. Nice to see you again. Um Well, let's continue doing econometrics. Let's quickly run through a bunch of housekeeping slides, and then we've got a lot to cover. All right, here. So this is just some information that you saw last week already. With uh some consultations added, um, there'll be a wattle announcement later this afternoon as well, so. Just Have a look at the consultations that the tutors offer on Thursdays in weeks 2 to 5 and Fridays in weeks 6 to 12. But like I said, there will be a water announcement this afternoon. Uh, quickly, some FAQs. That might help you for the next weeks. So what's this one here? I am unable to attend my regular lab this week. Um, what should I do? And I told you last week, just go to another one, OK? That's it. Maybe tell the tutor whose computer lab you're visiting that you're just visiting for the week. Then you go, oh, but I can't attend any of my labs this week. What should I do? OK, here's the advice. Students who, through unavoidable and unplanned occurrences are unable to attend a computer lab. Or any of the labs in a week, are expected to work through the Jupiter notebook on their own. Or supported by their classmates who have been there, OK? You go and you do this not, let's say this happens this week, you don't wait until week 7 to catch up on this week's lab. You do it as soon as you can, right? And you go, I can't do it on my own, then you come in. Visit us during consultations, OK? So that should address that. Oh then, another, another thing, another housekeeping item. It's a bit, bit early, but, uh, since the next lecture is already, uh, will, will take place when the quiz will have opened by then, so I'm announcing it already now, but I'm showing you the same slide again next week. So currently we're in week 2, just so nobody stresses, but you would know this. In week 3, there will be a water-based quiz, OK? There will be 50 multiple choice questions that you have to click through, and you have 60 minutes to answer them. This is historically not a binding constraint. OK. The average student needs 40 minutes or 30 minutes or much less than 60 minutes, OK? But once you start an attempt, 3 clock Counts or ticks, ticks down, right? So you've got 60 minutes. And what else Um, the quiz will be available from 9 a.m. next Wednesday. By next Wednesday, I mean the one in week 3, and it shuts down at 3 in the afternoon on the Thursday of week 3. Now that would mean, by the way, that if you start your quiz at 2:45 Thursday afternoon, how many minutes do you have? 15. OK. So that's why I'm putting this warning there. Don't start after 2 o'clock on Thursday, then you will not have the full 60 minutes. You can, but um what I'm saying is you will have less time. You, you have less than 60 minutes. Does that make sense? But altogether, you have a relatively broad time window to start the quiz. And when we meet next week, the quiz will be open for you to attend. The quiz covers only the week 21 and 2 materials, and when I say 1 and 2 materials, everything that the lecture and the workshop and the computer labs have covered so not what we will be doing in in in next week's meetings. Any questions on this? I will also make a wattle reminder next week so that nobody, nobody can possibly forget about the quiz. Yeah.

SPEAKER 2
If content from readings aren't included in the lecture, are those also tested in the.

SPEAKER 1
It's really close to what we do in the lecture and the workshops and maybe broadly the lessons of the computer lab, although for this for this quiz in particular because we haven't really been doing much in the computer labs, don't expect too much of that, but it's it's quite close to what we do in the lecture and then in the workshop session of today. Any other questions? All right, so I'll remind everyone next week. And then quickly, I told you this, you know this, please get Python ready. Um, have people tried this and been successful? OK, so I've seen nods. OK, good. All right, awesome. So the two, sorry, the computer labs start, uh, next week, tomorrow, and uh. And then there's another one on another bunch on Friday. And hopefully it will go well. I think that was the last housekeeping slide. Any other questions? No, good. That's Do econometrics, we've got a lot to do and I'm gonna go fast. So how does that work again, you know. All right. Central limit. Theorem. Let's race through this. We have figured out last week. Um, These what I call three parameters for the sample average. The sample average we understood was a random variable, so we were interested in its mean, in its variants, and then as a byproduct, its standard deviation. And we worked out that the sample average has the mean mu. What was that? Where did that come from? The individual YIs. Of which the sample average consists Have a mean of mu, OK. And the cool feature about the sample average is that its mean is the same as the mean of the individual Y subscript Is that the sample average is composed of. That is not true for the variance. For the variance, you have to divide by N, which is actually a cool feature of the sample average. The process of averaging. Across the sample of size and decreases the variance. All right. Now, now we turn to understand, so we've worked out these parameters, we turn to understanding. It's statistical distribution. I'll give you a generic notation here. So we do understand that the sample average is a random variable, so it has some sort of distribution. Most of us suspect. It's going to be a normal distribution in some way, but currently I just have a generic placeholder P for some statistical distribution around a known mean of new because we've worked this out and a known variants of sigma squared over. But what is P OK, we all, we all know what we're working towards, but let's, let's uh go through this. So what is P actually? So I'm just throwing out a few. Not throwing out but you know just naming a few distributions that you might know from stats like the binomial, the normal, the logistic, the exponential distribution. I'm not saying that you should be able to write down all of these PDFs. That's not what I'm saying. You can do that in a stats course. But the question is Perhaps the distribution of Y bar depends on. The precise distribution of the YIs that enter Y bar. So, and that in a way is true. The exact and the word exact here is important. The precise lash exact distribution of Y bar will depend on the distribution of the underlying YIs that enter Y bar. So then you might go, maybe well, maybe this year could be correct, it isn't. If the underlying Y1 through YN are binomialally distributed, maybe that would mean that Y bar also has a binomial distribution. All of these statements, almost all of them are false. So let's go to the last one. What if they're all gamma distributed? Does YR have a gamma distribution? No, it's not that easy. Actually easier than that. Um, only one statement here is true, is it? The one where the YI's have a normal distribution. Then indeed one can show that the sample average will also have a normal distribution, exactly. The correct version of this slide is. This one here. And the, the big statement is Whatever the distribution of the individual YIs, Y bar will almost have a normal distribution. By almost, I'll use a fancier word here approximately. Approximately have a normal distribution. In one instance, the word approximately. Is not used, and that is when the individual YIs are normally distributed, then YB is not just approximately, meaning almost normal, it is exactly normally distributed. So in only one situation, does YA really inherit the distribution of the underlying YIs. But the overall news here is good. Whatever the distribution of the individual YIs. Why a bar will approximately have a normal distribution. That's pretty cool. OK. Now, does this look surprising? I guess it doesn't look to you because you did stats. So where does this come from? The stats from the central limit theorem and the statement here is this. Given an IID random sample, the sample average has an approximate normal distribution. Irrespective of the underlying distribution of the I's. And then one qualification when YI is normal, then we can replace the word approximate with the word exact. All right. Here is the statement of the central limit theorem for applied to Y bar, our sample average. Um, I guess it's just a tech, more technical looking restatement of the previous slide. So why bar is Approximately distributed normal around, we, we, we worked out the rest here inside the parenthesis around mean mu, and variant uh sigma squared over N. All right. Good. And here's the standardised version by which I mean if you subtract of the bean and you divide by the standard deviation, the resulting standardised version of the sample average has a standard normal distribution. Practical meaning of the central limit theorem. When the sample size is large, the sample average has almost a normal distribution. Around the population mean new, with the variant sigma squared over N, irrespective of what the underlying distribution of the YIs is. By the way, that's pretty cool because we don't usually know the distribution of the YIs. So, for example, your heights. I have no idea what the population height distribution is. It's not normal. OK. And I don't need to know. Once I average your height, I know that object has a normal distribution. When is N large enough? OK, I'll give you a little. Computer simulation to convince you that And can be large enough relatively soon. Here, let's, let's try to make sense of this. Here, what I'm giving you is, what am I giving you? Sample averages that are based on the YIs from an exponential distribution. I'm not saying you need to know what an exponential distribution is. You probably do. This here in the top left is the PDF of the exponential distribution where the which is governed by one parameter, often called lambda, which is set to one. That means for the exponential distribution that it's a mean one random variable. The point is, I'm giving you Individuals that have a very non-normal looking distribution like this here is not the bell curve. Do you see that? OK. But once I average random variables of that type, I arrive at something that looks like the bell curve, the normal distribution. But what am I doing here? So in the, in the, let's take. Now, well, let's take this picture, bottom left. This is my example where I'm going to Tidbinbilla 1000 times, and I'm collecting samples of size 30. Now, kangaroo weights will not have an exponential distribution, but uh let's ignore that for, for a moment. So, I, I plot the histogram of what? So I'm going there 1000 times. Luckily just in my head. Collect every time 30 kangaroos at random and average their weight. Write down that one number, one average. So 55 kilogrammes and I go for the second time, do the same exercise, do this a 1000 times, and I plot to histogram and that's how it looks like. OK, and this actually is centred at one, which was, I, I'm using my knowledge of the PDF of the exponential distribution. It, it has been one here, the one, the one that I'm that I chose here. So likewise, you can see if I go to a tidbinbilla 1000 times and I collect instead of 30 kangaroos every time, I collect a sample of 100 kangaroos, the approximation here doesn't actually look better, but it should eventually look very smooth. OK. And you also see if if you did this by collecting 5 kangaroos, which is the middle left picture, you go there for 1, 1000 times. Every time you collect 5 kangaroos, you obtain 1000 sample averages that are based on a sample size of 5. This is how the histogram will look like. Do you guys sort of see how this represents a numerical illustration of the central limit theorem. And what I want to show you here in particular is this, we start with a very non-normal looking distribution, the exponential distribution. But sample averages derived of it are very normal looking. And then the next slide, it's just the standardised version of that. So you can put it under the standard normal distribution, which, which is the dash line. And here you see actually that in the bottom right picture, the, the histogram fits a little bit better under the, under the standard normal um PDF. Any questions? I think it's pretty cool. And it's easy to do on a computer. The computer can go to Tidbinbilla 1000 times in like 0, 0.001 seconds. OK. So, there you go. All right, what do we do with this knowledge? I would say for us, mostly hypothesis testing. Why do we want to know the shape of the distribution to do hypothesis tests? All right, so whenever we calculate a sample average, we need to remember that it could be interpreted as the outcome of a random variable. So we do know the sample average is random for a different sample, we would have obtained a different value of the sample average. So now I'm using an example for my boring real life and I go, um, I'm asking myself. It's the bus schedule that the bus company. Puts at my bus stop, is it accurate or is it false? OK. So they go, at your bus stop, Jurgen, the bus arrives, for example, I pretend like I'm going to work at 8:10 in the morning. Um, so the bus would leave at 8:10 in the morning. I, being a nerd. took the bus, let's say for 30 days, collected 30 observations, wrote down the numbers, and came to the conclusion that the average Bus arrival time is 8:14. This is a completely made up example in fairness to the bus company. OK. So the end of this will be Painting a bad picture about the bus company, but this is not true. OK. This is what do they call it? Only based on real experiences or was it motivated or they say it in Hollywood movies where it's not quite true, inspired by real events that weren't so real. In any case, the question is, what is the question? Um, is the bus company lying to me? So my, my parents having no knowledge of statistics, they would go, clearly they're lying to you. Your average is 814. Therefore, the bus company has to be lying. That's what my parents would say to him, throwing my parents under the bus. Um, they, they don't understand statistics. Because we understand 814 is the realisation of a random variable that could accidentally have been quite negative for the bus company. Maybe another random sample would have averaged out to 808. Right, I, what I would need to do is collect 1000 samples of size 30, but I, I don't do that. OK. So, and we don't usually do that in practise. We only have one random sample, but how can we use 11 random sample to judge about the unobserved population parameter. So this is hypothesis testing. So, the bus company claims that the population mean is 8/10. So I'm transferring this time to a real number or an actual number. My sample average is 814. What can I do with the central limit theorem? So we do understand my realisation could be a random, well, it's the outcome of a random event that could have been a different number for a different random sample. So we have to factor that in. There's a standard error around. Um Let's say the population mean. Um In any case, we only have one random sample with 30 observations that average out to 814. I do not know the actual distribution of the underlying YI so that I don't know the bus arrival time distribution, but thanks to the central limit theorem, I don't need to know. OK? As soon as I average, I get a normal distribution. So the CLT says, and this is hypothesis, if the bus company is not lying to me and the arrival time is age 10. And an oracle tells me that the unobserved population variance, just bear with me, um, I have this thing called an oracle that helps me out whenever I've got problems. Um, but I'll take that away in a second. And an oracle tells me, uh, the variance is 45. So with that information, I can go run and go, so therefore, under the central limit theorem, my sample average has this distribution. Does that make sense? Hello? OK, let me go slow. The population mean is 810 under the information of the bus company. Then I could ask the bus company, what's the variance, or I could ask an oracle and they tell me it's 45. So I've got all the information to plug that into the central limit the to get a distribution on my sample average, and we know the mean is 810. The variance is sigma squared over N. So I go 45/30 looks like this. This is the distribution F. If the population mean is 810 and the population variance of the underlying YIs is 45, then the Y bar distribution will be normal, 810 with variance 1.5. Variance is by a factor of 30 smaller, right, because you average by 30. And you go, the big picture is this. All these arrival times, that's so, especially here in the middle, so from 8:08 to 8:12, seem quite likely to occur. But the way I constructed my example, I collected an an observation of 814, which is in the unlikely range, OK? But we have to now define what do we mean by unlikely. But the big picture is this is where I threw my parents under the bus, and they go, as soon as you tell them the average is or my realisation is 814, they go, therefore they must be lying, but we go, well, there's a whole distribution of values of sample averages that you can obtain that are consistent with what the last company told you. But some values are more likely the ones here in the middle, in the middle, in the middle, and some values are not so likely the ones in the tail. And what the statistical testing does it basically defines relatively random or not randomly arbitrarily cut off values for you to make this judgement call of what is what is likely and what is unlikely, what is sufficiently likely or sufficiently unlikely. And you all know, it will have to do with the 5% cut off or 2.5% on both sides. So if what the bus company claims is correct. Then it would be very unlikely for me to obtain a sample average of 814. That's just based on looking at this picture, because 814 is out there in the tail. Yet I have obtained. A realisation of 814. So I can conclude that the bus company is probably misstating and this is important that I will have the word probably in there, right? The actual mean bus arrival time. So while it is possible, it is not probable, OK? Um, so this is an example of a probabilistic conclusion. So what am I doing here? All right, now I'm turning this into a statistical test. So we've just conducted our first hypothesis test where the null hypothesis was that the truth is a 10, and the alternative is that it isn't. If the sample average that we have obtained, the one sample average, It's too far away from the hypothesised population mean, then we can we conclude that the null hypothesis is probably not correct. In that case, we reject the null in favour of the alternative hypothesis. The question now is only what is too far? And we all know too far is if you are so far in the tails that you're sort of in the 2.5%. Uh, what is the tail probabilities on, on both sides, which here happens to be the case. So how far away can my sample mean my realisation be? What do I allow? If the true sample mean that I obtain has less than a 5% chance to occur under the hypothesised population mean we declare this too far. This is like a decision rule. It's a really arbitrary decision rule, but as you know, it's very conventional in statistics. Why is it 5%? Why is it not 4.3%? Um, any, any other number. And so what this means exploiting what we know about the normal distribution. Um, we take Everything's smaller than. The population means plus minus 1.96 times the standard deviation. Of the distribution of the sample average. So here I'm putting this in. Can you see that the tails are a little bit lighter and lighter coloured. So here my 814 is in that. The tale that is defined to be too far away from the population. So everything here between 807.6 and 812.4 is in the safe area, which we say, first of all, all values are consistent with the hypothesised population distribution because The normal distribution runs from minus infinity to plus infinity. The point here is realisations out there are so unlikely that we define this rejection region based on this 5% or 5% um tail probability uh which in this case translates to to this interval here. I think you get the point. So the sample average of 814 here does lie, this is the way I constructed it, it does lie outside the 5 the 95% area, the symmetric one, which is centred around the hypothesised true value of the population mean. So our sample average of 814 is unlikely to occur if the true population mean was really 810. We therefore reject the null hypothesis hypothesis that the true population mean is 8/10. This raises the question. What would the population mean need to be for us not to reject the now? Or in other words, which population would be in line with our sample average, and that takes us to the idea of the confidence interval that is centred at our sample average. So currently, our approach was to use one proposed. Hypothetical hypothesised value for the true unobserved population mean and compared to the sample average. And then have that cut-off rule to decide whether they're consistent with each other. If the sample average lies beyond 2.4 to the left and right, so 2.4 comes from, from these two numbers here. To the left and right of the population mean we conclude that the hypothesised population means it's probably not equal to the true population mean. But what population mean could be true given the sample average. So wouldn't it seem clever to construct this thing where you start at the sample average and look 1.96 times the standard deviation of the sample average to the left and right. And that is called the confidence interval. So here's the definition. A confidence interval for the population mean is the set of values the true population mean can be equal to for it. There's a mouthful here for for it not to be rejected at a 5% significant level, and I do believe in this course we really only use 5%. I can't recall any situations where we look at 1% or 10%. So we're safe with 5% in this course and That is expressed in using 1.96 here, obviously. 1.96 corresponds to the 2.5% Critical regions to the left and right of the central limit theorem, OK. So you take your sample average, you look 1.96 times to the standard deviation of the sample average to the left and right of the sample average. That is your confidence interval. And then you ask yourself, is the, so is the hypo hypothesised population mean in that or not? And go, OK, I gave you this definition and I had this weird. We construct called the Oracle earlier, which told us that sigma here. Uh sigma square was 45. In real life, there is no such oracle that tells us sigma squad. What do we do? OK. We do not know sigma or it's squared. That's the standard deviation of the YI's in the population. We do not observe the population, so we don't know sigma squared or sigma. So what we do, we replace it by the standard deviation in the sample, and this is its definition, relatively easy. The sample variance is the is the variance in the sample. So you take your bus arrival times and you let Python tells you the variances in the sample. And if we're interested, yeah, that's the uh sample variance. For the, for the formula earlier, we'll plug in its square root, which I think we'll, I'll show you in the next slide. There was a question that I received this week. Why am I dividing by N and not by N minus 1? Who knows? Who wants to divide by N minus 1? Most of you like, from stats probably want to divide by N minus 1, is that true? Or you felt like you didn't have an opinion on that? If you divide by N minus 1, what changes here? Yep.

SPEAKER 2
Mhm.

SPEAKER 1
Yeah, it's it's the degrees of freedom adjustment, the subsection of one. Yeah, so. It's like a whole sub discussion or stage show here is we regard as squared here defined like soul to be a replacement for sigma squared for the Greek letter. Using Squad computed from the sample like that will be a biassed estimator for sigma squared. Once you divide by N minus 1, it's unbiased. Did you?

SPEAKER 3
Yeah, with this you're using the population.

SPEAKER 1
This Yeah. Um, the population being dead.

SPEAKER 3
Um, I I'm, I hesitate with that just because aren't we trying to use the sample variants to disprove the fact that the population mean we've been given is like we're trying to say the population mean we've been given isn't true, but we're using it to prove. To, to solve the sample variances to then prove that the population is correct or not.

SPEAKER 1
So let me, let me see if I can make sense of my own slides here. The um the formula that we arrived at. So we want to use an operational version of this formula. We go, if the oracle tells us what sigma is the Greek letter here, it was the square root of 45, then we can calculate all the numbers. Then we go, but we don't have sigma, and then we use this guy here or it's square root to replace sigma. This here is calculated from the sample. Yeah, yeah. That's the, that's, so we will never know the population variance. So it's like my bus arrival time, so I get my 30 bus arrival times, and I can apply this formula here. I'm basically averaging over my 30 bus arrival times in this way, uh, so this quadratic average that is here by definition, you see the definition here. I call it the sample variant. This is an estimator for the population variance, which is the Greek letter sigma squared. And then As an estimator for that guy, this one that I write here is biassed. But now comes the big reveal. I don't care about its bias. OK, why not? Because for me, little N is a large number. So I give you a data set of size 20,000. Whether you divide here by 20,000 or by 20,000 minus 1. Do you see that it doesn't make a difference? It's a, it's an academic discussion. There we go. Aren't we at a university here? Yes, we are. OK. But this is a discussion that you had in stats. For all practical purposes, you can do whatever you want. Uh, this will not produce an interesting difference in your numerical estimates, OK? So that was, that's a nice little sideshow that we have here. But the focus is not for us. What is a good estimator for the variance? This can be interesting, right? But our focus is we want to estimate the sample average and its properties, and we use the sample variances as an ingredient in that. And whether we have a biassed or an unbiased version, I've just told you it doesn't actually make a big difference because the unbiased version results only by this degree of freedom correction where you subtract one here. If we're so indifferent between the two, why don't just

SPEAKER 2
use the.

SPEAKER 1
Just to confuse you guys. I, I don't actually know what the textbook does. Good question. But I, I mean, it's a, it's a good point, like a, I guess it wasted about 3 minutes, but uh There's a little bit of an insight here that, that's interesting. Uh, the proving that it is biassed slash unbiased is actually quite tricky. And not expected because it's a digression. We care about the sample average and use the sample variance here just as a tool to work out a confidence interval for the population mean. So we take the previous formula where we had the Greek sigma, we now plug in. The sample standard deviation. So just S. and this thing here, not divided by the square root of N has a special name. It's the standard error of Y bar. It is the estimated standard deviation of the sample average. So going back to this slide here, sigma over the square root of N is not typically called the standard error. Why not? Because this is not the estimated standard deviation. This is sort of what econometricians or statisticians would call the infeasible standard deviation. It's infeasible because you don't know sigma. Turn this feasible by plugging in the sample version of Sigma, which I called S here. And that is now a, a feasible confidence interval, where that, that thing here, S over the square rot has a special name, the standard error of YA. The generic rule for 95% confidence interval is always estimator plus minus 1.96 times the standard error. And you just need to know what the estimated standard error is for Y bar, it's given. Here Any questions? Could So this last expression for the confidence interval can be derived entirely from information that is contained in a sample. You're going back here, um, here, so this, this confidence interval, if I give you a random sample of bus arrival times, OK, you can get Y bar. It's just the average bus arrival time. You can get. I don't say subscript Y always from this slide here and square rooting it, OK, taking the square root, and N is the sample size, so you can calculate that and we do that in the 2nd hour today when we run through a workshop question. Um Yeah, good. All right, now, moving on, statistical inference. So what's the big picture here? So it's a bit of a step back, higher perspective on, on what we're doing here. The problem of statistical inference can be expressed like this. We want to learn something about the population. We do not observe the population for reasons I told you last week. It's too big, too costly, whatever. Um, instead, we are given one random sample. We're not given 1000 random samples. That was just a thought exercise, even one random sample. That random sample is a subset of the population. We use that one random subset to approximate or learn something about the population. The problem of statistical inference consists of using a random sample to learn about statistical parameters of the unobserved population. And what do we mean by statistical parameters? On the previous slides, it was the mean that we were interested in. But we just had this digression when we discussed. If you had to estimate the population variance, that could be a parameter of interest in itself. It typically isn't for us, but that could be an interesting parameter, so the variance. Moments, if you remember, moments where like higher order um expected values, like expected value of a random variable to the power of 4, for example. Covariances could be interesting. This is what we do when we run regressions. In, in at least 80% of all the cases, we're interested in the mean. The mean for me is this can actually be instrumentalized also to estimate regression coefficients as we will see. Um, next week or two weeks from now. So this lecture really focuses on, uh, on the statistical parameters that can be represented by means, population means. So for example, going back to my kangaroos. Suppose the park rangers want to know the answer to the question of what's the population mean weight, and they can't collect all their kangaroos, but they ask us as econometricians, use one random sample. Don't come 1000 times. Use one random sample and make your best guess. On what the population mean is. Um, So wouldn't it seem reasonable to use the average weight in our sample as our best guess of the population mean? This is where we're working towards, yes, the answer is yes. It seems reasonable, but there's, there's more tech there are more technical results required to to be established to actually give a convincing answer, but it does seem, you know, it doesn't seem like the worst idea for sure. I can, I can come up with many worse ideas. I'll do that in a second. So, this example illustrates common terminology. We are interested in a population parameter. In this example, the population mean. We have no hope of knowing this mean because we do not observe the population. The population mean is unobserved. We do, however, observe a sample average white bar. We use that as an estimator of the population mean. Given our particular random sample of 30 kangaroos, let's say my average takes on the value of 50, 50 kilogrammes. That is my estimate. OK, of this population mean. And then If we didn't continue the lecture for the next hour or so, and I asked you, what's your best guess for the population mean, you would say 50. That's given the data that you have. What's important, of course, is that the sample was random. You didn't collect. 30 kangaroos that looked very heavy. OK, that's a biassed sample or an unrepresentative sample, you sampled randomly. All right. Any questions? Estimators and their properties. I'm going at a good pace here. So this was just a soft definition of estimator. Now, Now, a more technical but still not too technical definition. I'm giving it a generic Greek name, Theda, with a hat on it. Hats oftentimes represent or signify estimators of things. An estimate theta hat is a procedure, that sounds odd for using sample data to compute an educated guess of the value of an unobserved population parameter theta. So the procedure is important. An estimator is not necessarily the number that you're getting at the end. But the procedure that you're applying to the data for our sample average. The procedure is called averaging the data. So it's Yeah, it sounds too complicated here, but there are many more estimators and procedures out there. We're using a very simple one here that it happens to be quite powerful. Averaging The number that you get when you apply an estimator to the sample data is called the estimate, the numerical value. So the procedure was I go to Tidbinbilla. And average the weight of 30 kangaroos. That's my procedure. That's the estimator. The estimate that we got in my example on the previous slide was 50. So another example, example. Example, I that to highlight the difference between estimate and estimate, but I think I just explained it. Um. Yeah, OK, here, I'm just repeating. An estimator is the, the procedure of sample averaging, and the estimate, if the example is, um, what's the population population mean of heights of you guys, um, let's say the population mean is 174, no idea. Uh, that's the estimate. OK. But I think you get the idea. Um, estimators are functions of the sample data, so we do understand from last time that they are themselves random variables. If you draw a different random sample, you apply the same estimator, meaning the same procedure, you're highly likely, not highly, but you, you're likely to get a different estimate. OK. It should be clear that most generally, this is important non-equality, that the thing that you're after theta is not equal to the thing that you You're using To to guess theta. So theta is not equal to theta hat. All right. And it could be, but you also never know because you don't know the left hand side. But intuitively, the left hand side is the population parameter you're after. And the right hand side, they had as the procedure that you apply and then evaluate. Apply to your data and you get a number, an estimate out of it, and oftentimes they're not the same, like with my, well, bus arrival times wasn't a good example, but. Um, if your estimate happens to be equal to the thing that you're after, you'd actually won't know it because you never know the population parameter. So the the object, the theta on the left hand side is what we're after. That's the unobserved population parameter theta here. We do not know that guy. We use theta hat and apply it to the data. That's our best guess for what the left hand side might be close to. For the sample average case, I'm just replacing theta by new and theta hat by bar. All right. Yeah, 2 more minutes, good. So let's, let's go through this slide. The sample average is not the only estimator for the population mean. So this is an important point now. For any estimation problem, you go, I want to know the population mean. There are infinitely many estimators. It's very easy to prove that here. You can nominate anything that you want as your estimator. Going back to the example of, now I'm going to your your the population mean of EAT 2007 students heights. Here are some estimators. I collect 30 observations from this room and use the height of the tallest student in my sample as an estimator for the population mean. I can do that, won't be a good estimator, right? That that hopefully makes sense. I could pick the smallest student, the shortest student. In my sample, can do that. It's not a good estimator. I can put the average height of students who identify as female, not a good estimator for the whole population. OK. My favourite one is this estimator, which I call the answer to everything estimator, which just says ignore the data. And your estimate is 42. Not a good estimator. And by the way, it doesn't have to be this particular number. It could be any number on the real line that convinces you that for any estimation problem, there's infinitely many estimators, right? So for example, the number 3 would also qualify. Um, and there's some other numbers as well. OK. So clearly, all of these are estimators, they use the sample data in various ways. And so for example, in Trivial ways, meaning they ignore throughout the sample data, the last one. OK. So they satisfy my definition given earlier. So clearly they, they are not, they're not all are sensible, these guys, OK? And the question that we have to turn to next is when is an estimator good? OK. And we will discover that the sample average. is the goodest of them all. We'll do that in the 2nd hour, and we do also turn to the workshop question in the 2nd hour. So 10 minute break and then we'll continue at 50.

SPEAKER 2
Uh. No. Yeah Yes Yes. Right Hi, how are you? uh. Yeah. Yeah. all very normal. Yeah. this is true. When. Yeah Yeah Yeah. OK, OK, so, uh, OK, so. I Yeah. OK. I. You just go with them like I said. Thanks. Are you? For real. But it was, it's like yes. It is it's a very treasury centralised. It's nice. Yes. Yes. I. I I. I'll And I'll tell you about that uh. I. right. I like Because. I say something. Yes. I. If you. Every I don't. I pointed you to the report. Yeah. Yeah. Yeah. that Yeah. Yeah. Yeah. It I. So. Yes. I I know what someone was doing. Yeah. You. Would you recommend Thank I. A. Like I said. And something yeah actually. Yeah. It was incredible thing, uh. No way. Well. like So really. will be that it's not. work All. I I know. I Yeah I Thank And. was So that's, that's so you wouldn't set. Yes. Yeah. that I. It's like There And Oh. Yeah.

SPEAKER 1
All right, let's continue. Shall we? Why not? Sooner we continue the earlier we can finish. Um The point is, the point of what? All right, there's infinitely many estimators, infinitely many of them are nonsensical. What is a good estimator? So we've got at least two dimensions of judging quality of an estimator. They are the bias, and you go, what, all of a sudden you care about bias. Yeah, I know, I'm, I'm inconsistent. And uh the, the variants. Let's look at these in turn. What is bias of an estimator? In the generic notation, if you have an estimator theta hat. If it has an expected value. First of all, it has an expected value. If the expected value coincides with the thing that you're after the, then that thing is called unbiased. The estimator is called unbiased. So the idea is this, if we draw lots of random samples of size and and we would obtain a lot of We apply estimator, the same estimator to 1000 random samples, like going to Titin Villa 1000 times. We get 1000 estimates, we plot the histogram. If that is anchored. Add theta, when that thing is called unbiased. This was true for the sample average, am I saying this here? No. Um, actually, so we arrived at this and the that's the final result, that's the big reveal. So, um, but do you remember when the estimator, which here is called theta hat, Is Y bar we figured out that the expected value of Y bar is actually new. So that is just a quick preview that Y bar as an estimator is unbiased and that will be one of our final results. Um, but the, the thought exercise is, is that. If you could somehow obtain 1000 random samples of size N. And you obtain 1000 estimates, applying the estimator to each of those 1000 samples. You get a histogram, and where is it anchored at? If it's anchored at theta, then that estimator is called unbiased. This is, this is a theoretical consideration, right? You never are given 1000 samples. It's a sort of a statistical slash mathematical property of an estimator to have, which here is deemed good. OK. Uh, I don't know what's going on there. So then. Staying with the unbiased estimates or estimators. So an estimator was a procedure that you applied to the data. An unbiased estimator for an unobserved population parameter parameter theta has minimum variance, so we call it minimum variance. If its variance is smaller than the variance of any other unbiased estimator, call it theta tilde. Of the So if the, if you can somehow show that it beats the variance of any other estimator theta tilde, then we call this estimator minimum variance. But what's important is that within the subset of unbiased estimators. So take my favourite estimator, the answer to everything estimator. What is its variance? 0 The answer to everything estimated beats the variance of all the other estimators. It's 0 But it's a very biassed estimator. Right? So that's why the qualification of unbiasedness here is important. So this throws out that estimator already, OK? So In the class of unbiased estimators, we are considering now the variants and we call, well, we, we would prefer an estimator that has a smaller variant, obviously if it's not costly, and such an estimator is called minimum variants are also efficient. Efficient is just another label for minimum variants. Don't, don't ask. Um, so if I, if I sometimes say is this estimator efficient, what I mean is. Not, is it easy to compute or whatever, the efficient means does it have minimum variance. 2 more slides. A quick detour here, a linear estimator is an estimator that is constructed as a linear combination of the sample data. Like the sample averages, for example. In econometrics, most of our estimators this semester are are um linear. And yeah, the obvious example is the sample average. And then a definition, a best linear unbiased estimator or a blue estimator is an estimator that is linear. So, linear linearly constructed from the sample data. Unbiased Like just defined and minimum variants. So it combines. The best of both worlds, the world of unbiasedness and minimum variance. Is there such an estimator? Well, the big reveal of course is if you are after the population mean. The sample average that we introduced last week is blue. There is no other linear estimator that is unbiased and has a smaller variance. You can spend days or weeks of proposing another such estimator, but you would be wasting your time. If this statement here is true. This one will do. OK, in the class of linear estimators. And only amongst unbiased estimators Y bar has minimum variance. Um, so this is a very important result, and that's also why we spent so much time talking about the sample average. And then I will also make, so this is the last slide I think, I will sort of always claim that what we then do later in the semester when we start running regressions, our regression coefficients are just sort of funky versions of sample averages. And then then they inherit. So when you're on a regression, you fit a line, the slope coefficients and the intercept. Let's focus on the slope. Inherit these properties. So what we're estimating from sample data when we run revisions produces. Blue estimators. What, what we, when we run regression, we, we, we get blue estimators. So just to give you a preview. So we're spending so much time here on to, to get this result, but we will be using this um later in the semester as well. Any questions? You guys learned this in stats, didn't you? No, what do you learn that? Don't tell your stats teacher. Um, but so it's, it's an important result. Um, the sample average is in a simple procedure and you can't beat it. At least if you stay amongst um the linear estimators. And you care about unbiased estimators. Sometimes we actually don't care too much about the buyers, and then the question is, can you control the bias? Anyway, Let's turn to the Um, To the workshop exercise where we now, we will play. Where's the picture? We'll play with this result. Are we sort of, we'll visit this result. Does it just take time now or? What's happening here? Oh yeah, OK. So this is, oh no, this is not good. Does it just keep doing it. Yeah, OK, and then what's it, please don't do this again. All right, this won't work. I don't know what to do. And now it's gonna go away. This is not really uh convenient. Um. Let me see here. Can I do it wirelessly? So I do know. Just bear with me. I think I need at least 5 minutes to work this out.

SPEAKER 2
In and I Yeah To OK Of I. And So Would it be possible to work with the white board of the? and then just upload a screenshots.

SPEAKER 1
That's a good solution. No, Yeah could you have like the thing that allows

SPEAKER 2
you to just like take a piece. The dock cam.

SPEAKER 1
Let's try this. Thanks Has do people have a piece of paper?

SPEAKER 2
Yeah.

SPEAKER 1
OK, let's let's first see if we can fire this up. Oh. Oh. Piece of paper. That's very kind and a pen, yeah, cool with different colours, awesome. I have to sit here, it feels lame. Alright. Now, let's see, doesn't it have a zoom out autofo? Oh yeah, cool. How can you guys see this? OK, right? All right. Headphones Maybe I'll do this every week and talk. So, what's the, what's the exercise? This is very old fashioned. So what have we got? So you see, do you, you don't see. I put this under here, how can you see that? All right. This is very clumsy, isn't it? Uh, so we've got this. This sample average here, um, in this line here. It's not the simple sample average. It is a weighted sample average. Do you see that? So we've got some weights are 1/2 or 1/2. On the odd numbered wise, and the even numbers get a weight of 3/2. So I guess I should write this down. So what we have, can you see this? It's called Ytilda, and it's defined to be 1/2 Y1 plus 3/2 Y2 plus blah blah blah. It keeps alternating to the end. Uh, we got 12 YN minus 1 + +32 Y N. And N here is Even Just to make our lives easier. Can you guys see this?

SPEAKER 2
You turn the flash, yeah.

SPEAKER 1
This thing here. Ah, is that better? Can zoom more Yeah There you go. All right, so the question is, what is the question? What's the mean and the variance of this thing? So let's do it. So we're interested in The expected value of Y tilde. So this is not Y bar. It's got a different name. It has weights attached. So what do we get? So, you go, well, all right, just as a plug-in exercise, you go 1/11, 2, blah blah blah, all the way to 3/2YN. OK, that is. Not too bad for my standards. So, what's next? What would you do next? Yes. Am I? Uh, no, I'm not sorry. Oh, I am, I am young. Um, yeah, thanks. Fixed, so we got uh. Division by In here as well. So what do we do? We could sort this into even and odd. Terms. That's my proposition here. So you go, how about you take Y1, Y3 all the way to YN minus 1. And let's leave that all in the expected value. So we have what have we got? We've got the. Odd terms Which are 1/2. Why I plus. The even terms. So this is not too technical, but it's pretty clear what I mean by that. OK. And so now you could, I can play with my colours here. Can put the one half here in front and the 302 here. In front, OK. And I'm doing an an extra step. I'll, I'll see this as The big picture is the expected value of the sum is equal to the sum of the expected values. I'm applying that here, so I get. Um, The expected value of 15. Just summing the odd YI's. Plus the and I'm going slow here, the expected value of 3/2, and the even ones. Now, be careful with my division by N, OK? Both need to be divided by N here. So What do I do that? I could just put brackets around this and go on over in here to not forget this, right? What's next? So I'm going super slow here, but now I can OK, you can see I can take this one half out of the expected value, right? And I can take the expected value inside the sum again. So, For example, one half sum of E of YI for the very odd. And then here, plus 3/2 some. EYI for the even ones and we have The division by N here. Now, what is you of YI? Every time This thing here, oops, is new subway and here. As well, because the YIs. Have the same distribution with mean mu. So what do we get? 1/2. Running over the odd ones. Muy plus 3/2 some, even ones muy 1 over N. Everyone happy? Now, if you evaluate this year. It's just the sum runs over the odd subscripts. Adding new each time, what do you get? What is the sum of new that runs the odd subscripts? That's just that's the only crucial bit here. Yeah. How many terms are you or how do you, how many times are you adding new to itself? N divided by 2. OK, so you get. One half And over 2 Me plus for 2 and same story here. Now, so cool. I have 4 colours. Thank you. Yeah. Oh yeah, thanks for warning me. Cause I don't see this. So I go, this end here. Kills this one and that one, so it's the mathematical term. All right. So what have we got left? Oh I'm I'm forgetting the subscript here, the sub Y. Cause I'm lazy. So what do we get? This, right? So the big picture here is This estimator is unbiased. Why Tilda is Unbiased All right. Yippee, right. So then next question is, In the In the oops class of unbiased estimators, can its variance be better than that of YA? No, we learned this and we'll show this now. OK. Let's do this. This, this is gonna be uglier. Um, where do we start? What could we do? Well, Do you guys have this? If I do this, will you be upset with me? Upset All, all good. So now I'll use the, I'll do the variance calculation here. So we go, this is all there. So what's the variance of white tilde? I go, OK, that is. Let me go slow here. The variance of One half, um, I don't want to do? She can I go here? Yeah, I can. Let's let's do, let's do this. Yeah. Should we do this one half. Why I running over the odd ones plus. So on 2. Even Why eyes. Brackets, 1 over N that's still inside the variance parenthesis. Now, if I want to pull the 1 over N out, what do I need to do? Squared, right? And what else do we want to do? Another thing that I want to do is break up the thing in brackets, because I see there's two terms, the odd ones and the even ones. Is it generally correct that the variance of the sum is equal to the sum of the variances? No. But, but what? Here I can do it. Why? Because they are independent, OK? All the YIs, they are any of them. So I'm summing NYIs, they are weighted, it doesn't matter, but by independence I can use the simplified rule that the variance of the sum is equal to the sum of the variances. OK, so we get first of all, 1 over nsquared. That's this little N here, taken to the front and outside of the variance. Yeah. And um brackets, what do I do? Let's go slow variance of 12, some Y I, that's the odd ones. Plus Variances of 3 and 2. What are we doing here? So, please stop me when I make a mistake. It happens a lot. All right. Next step is, so I can do this here by independence. If they weren't independent, I would have to factor in the covariance between the YIs, but they are, they have zero covariance. So next, I could take the 1/2 here out, but I have to square that, right? So it becomes 1 quarter. And then, like we did for the expected value here. Where do we do this? I want to take the expected, well, the variance in inside the sun. Can I do this here? Well, it's again that question, is the variance of the sum of the odd terms equal to the sum of the variances? Yes, it is here. OK. So I'm doing maybe two steps at the same time. First, this here remains, and I go, so this. 1/2 becomes 1 quarter. Times the sum of the variances. And I can do this here because there are no covariances, OK? Otherwise I would have to consider covariances as well. By independence of the observations, the variance of the sum here happens to be the sum of the variance. Please tell me if I make a mistake. And here are 9 quarters, uh, when we're doing variant here is even. Even And Why I The individual variances. are called sigma Y squared. OK. So plugging that in. You get One squared. 1 quarter. And Over 2 sigmay squad. Thanks. Sorry, sorry, you have to tell me. 904. So this is a 9 here. Oops. And over 2, sigma m2. Is this all correct? That's fingers crossed. Let's see. Now go, comes. One of the ends squares here kill the other ends here? OK. And what do we get? Who's got an overview of what this could be. We've got. A quarter plus 9 quarters, it's 10 quarters. We've got the division by N here, so we've got the 1 over N. Did I say 10 quarters, what could that be? 5/4? OK. Variances Y I is square. Now that is And let me rewrite this. This is equal to just making it look a little bit nicer, 5/4, sigma Y2 over N, that's just reordering, but that is strictly larger than just this. What did I write here? Where does this come from? This is the variant of a guy that we know. Could be a, doesn't have to be a guy. This is why fast variants. So we started on the left-hand side. Can you see this? The variance of white tilde, the weighted average of the observation, some weighted average of the observations, and we showed that this guy's variance or girls exceeds the Y bar, the variance of Y bar. That should not be surprising if you internalise the Gauss, Gauss-Markov theorem, right, which said that nothing beats Y bar. So this guy, so always call these guys, um, this, this variance here, or this estimator Ytilde. Does not have a better or lower variance. In fact, it has a larger one. So the unweighted average. Yo has the lowest variants. That's just an illustration of the Gauss-Markov theorem of the, the blue statement from our slides. Does that make sense? So Just um we got time, yeah, so. Why Tilda has. Larger Variances, oops. Then my bar, by Tilda, I would call. Some weighted average, why bar is our sample average or unweighted average. So maybe another conclusion is why bar is not blue. Not Blue exclamation drama. Can you see? Oh yeah, OK, I can. Uh, it's just a second. OK. Any questions? So it was unbiased. But its variance exceeds the variance of Y bar. You could You could um Put in generic weights here. It doesn't have to be 1/2 and 3/2. It could be 1 over A A over B and C over D or whatever. You can do a similar calculation. It could just get more tedious. The point is, we knew this already. Why bar Waiba has a Lower variance or at least not a variance that is worse. Shall we move on to the next question? Good what's the next question? So these, these questions are taken from the textbook while I do this transition. Um, I do like the textbook. Uh, I know textbooks are maybe not so modern anymore, but this, this is a good textbook if you can get it somehow. Um, I recommend cross-reading. Um, if, if you sort of can't follow some parts of the lecture, I think that this particular book, or let's put it this way, the lecture is based on the book, I get my ideas from the book. So the questions are also from the book. And I point up there, there are no questions for you to see. But so the second exercise comes straight from the book. And a few years ago, there was no issues with this exercise, and then all of a sudden the the war in the Ukraine happened and it just seems like such an unfortunate. Uh, statement, but I'll read through it. So there's a, there's 500 students. So there's a standardised test. This is in Europe for students in Europe. The test. Uh, let me not switch, but, uh, can I show this to you? The test, can you sort of read this? The test is given to 600 randomly selected students in the Ukraine. Lucky textbook question and that question was in there since 2015 or something like that, right? And then anyways. In the as a statistical exercise, it's still quite doable. In the sample, in the sample of 600 Ukrainian kids taking this test, this is secondary school or whatever, the mean is 508, and the standard deviation, the sample standard deviation is 75. So then the question is, first of all. The pop, the hypothesised population mean is 500. These Ukrainian students get an average of 508, so then I go ask my parents, does this mean Ukrainian students are cleverer? Then they go, yes. And What is your more nuanced statement? They have a higher average, so my parents say, therefore they are cleverer. What do you say? So while you think, I'm just collecting the information from this exercise on the piece of paper. So Please have a think and tell me why my parents are wrong. Or why we might need to think harder, so I guess. Maybe some sort of null hypothesis would be The mean is 500, population mean, but then we have a sample of size, let's call it sample 1. sample 0. I'm setting this up for a later exercise. We have 600 students from the Ukraine and we obtained a sample average of 508 and a sample standard deviation. Sorry, this is not as bar but as 0. Of 75. So I'm giving it subscript 0 because we're getting a second sample in a subsequent question. So then I'll call it subscript one. So we've got 600 Ukrainian student students taking this test that averages to 508. The sample standard deviation is 75. This is the S squared that I defined earlier. The square root of that. OK. Now, what's your more nuanced answer on my parents' reply, or my parents always are the ones that don't know statistics in my storytelling. Why is this not enough information to conclude that Ukrainian students are cleverer? Anyone? Yeah. Yeah, it just, it just could have just been a favourable sample for this conclusion. Another random sample could have resulted in 480 as an average. We need to consider the distribution, the spread, and that information is contained in the standard deviation here. Now, how do you construct a confidence interval? I think that was the question. Construct a 95% confidence interval. So what, what was the formula and, and it's just. Um. Mechanics, what was it? From the lecture, so the generic result is you estimate plus minus 1.96 times the standard error. So why bar is my estimator, and I gave it the subscript 0, plus minus 1.96 times the standard error. What's the standard error here? What must I plug in? 75 over Yeah. 75 over route. 600 This thing here, so, um, so here I can calculate the standard error, call it zero is um S0 over N0. Square root. OK. That's, that's what we plug in here. Do people have a number for this? So I'm doing a combination of symbols and numbers. So, so what I should have written here is as node over the square of N. I plugged in the number here. If I plug in the number here, 5008. Do people, can people tell me what you get because I don't, I really don't know what what one gets. So 502-ish maybe? And then 514 then probably it. Yeah. That's good enough. OK. So Were my parents right after all? No, why? This conference interval does not contain 500. So Ukrainian students are cleverer. Just All right. Any, any questions on this, uh, we're still on the page. What's the next question? Oh yeah. Is there statistical evidence, whatever, that Ukrainian students perform differently? Yeah, there is because the hypothesised value is 500 and the confidence interval expands from 5002 to 514. The point here is it's bounded away from 500 above 500, so we can conclude that they're probably cleverer. It's just a probabilistic statement, right? All right, let's, let's collect. So what happens in the next exercise, and we can um probably finish this. Exercise 3. So another 500 students from the Ukraine are selected at random. They are given a 3 hour prep course before taking the test. And they go, they average, the average is 514. With a standard deviation of 65, so this is my second sample now and the question is, are they cleverer than the other Ukrainian students? I mean, cleverer is maybe not a good word. Are there better test takers than the other Ukrainian students. So that's when Schools practise for the NAPLAN and they believe that it makes the kids better test takers. Um let's see if the Ukrainian students here are better test takers. So we've got a second sample of this time of size 500. The average is. Or was it 5? For Standard deviation was 65. Yeah. Now, we are interested in A confidence interval for the change. In mean, so what we are interested in is to study the this random variable here is Y one. Bar minus Y not bar and this guy's variance. This random variables variants we want to assess. That will then tell us something about new 1 minus new not. Just to keep things moving along. OK. Um, so my parents would go, my parents, my poor parents. Um, well, clearly, the thing in parenthesis is 6. So the test takers are cleverer, but we understand there's a whole distribution around this. Now, To, to come up with a confidence interval, we need to apply the generic formula, estimator plus minus 1.96 times the estimator standard error. The estimator here is Y1 bar minus Y not bar. What I'm setting up here is a result for a standard error, OK? Let's, let's work through this and I'll show you what I mean. So first, I can write it like so. OK, um let me make a deliberate mistake and you tell me what the mistake is. Where is the mistake?

SPEAKER 2
Quickly, yeah.

SPEAKER 1
No, we can't, we can. Mhm Should be a plus We can, because it says another, another sample selected at random. So these are different kits. So we, so we can apply the rule here. The variance of the difference is the sum of the variances. Because of independence, we don't need to consider covariances, but what I've written here wasn't a plus, but a minus. So this is correct now. And so we do know from last week what this is here. This is sigma 1 squared over N1, and this is sigma not squared over. And for these guys, we plug in the estimators. So What I've just arrived at here, this is the This is the Population variants of Y1 bar minus Y not bar. So. Um, how do I write this? This gives me uh results. In The standard error. Which I call SE of Y1 bar minus Y not bar by taking this formula here and plugging in. The sample versions of the variances, OK. So you get Oh yeah. S1 squared over N1 plus S0 squared over N0. See here. Oh, we've got plenty of time. And to turn it into a standard error. I have to do this. So the big picture is I figured out the variants of my estimator, and now to make it operational or feasible, I need to replace population objects, so the sigmas here by the sample versions, the S is here, and to turn it into a standard deviation, an estimated standard deviation, I put the square root. So my generic formula for the confidence interval then. How do I write it is Why one bar minus why not bar? Let's put this in parenthesis, don't have to plus minus 1.96. Times the standard error. So I'll just write it again. Have people tried to calculate this? I don't know what you get. This is the confidence interval for the change in population means. So the S you have, you have got S1 squared is 65 squared, not squared is 75 squared. You've got the sample sizes. You can evaluate all of this. The actual number, I don't really care too much about. But what we have done is we have looked at the different estimator here. The estimator was for the change in population means. We used the change in sample means. We had to ask ourselves, ourselves, what is that? What is that guy's variance? We worked it out. First, we worked the variance out. We came up with a feasible version of that variance, turned it into a standard error here, and then applied our generic confidence interval result. The generic confidence interval result.
